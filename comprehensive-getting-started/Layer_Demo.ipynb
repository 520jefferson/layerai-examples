{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Layer Demo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOKbz9uuakNQ"
      },
      "outputs": [],
      "source": [
        "# Install Layer and Authentication\n",
        "!pip install layer -U\n",
        "import layer\n",
        "layer.login()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Project initialization and import Layer decorators\n",
        "layer.init(\"my-first-project\",pip_packages=['matplotlib','sklearn'])\n",
        "from layer.decorators import dataset, model, resources, fabric\n",
        "from layer.decorators.assertions import assert_not_null, assert_true"
      ],
      "metadata": {
        "id": "l6G61hqJlf19"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create your first dataset\n",
        "@dataset(\"my_first_dataset\")\n",
        "@assert_not_null([\"target\",\"feat1\"])\n",
        "@resources(path=\"./data\")\n",
        "def create_dataset():\n",
        "  from matplotlib import pyplot as plt\n",
        "  from sklearn.datasets import make_regression\n",
        "  import pandas as pd\n",
        "  \n",
        "  X_train, Y_train = make_regression(n_samples=100, n_features=3, n_targets=1, noise=0.5)\n",
        "\n",
        "  features = pd.DataFrame(X_train, columns = ['feat1', 'feat2', 'feat3'])\n",
        "  target = pd.DataFrame(Y_train, columns = ['target'])\n",
        "  training_df= pd.concat([features, target], axis=1)\n",
        "\n",
        "  external_df = pd.read_csv(\"data/external.csv\",names=['feat1','feat2','feat3','target'],header=None)\n",
        "  final_training_df = training_df.append(external_df)\n",
        "\n",
        "  training_df[['target']].plot(kind='box', title='Target Quartile Analysis')\n",
        "  layer.log({\"Box plots\": plt})\n",
        "  \n",
        "  return training_df "
      ],
      "metadata": {
        "id": "c8vKAtvLzZH7"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run your function remotely\n",
        "layer.run([create_dataset])"
      ],
      "metadata": {
        "id": "crHeFPUVLryD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create your first model\n",
        "\n",
        "# Test function for your model\n",
        "def model_test_function(predictor):\n",
        "    return (predictor.coef_[0] > 0 and  predictor.coef_[1] > 0 and predictor.coef_[2] > 0) \n",
        "\n",
        "# Model build function\n",
        "@model(\"my_first_model\")\n",
        "@fabric(\"f-medium\")\n",
        "@assert_true(model_test_function)\n",
        "def create_model():\n",
        "  from sklearn.linear_model import LinearRegression\n",
        "  from matplotlib import pyplot as plt\n",
        "  training_data = layer.get_dataset(\"my_first_dataset:1.1\").to_pandas()\n",
        "  predictor = LinearRegression(n_jobs=-1)\n",
        "  predictor.fit(X=training_data.iloc[:,:-1], y=training_data.iloc[:,-1])\n",
        "\n",
        "\n",
        "  importance = predictor.coef_\n",
        "  plt.bar(['feat1', 'feat2', 'feat3'], importance)\n",
        "\n",
        "  layer.log({\"Coef_1\": importance[0],\n",
        "             \"Coef_2\": importance[1],\n",
        "             \"Coef_3\": importance[2],\n",
        "             \"Feature Importance Plot\": plt\n",
        "             })\n",
        "\n",
        "  return predictor"
      ],
      "metadata": {
        "id": "jwIRYIcuz7oG"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run your function remotely\n",
        "layer.run([create_model])"
      ],
      "metadata": {
        "id": "6C-Fa92A0dNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a predictions dataset by fetching and using the model\n",
        "@dataset(\"predictions\")\n",
        "def generate_predictions():\n",
        "  from sklearn.datasets import make_regression\n",
        "  import pandas as pd\n",
        "  from sklearn.metrics import r2_score\n",
        "  \n",
        "  X_test, Y_true = make_regression(n_samples=10, n_features=3, n_targets=1, noise=0.5)\n",
        "\n",
        "  X_test = pd.DataFrame(X_test, columns = ['feat1', 'feat2', 'feat3'])\n",
        "  Y_true = pd.DataFrame(Y_true, columns = ['target'])\n",
        "  \n",
        "  my_model = layer.get_model(\"my_first_model:1.1\").get_train()\n",
        "  Y_pred_arr = my_model.predict(X_test)\n",
        "  Y_pred = pd.DataFrame(Y_pred_arr, columns = ['prediction'])\n",
        "\n",
        "  r2 = r2_score(Y_true, Y_pred)\n",
        "  layer.log({\"R2 Score\": r2})\n",
        "\n",
        "  predictions_df = pd.concat([X_test, Y_true, Y_pred], axis=1)\n",
        "\n",
        "  return predictions_df"
      ],
      "metadata": {
        "id": "rR43envC0Lv3"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run your function remotely\n",
        "layer.run([generate_predictions])"
      ],
      "metadata": {
        "id": "gbI2BDxjP4od"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}