{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "version": "3.6.4",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python",
   "mimetype": "text/x-python"
  },
  "colab": {
   "name": "convolutional-neural-network-cnn-ima.ipynb",
   "provenance": [],
   "collapsed_sections": []
  }
 },
 "nbformat_minor": 0,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Convolutional Neural Network (CNN) - Image Classification"
   ],
   "metadata": {
    "id": "XYn7v0Vg6bfi"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "[![Open in Layer](https://app.layer.ai/assets/badge.svg)](https://app.layer.ai/layer/image-classification) [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/layerai/examples/blob/main/food-vision/food-vision.ipynb) [![Layer Examples Github](https://badgen.net/badge/icon/github?icon=github&label)](https://github.com/layerai/examples/tree/main/food-vision)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "pip install layer -qqq"
   ],
   "metadata": {
    "id": "gFo95gq9YOGc",
    "trusted": true,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "09fd994c-63e4-43a1-9815-36b8cd1ef198",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import layer\n",
    "from layer.decorators import model, fabric,pip_requirements"
   ],
   "metadata": {
    "id": "4mAdGAWAYOGd",
    "execution": {
     "iopub.status.busy": "2022-04-24T15:40:03.867739Z",
     "iopub.execute_input": "2022-04-24T15:40:03.868001Z",
     "iopub.status.idle": "2022-04-24T15:40:03.871598Z",
     "shell.execute_reply.started": "2022-04-24T15:40:03.867976Z",
     "shell.execute_reply": "2022-04-24T15:40:03.870965Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "layer.login()"
   ],
   "metadata": {
    "id": "tZ0uKzJyYOGd",
    "execution": {
     "iopub.status.busy": "2022-04-24T15:40:04.682609Z",
     "iopub.execute_input": "2022-04-24T15:40:04.683017Z",
     "iopub.status.idle": "2022-04-24T15:40:25.149686Z",
     "shell.execute_reply.started": "2022-04-24T15:40:04.682973Z",
     "shell.execute_reply": "2022-04-24T15:40:25.1482Z"
    },
    "trusted": true,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5427d89f-0016-4697-8343-16811077f297",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "layer.init(\"image-classification\")"
   ],
   "metadata": {
    "id": "tq6yTgnxYOGd",
    "execution": {
     "iopub.status.busy": "2022-04-24T15:41:12.658776Z",
     "iopub.execute_input": "2022-04-24T15:41:12.659074Z",
     "iopub.status.idle": "2022-04-24T15:41:13.169253Z",
     "shell.execute_reply.started": "2022-04-24T15:41:12.659046Z",
     "shell.execute_reply": "2022-04-24T15:41:13.168024Z"
    },
    "trusted": true,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "4bb4efb2-925c-48ef-b8c6-df005e7beda7",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "pip install wget"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-24T15:41:51.929365Z",
     "iopub.execute_input": "2022-04-24T15:41:51.929631Z",
     "iopub.status.idle": "2022-04-24T15:42:02.547896Z",
     "shell.execute_reply.started": "2022-04-24T15:41:51.929602Z",
     "shell.execute_reply": "2022-04-24T15:42:02.54727Z"
    },
    "trusted": true,
    "id": "TypPFTJ2Mnhn"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "@pip_requirements(packages=[\"wget\",\"tensorflow\",\"keras\"])\n",
    "@fabric(\"f-gpu-small\")\n",
    "@model(name=\"food-vision\")\n",
    "def train():\n",
    "    from tensorflow import keras\n",
    "    from tensorflow.keras import Sequential\n",
    "    from tensorflow.keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,Dropout\n",
    "    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "    from tensorflow.keras.callbacks import EarlyStopping\n",
    "    import os\n",
    "    import matplotlib.pyplot as plt \n",
    "    from PIL import Image\n",
    "    import pandas as pd\n",
    "    import tarfile\n",
    "    import wget\n",
    "    wget.download(\"http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz\")\n",
    "    food_tar = tarfile.open('food-101.tar.gz')\n",
    "    food_tar.extractall('.') \n",
    "    food_tar.close()\n",
    "    plt.imshow(Image.open(\"food-101/images/beignets/2802124.jpg\"))\n",
    "    plt.axis('off')\n",
    "    layer.log({\"Sample image\":plt.gcf()})\n",
    "    base_dir = 'food-101/images'\n",
    "    class_names = os.listdir(base_dir)\n",
    "    train_datagen = ImageDataGenerator(rescale=1./255, \n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2, \n",
    "                                   horizontal_flip=True,\n",
    "                                   width_shift_range=0.1,\n",
    "                                   height_shift_range=0.1,\n",
    "                                   validation_split=0.2\n",
    "                                   )\n",
    "    validation_gen = ImageDataGenerator(rescale=1./255,validation_split=0.2)\n",
    "    image_size = (200, 200)\n",
    "    training_set = train_datagen.flow_from_directory(base_dir,\n",
    "                                                 seed=101,                                                 \n",
    "                                                 target_size=image_size,\n",
    "                                                 batch_size=32,\n",
    "                                                 subset = \"training\",\n",
    "                                                 class_mode='categorical')\n",
    "    validation_set = validation_gen.flow_from_directory(base_dir, \n",
    "                                               target_size=image_size,\n",
    "                                               batch_size=32, \n",
    "                                               subset = \"validation\",\n",
    "                                               class_mode='categorical')\n",
    "    model = Sequential([\n",
    "            \n",
    "    Conv2D(filters=32,kernel_size=(3,3),  input_shape = (200, 200, 3),activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "\n",
    "    Conv2D(filters=32,kernel_size=(3,3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Conv2D(filters=64,kernel_size=(3,3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    Dense(101, activation='softmax')])\n",
    "    model.compile(optimizer='adam',\n",
    "              loss=keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=[keras.metrics.CategoricalAccuracy()])\n",
    "    callback = EarlyStopping(monitor='loss', patience=3)\n",
    "    epochs=10\n",
    "    history = model.fit(training_set,validation_data=validation_set, epochs=epochs,callbacks=[callback])\n",
    "    metrics_df = pd.DataFrame(history.history)\n",
    "    layer.log({\"Metrics\":metrics_df})\n",
    "    loss, accuracy = model.evaluate(validation_set)\n",
    "    layer.log({\"Accuracy on test dataset\":accuracy})\n",
    "    metrics_df[[\"loss\",\"val_loss\"]].plot()\n",
    "    layer.log({\"Loss plot\":plt.gcf()})\n",
    "    metrics_df[[\"categorical_accuracy\",\"val_categorical_accuracy\"]].plot()\n",
    "    layer.log({\"Accuracy plot\":plt.gcf()})\n",
    "    return model"
   ],
   "metadata": {
    "id": "6NeNa9KIYOGe",
    "execution": {
     "iopub.status.busy": "2022-04-24T15:42:06.180692Z",
     "iopub.execute_input": "2022-04-24T15:42:06.180986Z",
     "iopub.status.idle": "2022-04-24T15:42:06.208236Z",
     "shell.execute_reply.started": "2022-04-24T15:42:06.180956Z",
     "shell.execute_reply": "2022-04-24T15:42:06.206469Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Run Layer infra\n",
    "layer.run([train],debug=True)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-24T15:42:10.157203Z",
     "iopub.execute_input": "2022-04-24T15:42:10.15748Z"
    },
    "trusted": true,
    "id": "E-mRkxXsMnhq"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Run locally\n",
    "train()"
   ],
   "metadata": {
    "id": "J8MsHfqkYOGf",
    "execution": {
     "iopub.status.busy": "2022-04-24T15:41:21.254046Z",
     "iopub.execute_input": "2022-04-24T15:41:21.25484Z",
     "iopub.status.idle": "2022-04-24T15:41:25.146901Z",
     "shell.execute_reply.started": "2022-04-24T15:41:21.254806Z",
     "shell.execute_reply": "2022-04-24T15:41:25.144825Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "image_model = layer.get_model('food-vision').get_train()\n",
    "!wget --no-check-certificate \\\n",
    "    https://upload.wikimedia.org/wikipedia/commons/b/b1/Buttermilk_Beignets_%284515741642%29.jpg \\\n",
    "    -O /tmp/Buttermilk_Beignets_.jpg"
   ],
   "metadata": {
    "id": "_2xpN6wgYOGf",
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "test_image = image.load_img('/tmp/Buttermilk_Beignets_.jpg', target_size=(200, 200))"
   ],
   "metadata": {
    "id": "5sssJ6THYOGf",
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "test_image = image.img_to_array(test_image)\n"
   ],
   "metadata": {
    "id": "CwVrT9Z1YOGg",
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "test_image = test_image / 255.0"
   ],
   "metadata": {
    "id": "kYeWf7IQYOGg",
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "test_image.shape"
   ],
   "metadata": {
    "id": "WHajQBvOYOGg",
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "test_image = np.expand_dims(test_image, axis=0)\n"
   ],
   "metadata": {
    "id": "Yb74G7MaYOGg",
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "prediction = image_model.predict(test_image)\n"
   ],
   "metadata": {
    "id": "YKPvxeTZYOGg",
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "prediction[0][0]"
   ],
   "metadata": {
    "id": "lb_6_0sJYOGg",
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "scores = tf.nn.softmax(prediction[0])\n",
    "scores = scores.numpy()"
   ],
   "metadata": {
    "id": "S_0dwBLXYOGg",
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "base_dir = 'food-101/images'\n",
    "class_names = os.listdir(base_dir)\n",
    "f\"{class_names[np.argmax(scores)]} with a { (100 * np.max(scores)).round(2) } percent confidence.\" "
   ],
   "metadata": {
    "id": "DhlDdwn5YOGh",
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}