{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8TglEQfw28IZ"
   },
   "source": [
    "# Face classification with Ango and Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-q2HHEBY28Ib"
   },
   "source": [
    "## Install Ango"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_t-rRu6r7Mgj",
    "outputId": "4ccc57be-90de-4073-a80d-e64ab8382532",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "!pip install ango -qqq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MvdHYeg628Ic"
   },
   "source": [
    "## Install Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6GtVdzom28Ic",
    "outputId": "ec69fc91-15de-48cf-c442-8bfbfd7a2d7d",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade layer -qqq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rePs1GAX28Ic"
   },
   "source": [
    "## Fetch [data from Ango Hub](https://ango.ai/open-dataset/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "F6pl0oyT64al"
   },
   "outputs": [],
   "source": [
    "from ango.sdk import SDK\n",
    "import os \n",
    "import urllib.request\n",
    "\n",
    "class Ango:\n",
    "    def __init__(self, api_key, project_id=None) -> None:\n",
    "        self.sdk = SDK(api_key=api_key)\n",
    "        if project_id:\n",
    "            self.project_id = project_id\n",
    "    \n",
    "    def setProject(self,project_id):\n",
    "        self.project_id = project_id\n",
    "    \n",
    "    '''\n",
    "    Gets annotations for assets within a project, streams page by page.\n",
    "    params:\n",
    "    items_per_page : The number of annotations fetched per page.\n",
    "    annotation_status : The current stage of annotation (\"Completed\" OR \"Todo\") leave blank to fetch all\n",
    "\n",
    "    returns:\n",
    "    A List of annotations\n",
    "    '''\n",
    "    def getAnnotations(self, items_per_page = 100, annotation_status = None):\n",
    "        remaining_tasks = 1\n",
    "        page = 1\n",
    "        tasks = []\n",
    "        while (remaining_tasks > 0):\n",
    "            response =  self.sdk.get_tasks(self.project_id, page=page, limit=items_per_page, status= annotation_status)\n",
    "            tasks.extend(response['data']['tasks'])\n",
    "            remaining_tasks =  response[\"data\"][\"total\"] - len(tasks)\n",
    "            page += 1\n",
    "        return tasks\n",
    "\n",
    "    def get_name_from_url(self, imgUrl):\n",
    "      return imgUrl.split('/')[-1]\n",
    "\n",
    "    def fetchImages(self,images, folder_path=\"downloaded_images/\"):\n",
    "      dirname = os.path.dirname(__file__)\n",
    "      if (not os.path.exists(folder_path)):\n",
    "          os.mkdir(os.path.join(dirname, folder_path))\n",
    "      for imgUrl in images:\n",
    "        img_name = self.get_name_from_url(imgUrl)\n",
    "        image_path = os.path.join(dirname, folder_path, img_name)\n",
    "        if os.path.isfile(image_path):\n",
    "          continue\n",
    "        else:\n",
    "          urllib.request.urlretrieve(imgUrl, image_path)\n",
    "      print(\"All images downloaded\")\n",
    "\n",
    "    def fetchExportLink(self):\n",
    "      return self.sdk.export(self.project_id)['data']['exportPath']\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "-yp1jFSu7ESQ",
    "outputId": "a3d7b204-f4c4-41e5-b29c-babf63e51725",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "46064\n"
     ]
    }
   ],
   "source": [
    "#Run this block after the two credentials have been added.\n",
    "#You may save the annotations in JSON, or use them programatically. \n",
    "#Note: This takes some time for larger annotations.\n",
    "ango = Ango(api_key=\"YOUR_API_KEY\",project_id=\"YOUR_PROJECT_ID\") #Face Classification\n",
    "annotations = ango.getAnnotations(annotation_status=\"Completed\")\n",
    "print(len(annotations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sKJGwI6Pq9kA",
    "outputId": "3dbf41e6-7a70-432f-e907-ae1f9c8702c2",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "link = ango.fetchExportLink()\n",
    "print(link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4-yLINx_ch6t"
   },
   "source": [
    "### Save the data as a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "DYU3qE-Rcmq3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_answer(schemaId, task):\n",
    "  return next((answer[\"answer\"] for answer in task['answer']['classifications'] if answer['schemaId'] == schemaId), None)\n",
    "\n",
    "def build():\n",
    "  from PIL import Image\n",
    "  import requests\n",
    "\n",
    "  data = []\n",
    "  for task in annotations[:2500]:\n",
    "    img_url = task[\"asset\"][\"data\"]\n",
    "    img = Image.open(requests.get(img_url, stream=True).raw)\n",
    "\n",
    "    data.append([\n",
    "      img,\n",
    "      get_answer(\"7d4d70ea16e8e5d7ce8e721\", task), # Sex\n",
    "      get_answer(\"76e4a3dbf96926edadd5203\", task), # Age\n",
    "      get_answer(\"05e865541776c186f3e4003\", task), # Hair Color\n",
    "      get_answer(\"ff5e7ac66607ebe73810601\", task), # Beard Color\n",
    "      get_answer(\"1f5411a7bbcdba28fe30677\", task), # Mustache Color\n",
    "      get_answer(\"d0d75fc06feaa006e5c0106\", task), # Eye Color\n",
    "      get_answer(\"ec5e7cd3838fc4d5c7c6298\", task), # Glasses\n",
    "    ])\n",
    "    # answers = task['answer']['classifications']\n",
    "    # answer = next((answer for answer in task['answer']['classifications'] if answer['schemaId'] == \"7d4d70ea16e8e5d7ce8e721\"), None)\n",
    "    # print(answer)\n",
    "    task['answer']['classifications']\n",
    "  \n",
    "  return pd.DataFrame(data,columns=[\"image\", \"sex\", \"age\",\"hair_color\",\"beard_color\",\"mustache_color\",\"eye_color\",\"glasses\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WOvthdW-28Ih"
   },
   "source": [
    "## Log in to Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nDqVqDaq28Ih",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "afb90ea4-be5a-4c3a-cbc5-1dc03477c7cd",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import layer\n",
    "layer.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v5IWMEeg28Ih"
   },
   "source": [
    "### Initialize a Layer project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "pycharm": {
     "is_executing": true
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dd-FNc7K28Ih",
    "outputId": "4682095b-33e8-487a-bf44-3f505b7a84c1"
   },
   "outputs": [],
   "source": [
    "from layer.decorators import model, fabric\n",
    "layer.init(\"ango-face-classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rKPLZPCK28Ih"
   },
   "source": [
    "### Define the model training function"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "def load_process_images(image):\n",
    "  image = image.resize((224,224))\n",
    "  image_array  = img_to_array(image)\n",
    "  return image_array"
   ],
   "metadata": {
    "id": "0yReTZuR2vH2"
   },
   "execution_count": 60,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": [],
    "id": "ughlVXUf28Ih"
   },
   "outputs": [],
   "source": [
    "@fabric(\"f-gpu-small\")\n",
    "@model(\"face-classification\")\n",
    "def train():\n",
    "  from tensorflow import keras\n",
    "  from tensorflow.keras import Sequential\n",
    "  from tensorflow.keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,Dropout,Resizing\n",
    "  from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "  from tensorflow.keras.callbacks import EarlyStopping\n",
    "  import matplotlib.pyplot as plt \n",
    "  import numpy as np\n",
    "  import pandas as pd\n",
    "  from sklearn.preprocessing import LabelEncoder\n",
    "  from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "  df = build()\n",
    "  gender = df[['image','sex']]\n",
    "  labelencoder = LabelEncoder()\n",
    "  gender = gender.assign(sex = labelencoder.fit_transform(gender[\"sex\"]))\n",
    "  X = gender[['image']]\n",
    "  y = gender[['sex']]\n",
    "  X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "  for image in range(4):\n",
    "    layer.log({f\"Sample face-{image}\": X_train['image'][image]})\n",
    "  X_train = np.stack(X_train['image'].map(load_process_images))\n",
    "  X_test = np.stack(X_test['image'].map(load_process_images))\n",
    "    \n",
    "  train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2,zoom_range=0.2, horizontal_flip=True,width_shift_range=0.1,height_shift_range=0.1)\n",
    "  train_datagen.fit(X_train)\n",
    "  training_data = train_datagen.flow(X_train, y_train, batch_size=32)\n",
    " \n",
    "  validation_gen = ImageDataGenerator(rescale=1./255)\n",
    "  testing_data = validation_gen.flow(X_test, y_test, batch_size=32)\n",
    "\n",
    "  model = Sequential([\n",
    "    Conv2D(filters=32,kernel_size=(3,3),  input_shape = (224, 224, 3),activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "\n",
    "    Conv2D(filters=32,kernel_size=(3,3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Conv2D(filters=64,kernel_size=(3,3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    Dense(3, activation='softmax')])\n",
    "\n",
    "  model.compile(optimizer='adam', loss=keras.losses.SparseCategoricalCrossentropy(), metrics=[keras.metrics.CategoricalAccuracy()])\n",
    "  callback = EarlyStopping(monitor='loss', patience=3)\n",
    "  epochs=100\n",
    "  history = model.fit(training_data,validation_data=testing_data, epochs=epochs,callbacks=[callback])\n",
    "  metrics_df = pd.DataFrame(history.history)\n",
    "  layer.log({\"metrics DataFrame\": metrics_df})\n",
    "  loss, accuracy = model.evaluate(testing_data)\n",
    "  layer.log({\"Testing loss\": loss})\n",
    "  layer.log({\"Testing accuracy\": accuracy})\n",
    "  print('Accuracy on test dataset:', accuracy)\n",
    "  metrics_df[[\"loss\",\"val_loss\"]].plot()\n",
    "  layer.log({\"Loss plot\": plt.gcf()})\n",
    "  training_loss, training_accuracy = model.evaluate(training_data)\n",
    "  layer.log({\"Training loss\": training_loss})\n",
    "  layer.log({\"Training accuracy\": training_accuracy})\n",
    "  metrics_df[[\"categorical_accuracy\",\"val_categorical_accuracy\"]].plot()\n",
    "  layer.log({\"Accuracy plot\": plt.gcf()})\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oeQatbZg28Ih"
   },
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": [],
    "id": "VeUhXJYN28Ih"
   },
   "outputs": [],
   "source": [
    "# Train the model on your local infra\n",
    "# train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "id": "aA0bbLYy28Ih",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51,
     "referenced_widgets": [
      "276a421c4b2d484a8bae49f1699fcd09",
      "18a8a2bb16564153b5b01031d7e4b311"
     ]
    },
    "outputId": "2a2ec3a7-c3a4-4b8c-cf18-bac252bd013e"
   },
   "outputs": [],
   "source": [
    "# Run the project on Layer Infra using remote GPUs\n",
    "layer.run([train])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mfxBCx9i28Ii"
   },
   "source": [
    "### Fetch trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "id": "_BHjJKNW28Ii",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35,
     "referenced_widgets": [
      "9c212a7c34814e5290dbc615238c575c",
      "b566111319114167b8f875a3662cfaf7"
     ]
    },
    "outputId": "f181e897-e1b8-4501-de8c-348e5108037c",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "my_model = layer.get_model('layer/ango-face-classification/models/face-classification').get_train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JIM3wV6Y28Ii"
   },
   "source": [
    "### Run predictions on the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "Ihh1Xpwf28Ii"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "id": "Z5Yt8lZQ28Ik",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1b82d2df-1c3c-4847-fa5e-7aa5bc8c3c93"
   },
   "outputs": [],
   "source": [
    "!wget --no-check-certificate \\\n",
    "   https://storage.googleapis.com/ango-covid-dataset/ffhq-dataset/batch2/48312.png \\\n",
    "    -O 48312.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "jWVBJRxz28Il"
   },
   "outputs": [],
   "source": [
    "test_image = image.load_img('48312.png', target_size=(224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "xpMjFACv28Il"
   },
   "outputs": [],
   "source": [
    "test_image = image.img_to_array(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "IiZY_yTY28Il"
   },
   "outputs": [],
   "source": [
    "test_image = test_image / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "W_k3thPL28Il"
   },
   "outputs": [],
   "source": [
    "test_image = np.expand_dims(test_image, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "UA94GZtB28Il"
   },
   "outputs": [],
   "source": [
    "prediction = my_model.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "_WhEFH8s28Il",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "04ed819d-19e4-41c2-ddb5-22a84ffdbe7d"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.58835137, 0.02280423, 0.38884434], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "U0U9oML228Il",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "outputId": "0aa9aa4b-dfca-4743-8728-06325f3c142b"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'0 with a 41.89 percent confidence.'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "scores = tf.nn.softmax(prediction[0])\n",
    "scores = scores.numpy()\n",
    "class_names = [0,1,2]\n",
    "f\"{class_names[np.argmax(scores)]} with a { (100 * np.max(scores)).round(2) } percent confidence.\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lIcI708I28Im"
   },
   "source": [
    "## Next steps\n",
    "To learn more about using layer, you can: \n",
    "- Join our [Slack Community ](https://bit.ly/layercommunityslack)\n",
    "- Visit [Layer Examples Repo](https://github.com/layerai/examples) for more examples\n",
    "- Browse [Trending Layer Projects](https://layer.ai) on our mainpage\n",
    "- Check out [Layer Documentation](https://docs.app.layer.ai) to learn more"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "colab": {
   "name": "ango.ipynb",
   "provenance": []
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "276a421c4b2d484a8bae49f1699fcd09": {
     "model_module": "@jupyter-widgets/output",
     "model_name": "OutputModel",
     "model_module_version": "1.0.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_18a8a2bb16564153b5b01031d7e4b311",
      "msg_id": "",
      "outputs": [
       {
        "output_type": "display_data",
        "data": {
         "text/plain": "\u001B[32m⠧\u001B[0m  face-classification  \u001B[38;2;0;0;0m━━━━━━━\u001B[0m\u001B[39m╺\u001B[0m\u001B[39m━━\u001B[0m TRAINING \u001B[39m[\u001B[0m\u001B[38;2;155;155;159m0:00:26\u001B[0m\u001B[39m]\u001B[0m                               \n   \u001B[4;38;2;161;161;169m↳ \u001B[0m\u001B]8;id=576778;https://app.layer.ai/layer/ango-face-classification/models/face-classification\u001B\\\u001B[4;38;2;161;161;169mhttps://app.layer.ai/layer/ango-face-classification/models/face-classification\u001B[0m\u001B]8;;\u001B\\ \n",
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">⠧</span>  face-classification  <span style=\"color: #000000; text-decoration-color: #000000\">━━━━━━━</span><span style=\"color: #000000; text-decoration-color: #000000\">╺━━</span> TRAINING <span style=\"color: #000000; text-decoration-color: #000000\">[</span><span style=\"color: #9b9b9f; text-decoration-color: #9b9b9f\">0:00:26</span><span style=\"color: #000000; text-decoration-color: #000000\">]</span>                               \n   <span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">↳ </span><a href=\"https://app.layer.ai/layer/ango-face-classification/models/face-classification\"><span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">https://app.layer.ai/layer/ango-face-classification/models/face-classification</span></a> \n</pre>\n"
        },
        "metadata": {}
       }
      ]
     }
    },
    "18a8a2bb16564153b5b01031d7e4b311": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c212a7c34814e5290dbc615238c575c": {
     "model_module": "@jupyter-widgets/output",
     "model_name": "OutputModel",
     "model_module_version": "1.0.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_b566111319114167b8f875a3662cfaf7",
      "msg_id": "",
      "outputs": [
       {
        "output_type": "display_data",
        "data": {
         "text/plain": "\u001B[32m⠙\u001B[0m  face-classification  \u001B[38;2;21;127;61m━━━━━━━━━━\u001B[0m \u001B[38;2;21;127;61mLOADED\u001B[0m \u001B[39m[\u001B[0m\u001B[38;2;155;155;159m0:00:13\u001B[0m\u001B[39m]\u001B[0m \n",
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">⠙</span>  face-classification  <span style=\"color: #157f3d; text-decoration-color: #157f3d\">━━━━━━━━━━</span> <span style=\"color: #157f3d; text-decoration-color: #157f3d\">LOADED</span> <span style=\"color: #000000; text-decoration-color: #000000\">[</span><span style=\"color: #9b9b9f; text-decoration-color: #9b9b9f\">0:00:13</span><span style=\"color: #000000; text-decoration-color: #000000\">]</span> \n</pre>\n"
        },
        "metadata": {}
       }
      ]
     }
    },
    "b566111319114167b8f875a3662cfaf7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}