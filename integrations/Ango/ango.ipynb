{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8TglEQfw28IZ"
   },
   "source": [
    "# Face classification with Ango and Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-q2HHEBY28Ib"
   },
   "source": [
    "## Install Ango"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_t-rRu6r7Mgj",
    "outputId": "159fa177-96c6-49a0-89c0-206233f3d5c7",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001B[?25l\r\u001B[K     |██████                          | 10 kB 20.2 MB/s eta 0:00:01\r\u001B[K     |████████████                    | 20 kB 19.8 MB/s eta 0:00:01\r\u001B[K     |██████████████████              | 30 kB 10.6 MB/s eta 0:00:01\r\u001B[K     |████████████████████████▏       | 40 kB 4.5 MB/s eta 0:00:01\r\u001B[K     |██████████████████████████████▏ | 51 kB 4.8 MB/s eta 0:00:01\r\u001B[K     |████████████████████████████████| 54 kB 1.5 MB/s \n",
      "\u001B[K     |████████████████████████████████| 56 kB 3.9 MB/s \n",
      "\u001B[K     |████████████████████████████████| 59 kB 6.1 MB/s \n",
      "\u001B[K     |████████████████████████████████| 52 kB 777 kB/s \n",
      "\u001B[K     |████████████████████████████████| 70 kB 7.3 MB/s \n",
      "\u001B[K     |████████████████████████████████| 339 kB 53.2 MB/s \n",
      "\u001B[?25h"
     ]
    }
   ],
   "source": [
    "!pip install ango -qqq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MvdHYeg628Ic"
   },
   "source": [
    "## Install Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6GtVdzom28Ic",
    "outputId": "4aaad470-caf7-4bf1-8085-ffec574c49ad",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001B[K     |████████████████████████████████| 438 kB 5.3 MB/s \n",
      "\u001B[K     |████████████████████████████████| 4.0 MB 37.2 MB/s \n",
      "\u001B[K     |████████████████████████████████| 4.2 MB 36.7 MB/s \n",
      "\u001B[K     |████████████████████████████████| 271 kB 61.9 MB/s \n",
      "\u001B[K     |████████████████████████████████| 101 kB 9.2 MB/s \n",
      "\u001B[K     |████████████████████████████████| 26.7 MB 1.3 MB/s \n",
      "\u001B[K     |████████████████████████████████| 212 kB 63.3 MB/s \n",
      "\u001B[K     |████████████████████████████████| 132 kB 66.3 MB/s \n",
      "\u001B[K     |████████████████████████████████| 56 kB 3.8 MB/s \n",
      "\u001B[K     |████████████████████████████████| 17.8 MB 552 kB/s \n",
      "\u001B[K     |████████████████████████████████| 2.4 MB 41.1 MB/s \n",
      "\u001B[K     |████████████████████████████████| 256 kB 46.7 MB/s \n",
      "\u001B[K     |████████████████████████████████| 4.4 MB 39.7 MB/s \n",
      "\u001B[K     |████████████████████████████████| 1.3 MB 35.1 MB/s \n",
      "\u001B[K     |████████████████████████████████| 40 kB 2.9 MB/s \n",
      "\u001B[K     |████████████████████████████████| 381 kB 52.1 MB/s \n",
      "\u001B[K     |████████████████████████████████| 94 kB 1.4 MB/s \n",
      "\u001B[K     |████████████████████████████████| 8.7 MB 19.1 MB/s \n",
      "\u001B[K     |████████████████████████████████| 79 kB 4.3 MB/s \n",
      "\u001B[K     |████████████████████████████████| 138 kB 48.7 MB/s \n",
      "\u001B[K     |████████████████████████████████| 62 kB 628 kB/s \n",
      "\u001B[K     |████████████████████████████████| 596 kB 46.5 MB/s \n",
      "\u001B[K     |████████████████████████████████| 181 kB 50.1 MB/s \n",
      "\u001B[K     |████████████████████████████████| 210 kB 30.7 MB/s \n",
      "\u001B[K     |████████████████████████████████| 146 kB 50.5 MB/s \n",
      "\u001B[K     |████████████████████████████████| 79 kB 6.6 MB/s \n",
      "\u001B[K     |████████████████████████████████| 63 kB 1.1 MB/s \n",
      "\u001B[K     |████████████████████████████████| 127 kB 49.9 MB/s \n",
      "\u001B[K     |████████████████████████████████| 51 kB 5.9 MB/s \n",
      "\u001B[K     |████████████████████████████████| 78 kB 5.8 MB/s \n",
      "\u001B[K     |████████████████████████████████| 6.6 MB 38.3 MB/s \n",
      "\u001B[K     |████████████████████████████████| 84 kB 2.9 MB/s \n",
      "\u001B[33mWARNING: The candidate selected for download or install is a yanked version: 'grpcio' candidate (version 1.45.0 at https://files.pythonhosted.org/packages/b8/ab/c7abc950e222c4cab5f7fd92107f3b09553061f673f1a670e6569105f584/grpcio-1.45.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl#sha256=cc135b77f384a84bac67a37947886986be136356446338d64160a30c85f20c6d (from https://pypi.org/simple/grpcio/) (requires-python:>=3.6))\n",
      "Reason for being yanked: Segfaults\u001B[0m\n",
      "\u001B[33mWARNING: The candidate selected for download or install is a yanked version: 'grpcio-tools' candidate (version 1.45.0 at https://files.pythonhosted.org/packages/be/e1/70dac693e6df7e4f3108dfd3a82f86f0cd3742d9afe98bb2fe4333a3edd7/grpcio_tools-1.45.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl#sha256=7db11a65e07410db1c31cbeb9afe344a6bd88a63dcd819557707ca7318478727 (from https://pypi.org/simple/grpcio-tools/) (requires-python:>=3.6))\n",
      "Reason for being yanked: grpcio 1.45.0 was yanked\u001B[0m\n",
      "\u001B[?25h  Building wheel for validate-email (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Building wheel for databricks-cli (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Building wheel for polling (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
      "nbclient 0.6.2 requires jupyter-client>=6.1.5, but you have jupyter-client 5.3.5 which is incompatible.\n",
      "jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.29 which is incompatible.\n",
      "ipython 5.5.0 requires prompt-toolkit<2.0.0,>=1.0.4, but you have prompt-toolkit 3.0.29 which is incompatible.\n",
      "gym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.0.0 which is incompatible.\n",
      "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade layer -qqq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rePs1GAX28Ic"
   },
   "source": [
    "## Fetch [data from Ango Hub](https://ango.ai/open-dataset/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "F6pl0oyT64al"
   },
   "outputs": [],
   "source": [
    "from ango.sdk import SDK\n",
    "import os \n",
    "import urllib.request\n",
    "\n",
    "class Ango:\n",
    "    def __init__(self, api_key, project_id=None) -> None:\n",
    "        self.sdk = SDK(api_key=api_key)\n",
    "        if project_id:\n",
    "            self.project_id = project_id\n",
    "    \n",
    "    def setProject(self,project_id):\n",
    "        self.project_id = project_id\n",
    "    \n",
    "    '''\n",
    "    Gets annotations for assets within a project, streams page by page.\n",
    "    params:\n",
    "    items_per_page : The number of annotations fetched per page.\n",
    "    annotation_status : The current stage of annotation (\"Completed\" OR \"Todo\") leave blank to fetch all\n",
    "\n",
    "    returns:\n",
    "    A List of annotations\n",
    "    '''\n",
    "    def getAnnotations(self, items_per_page = 100, annotation_status = None):\n",
    "        remaining_tasks = 1\n",
    "        page = 1\n",
    "        tasks = []\n",
    "        while (remaining_tasks > 0):\n",
    "            response =  self.sdk.get_tasks(self.project_id, page=page, limit=items_per_page, status= annotation_status)\n",
    "            tasks.extend(response['data']['tasks'])\n",
    "            remaining_tasks =  response[\"data\"][\"total\"] - len(tasks)\n",
    "            page += 1\n",
    "        return tasks\n",
    "\n",
    "    def get_name_from_url(self, imgUrl):\n",
    "      return imgUrl.split('/')[-1]\n",
    "\n",
    "    def fetchImages(self,images, folder_path=\"downloaded_images/\"):\n",
    "      dirname = os.path.dirname(__file__)\n",
    "      if (not os.path.exists(folder_path)):\n",
    "          os.mkdir(os.path.join(dirname, folder_path))\n",
    "      for imgUrl in images:\n",
    "        img_name = self.get_name_from_url(imgUrl)\n",
    "        image_path = os.path.join(dirname, folder_path, img_name)\n",
    "        if os.path.isfile(image_path):\n",
    "          continue\n",
    "        else:\n",
    "          urllib.request.urlretrieve(imgUrl, image_path)\n",
    "      print(\"All images downloaded\")\n",
    "\n",
    "    def fetchExportLink(self):\n",
    "      return self.sdk.export(self.project_id)['data']['exportPath']\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "-yp1jFSu7ESQ",
    "outputId": "f56979d6-e2e7-4cc8-fcb0-d983b8a65c4a",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "46064\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Run this block after the two credentials have been added.\n",
    "#You may save the annotations in JSON, or use them programatically. \n",
    "#Note: This takes some time for larger annotations.\n",
    "ango = Ango(api_key=\"YOUR_API_KEY\",project_id=\"YOUR_PROJECT_ID\") #Face Classification\n",
    "annotations = ango.getAnnotations(annotation_status=\"Completed\")\n",
    "print(len(annotations))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sKJGwI6Pq9kA",
    "outputId": "86cf1d23-a0bd-4a6e-a16d-fc62f6a46504",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "link = ango.fetchExportLink()\n",
    "print(link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4-yLINx_ch6t"
   },
   "source": [
    "### Save the data as a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "DYU3qE-Rcmq3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def get_answer(schemaId, task):\n",
    "  return next((answer[\"answer\"] for answer in task['answer']['classifications'] if answer['schemaId'] == schemaId), None)\n",
    "\n",
    "def build():\n",
    "  from PIL import Image\n",
    "  import requests\n",
    "\n",
    "  data = []\n",
    "  for task in annotations[:2500]:\n",
    "    img_url = task[\"asset\"][\"data\"]\n",
    "    img = Image.open(requests.get(img_url, stream=True).raw)\n",
    "    img_byte_arr = io.BytesIO()\n",
    "    img.save(img_byte_arr, format=img.format)\n",
    "    image_as_string = base64.b64encode(img_byte_arr.getvalue())\n",
    "    img_str = image_as_string.decode(\"utf-8\")\n",
    "\n",
    "    data.append([\n",
    "      img_str,\n",
    "      get_answer(\"7d4d70ea16e8e5d7ce8e721\", task), # Sex\n",
    "      get_answer(\"76e4a3dbf96926edadd5203\", task), # Age\n",
    "      get_answer(\"05e865541776c186f3e4003\", task), # Hair Color\n",
    "      get_answer(\"ff5e7ac66607ebe73810601\", task), # Beard Color\n",
    "      get_answer(\"1f5411a7bbcdba28fe30677\", task), # Mustache Color\n",
    "      get_answer(\"d0d75fc06feaa006e5c0106\", task), # Eye Color\n",
    "      get_answer(\"ec5e7cd3838fc4d5c7c6298\", task), # Glasses\n",
    "    ])\n",
    "    # answers = task['answer']['classifications']\n",
    "    # answer = next((answer for answer in task['answer']['classifications'] if answer['schemaId'] == \"7d4d70ea16e8e5d7ce8e721\"), None)\n",
    "    # print(answer)\n",
    "    task['answer']['classifications']\n",
    "  \n",
    "  return pd.DataFrame(data,columns=[\"image\", \"sex\", \"age\",\"hair_color\",\"beard_color\",\"mustache_color\",\"eye_color\",\"glasses\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZHNIBrT228Ih"
   },
   "source": [
    "### Process the image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [],
    "id": "x94JUDiP28Ih"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import io\n",
    "import base64\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "def load_process_images(image):\n",
    "    image_decoded = base64.b64decode(image)\n",
    "    image = Image.open(io.BytesIO(image_decoded)).resize([224, 224])\n",
    "    image = img_to_array(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WOvthdW-28Ih"
   },
   "source": [
    "## Log in to Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nDqVqDaq28Ih",
    "outputId": "f587a067-b78b-4e9a-a235-851e35d43104",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import layer\n",
    "layer.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v5IWMEeg28Ih"
   },
   "source": [
    "### Initialize a Layer project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "pycharm": {
     "is_executing": true
    },
    "id": "Dd-FNc7K28Ih",
    "outputId": "6e42a284-9a6c-40b3-d105-6779b7fdd085",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [],
   "source": [
    "from layer.decorators import model, fabric\n",
    "layer.init(\"ango-face-classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rKPLZPCK28Ih"
   },
   "source": [
    "### Define the model training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [],
    "id": "ughlVXUf28Ih"
   },
   "outputs": [],
   "source": [
    "@fabric(\"f-gpu-small\")\n",
    "@model(\"face-classification\")\n",
    "def train():\n",
    "  from tensorflow import keras\n",
    "  from tensorflow.keras import Sequential\n",
    "  from tensorflow.keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,Dropout\n",
    "  from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "  from tensorflow.keras.callbacks import EarlyStopping\n",
    "  import matplotlib.pyplot as plt \n",
    "  from PIL import Image\n",
    "  import numpy as np\n",
    "  import pandas as pd\n",
    "  from sklearn.preprocessing import LabelEncoder\n",
    "  from sklearn.model_selection import train_test_split\n",
    "\n",
    "  df = build()\n",
    "  gender = df[['image','sex']]\n",
    "  labelencoder = LabelEncoder()\n",
    "  gender = gender.assign(sex = labelencoder.fit_transform(gender[\"sex\"]))\n",
    "  X = gender[['image']]\n",
    "  y = gender[['sex']]\n",
    "  X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.20, random_state=42)\n",
    "  X_train = np.stack(X_train['image'].map(load_process_images))\n",
    "  X_test = np.stack(X_test['image'].map(load_process_images))\n",
    "\n",
    "  for image in range(4):\n",
    "    PIL_image = Image.fromarray(np.uint8(X_test[image])).convert('RGB')\n",
    "    layer.log({f\"Sample face-{image}\": PIL_image})\n",
    "    \n",
    "  train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2,zoom_range=0.2, horizontal_flip=True,width_shift_range=0.1,height_shift_range=0.1)\n",
    "  train_datagen.fit(X_train)\n",
    "  training_data = train_datagen.flow(X_train, y_train, batch_size=32)\n",
    "  validation_gen = ImageDataGenerator(rescale=1./255)\n",
    "  testing_data = validation_gen.flow(X_test, y_test, batch_size=32)\n",
    "  model = Sequential([\n",
    "    Conv2D(filters=32,kernel_size=(3,3),  input_shape = (224, 224, 3),activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "\n",
    "    Conv2D(filters=32,kernel_size=(3,3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Conv2D(filters=64,kernel_size=(3,3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    Dense(3, activation='softmax')])\n",
    "  model.compile(optimizer='adam', loss=keras.losses.SparseCategoricalCrossentropy(), metrics=[keras.metrics.CategoricalAccuracy()])\n",
    "  callback = EarlyStopping(monitor='loss', patience=3)\n",
    "  epochs=2\n",
    "  history = model.fit(training_data,validation_data=testing_data, epochs=epochs,callbacks=[callback])\n",
    "  metrics_df = pd.DataFrame(history.history)\n",
    "  layer.log({\"metrics DataFrame\": metrics_df})\n",
    "  loss, accuracy = model.evaluate(testing_data)\n",
    "  layer.log({\"Testing loss\": loss})\n",
    "  layer.log({\"Testing accuracy\": accuracy})\n",
    "  print('Accuracy on test dataset:', accuracy)\n",
    "  metrics_df[[\"loss\",\"val_loss\"]].plot()\n",
    "  layer.log({\"Loss plot\": plt.gcf()})\n",
    "  training_loss, training_accuracy = model.evaluate(training_data)\n",
    "  layer.log({\"Training loss\": training_loss})\n",
    "  layer.log({\"Training accuracy\": training_accuracy})\n",
    "  metrics_df[[\"categorical_accuracy\",\"val_categorical_accuracy\"]].plot()\n",
    "  layer.log({\"Accuracy plot\": plt.gcf()})\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oeQatbZg28Ih"
   },
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [],
    "id": "VeUhXJYN28Ih"
   },
   "outputs": [],
   "source": [
    "# Train the model on your local infra\n",
    "# train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "id": "aA0bbLYy28Ih",
    "outputId": "9f8eedf3-08be-4e71-c872-d80c90cd3d89",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70,
     "referenced_widgets": [
      "ac90d429bf1f42389343aa5b19f88321",
      "f29c01d03cd24cfd923045dd445c8e9e"
     ]
    }
   },
   "outputs": [],
   "source": [
    "# Run the project on Layer Infra using remote GPUs\n",
    "layer.run([train])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mfxBCx9i28Ii"
   },
   "source": [
    "### Fetch trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "id": "_BHjJKNW28Ii",
    "outputId": "09993600-4288-468c-db7b-c754126265f8",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "referenced_widgets": [
      "009be8fe55374dcfb51fdbd02805b3d3",
      "dac7f89cba364403aabbbb91fa5a7620"
     ]
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "my_model = layer.get_model('layer/ango-face-classification/models/face-classification').get_train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JIM3wV6Y28Ii"
   },
   "source": [
    "### Run predictions on the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Ihh1Xpwf28Ii"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "id": "Z5Yt8lZQ28Ik",
    "outputId": "ae1fcbb3-a1df-4a94-95b7-07b193a831fc",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [],
   "source": [
    "!wget --no-check-certificate \\\n",
    "   https://storage.googleapis.com/ango-covid-dataset/ffhq-dataset/batch2/48312.png \\\n",
    "    -O 48312.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "jWVBJRxz28Il"
   },
   "outputs": [],
   "source": [
    "test_image = image.load_img('48312.png', target_size=(224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "xpMjFACv28Il"
   },
   "outputs": [],
   "source": [
    "test_image = image.img_to_array(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "IiZY_yTY28Il"
   },
   "outputs": [],
   "source": [
    "test_image = test_image / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "W_k3thPL28Il"
   },
   "outputs": [],
   "source": [
    "test_image = np.expand_dims(test_image, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "UA94GZtB28Il"
   },
   "outputs": [],
   "source": [
    "prediction = my_model.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "_WhEFH8s28Il",
    "outputId": "5ea1c7ca-e59a-4792-9b2a-3cc4ea798a96",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.5288901 , 0.04307812, 0.42803174], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "U0U9oML228Il",
    "outputId": "68545e50-29e3-4d60-f4f1-72c63dea6bb6",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'0 with a 39.69 percent confidence.'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "scores = tf.nn.softmax(prediction[0])\n",
    "scores = scores.numpy()\n",
    "class_names = [0,1,2]\n",
    "f\"{class_names[np.argmax(scores)]} with a { (100 * np.max(scores)).round(2) } percent confidence.\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lIcI708I28Im"
   },
   "source": [
    "## Next steps\n",
    "To learn more about using layer, you can: \n",
    "- Join our [Slack Community ](https://bit.ly/layercommunityslack)\n",
    "- Visit [Layer Examples Repo](https://github.com/layerai/examples) for more examples\n",
    "- Browse [Trending Layer Projects](https://layer.ai) on our mainpage\n",
    "- Check out [Layer Documentation](https://docs.app.layer.ai) to learn more"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "colab": {
   "name": "ango.ipynb",
   "provenance": []
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "ac90d429bf1f42389343aa5b19f88321": {
     "model_module": "@jupyter-widgets/output",
     "model_name": "OutputModel",
     "model_module_version": "1.0.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_f29c01d03cd24cfd923045dd445c8e9e",
      "msg_id": "",
      "outputs": [
       {
        "output_type": "display_data",
        "data": {
         "text/plain": "✅  face-classification  \u001B[38;2;21;127;61m━━━━━━━━━━\u001B[0m \u001B[38;2;21;127;61mDONE\u001B[0m \u001B[39m[\u001B[0m\u001B[38;2;155;155;159m0:37:34\u001B[0m\u001B[39m]\u001B[0m                                          \n    \u001B[4;38;2;161;161;169m↳ \u001B[0m\u001B]8;id=26245;https://app.layer.ai/layer/ango-face-classification/models/face-classification?v=37.2\u001B\\\u001B[4;38;2;161;161;169mhttps://app.layer.ai/layer/ango-face-classification/models/face-classification?v=37.2\u001B[0m\u001B]8;;\u001B\\ \n",
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅  face-classification  <span style=\"color: #157f3d; text-decoration-color: #157f3d\">━━━━━━━━━━</span> <span style=\"color: #157f3d; text-decoration-color: #157f3d\">DONE</span> <span style=\"color: #000000; text-decoration-color: #000000\">[</span><span style=\"color: #9b9b9f; text-decoration-color: #9b9b9f\">0:37:34</span><span style=\"color: #000000; text-decoration-color: #000000\">]</span>                                          \n    <span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">↳ </span><a href=\"https://app.layer.ai/layer/ango-face-classification/models/face-classification?v=37.2\"><span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">https://app.layer.ai/layer/ango-face-classification/models/face-classification?v=37.2</span></a> \n</pre>\n"
        },
        "metadata": {}
       }
      ]
     }
    },
    "f29c01d03cd24cfd923045dd445c8e9e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "009be8fe55374dcfb51fdbd02805b3d3": {
     "model_module": "@jupyter-widgets/output",
     "model_name": "OutputModel",
     "model_module_version": "1.0.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_dac7f89cba364403aabbbb91fa5a7620",
      "msg_id": "",
      "outputs": [
       {
        "output_type": "display_data",
        "data": {
         "text/plain": "\u001B[32m⠏\u001B[0m  face-classification  \u001B[38;2;21;127;61m━━━━━━━━━━\u001B[0m \u001B[38;2;21;127;61mLOADED\u001B[0m \u001B[39m[\u001B[0m\u001B[38;2;155;155;159m0:00:06\u001B[0m\u001B[39m]\u001B[0m \n",
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">⠏</span>  face-classification  <span style=\"color: #157f3d; text-decoration-color: #157f3d\">━━━━━━━━━━</span> <span style=\"color: #157f3d; text-decoration-color: #157f3d\">LOADED</span> <span style=\"color: #000000; text-decoration-color: #000000\">[</span><span style=\"color: #9b9b9f; text-decoration-color: #9b9b9f\">0:00:06</span><span style=\"color: #000000; text-decoration-color: #000000\">]</span> \n</pre>\n"
        },
        "metadata": {}
       }
      ]
     }
    },
    "dac7f89cba364403aabbbb91fa5a7620": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}