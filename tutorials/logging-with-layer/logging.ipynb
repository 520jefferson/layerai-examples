{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cXmolSB2_RVO"
   },
   "source": [
    "# Log everything with Layer\n",
    "\n",
    "[![Open in Layer](https://development.layer.co/assets/badge.svg)](https://app.layer.ai/layer/logging/) [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/layerai/examples/blob/main/tutorials//logging-with-layer/logging.ipynb) [![Layer Examples Github](https://badgen.net/badge/icon/github?icon=github&label)](https://github.com/layerai/examples/tree/main/tutorials/logging-with-layer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Layer allows you log your projects metadata such as model metrics, parameters, etc. In this notebook, we'll look through how you can log various items in your project with Layer. Let's start by installing Layer. "
   ],
   "metadata": {
    "id": "ROz3cD4Zmb34"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dW9DDmvb_PFT"
   },
   "outputs": [],
   "source": [
    "!pip install layer -U"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "For this illustration, we'll use the Fashion MNIST dataset to build a simple CNN model. "
   ],
   "metadata": {
    "id": "JIFXDyzxADDK"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "HBgwlVE2gP4x"
   },
   "outputs": [],
   "source": [
    "import layer\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import io\n",
    "import os\n",
    "import base64\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load Fashion Mnist train and test datasets from Layer"
   ],
   "metadata": {
    "id": "iSnBsFinAGMe"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BBXNlEOYgg1L"
   },
   "outputs": [],
   "source": [
    "mnist_train = layer.get_dataset('layer/fashion_mnist/datasets/fashion_mnist_train').to_pandas()\n",
    "mnist_test = layer.get_dataset('layer/fashion_mnist/datasets/fashion_mnist_test').to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "mnist_train.head()"
   ],
   "metadata": {
    "id": "yfcHtYyG_BDG"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "mnist_test.head()"
   ],
   "metadata": {
    "id": "1JA1KcW1_DCA"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Convert the images to a np.array for TF"
   ],
   "metadata": {
    "id": "AR60yxcHATrF"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "NbLG9uUngjwR"
   },
   "outputs": [],
   "source": [
    "def images_to_np_array(image_column):\n",
    "    return np.array([np.array(im.getdata()).reshape((im.size[1], im.size[0])) for im in image_column])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Adding Layer to your project is as simple as wrapping your functions with Layer decorators. Let's import the ones we'll be using."
   ],
   "metadata": {
    "id": "F2mFfZpvAYca"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "pjXRqbpCgnqG"
   },
   "outputs": [],
   "source": [
    "from layer.decorators import model, fabric,pip_requirements, resources"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, let's authenticate your Layer account. Click the generated link to log in or sing up. Copy and paste the code generated on the textbox on this notebook and press enter. "
   ],
   "metadata": {
    "id": "O78HGAudAwHl"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yeI3XaoUgz0q"
   },
   "outputs": [],
   "source": [
    "layer.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initialize a Layer project \n",
    "\n",
    "Layer stores all your project's metadata in a project. You create multiple projects for free. Each project can hold multiple datasets and models. Projects are created using the `init` function. "
   ],
   "metadata": {
    "id": "zrAno9lXBFN-"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PNlJSC85klHD",
    "outputId": "bdb1d82d-afce-4c5b-e2f1-9187910e7ada"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Your Layer project is here: https://app.layer.ai/layer/logging"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "layer.init(\"logging\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Logging with Layer"
   ],
   "metadata": {
    "id": "UG-ErCKp8VvE"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Some of the items you can log with Layer include: \n",
    "\n",
    "- Project description. \n",
    "- Markdown. \n",
    "- Model parameters. \n",
    "- Model training and evaluation metrics.\n",
    "- Pandas DataFrame.\n",
    "- Matplotlib charts.\n",
    "\n",
    "Logging in Layer is done inside a function wrapped with the [@model](https://docs.app.layer.ai/docs/sdk-library/model-decorator) and the [@dataset](https://docs.app.layer.ai/docs/sdk-library/dataset-decorator) decorators. The [log](https://docs.app.layer.ai/docs/sdk-library/layer-log) function is used to log everything in Layer. This function expects a dictionary. \n",
    "\n",
    "\n",
    "\n",
    "In the snippet below we use Layer to log the model parameters, description, validation metrics sample prediction DataFrame. \n",
    "\n",
    "```\n",
    " layer.log({\"Description\": \"TensorFlow MNIST project\"})\n",
    "  markdown = \"\"\"\n",
    "  # Layer supports Markdown. \n",
    "  \n",
    "  You can use it to add **some descriptions** in your model development. \n",
    "  \n",
    "  \"\"\"\n",
    "  layer.log({\"Description\":layer.Markdown(markdown)})\n",
    "  parameters = {\"shape\":28, \"activation\": \"relu\", \"classes\": 10, \"units\":12, \"optimizer\":\"adam\", \"epochs\":10,\"kernel_size\":3,\"pool_size\":2, \"dropout\":0.5}\n",
    "  layer.log(parameters)\n",
    "\n",
    "  df = pd.DataFrame(predictions, columns=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"])\n",
    "  # Log Pandas DataFrame\n",
    "  layer.log({\"Sample predictions\":df.sample(100)})\n",
    "  test_metrics = {\"Test loss\": test_loss,\"Test accuracy\":test_acc }\n",
    "  layer.log(test_metrics)\n",
    "  layer.log({\"Accuracy plot\": plt.gcf()})\n",
    "\n",
    "```"
   ],
   "metadata": {
    "id": "JG2zMCViBfNz"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "0hpIWvsbgwb_"
   },
   "outputs": [],
   "source": [
    "@pip_requirements(packages=[\"tensorflow==2.7.0\",\"keras\"])\n",
    "@fabric(\"f-gpu-small\")\n",
    "@model(\"mnist\")\n",
    "def train():\n",
    "  from tensorflow import keras\n",
    "  from tensorflow.keras import layers\n",
    "  import matplotlib.pyplot as plt\n",
    "  train_images = images_to_np_array(mnist_train.images)\n",
    "  test_images = images_to_np_array(mnist_test.images)\n",
    "  train_labels = mnist_train.labels\n",
    "  test_labels = mnist_test.labels\n",
    "  layer.log({\"Description\": \"TensorFlow MNIST project\"})\n",
    "  markdown = \"\"\"\n",
    "  # Layer supports Markdown. \n",
    "  \n",
    "  You can use it to add **some descriptions** in your model development. \n",
    "  \n",
    "  \"\"\"\n",
    "  layer.log({\"Description\":layer.Markdown(markdown)})\n",
    "  parameters = {\"shape\":28, \"activation\": \"relu\", \"classes\": 10, \"units\":12, \"optimizer\":\"adam\", \"epochs\":10,\"kernel_size\":3,\"pool_size\":2, \"dropout\":0.5}\n",
    "  layer.log(parameters)\n",
    "  # Setup the layers\n",
    "  model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(parameters[\"shape\"], parameters[\"shape\"], 1)),\n",
    "        layers.Conv2D(32, kernel_size=(parameters[\"kernel_size\"], parameters[\"kernel_size\"]), activation=parameters[\"activation\"]),\n",
    "        layers.MaxPooling2D(pool_size=(parameters[\"pool_size\"], parameters[\"pool_size\"])),\n",
    "        layers.Conv2D(64, kernel_size=(parameters[\"kernel_size\"], parameters[\"kernel_size\"]), activation=parameters[\"activation\"]),\n",
    "        layers.MaxPooling2D(pool_size=(parameters[\"pool_size\"], parameters[\"pool_size\"])),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(parameters[\"dropout\"]),\n",
    "        layers.Dense(parameters[\"classes\"], activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "    # Compile the model\n",
    "  model.compile(optimizer=parameters[\"optimizer\"],\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "  # Train it!\n",
    "  history = model.fit(x=train_images, y=train_labels,validation_data=(test_images,test_labels), epochs=parameters[\"epochs\"])\n",
    "  metrics_df = pd.DataFrame(history.history)\n",
    "  layer.log({\"Metrics DF\":metrics_df })\n",
    "  metrics_df[[\"loss\",\"val_loss\"]].plot()\n",
    "  layer.log({\"Loss plot\": plt.gcf()})\n",
    "  metrics_df[[\"accuracy\",\"val_accuracy\"]].plot()\n",
    "  layer.log({\"Accuracy plot\": plt.gcf()})\n",
    "  # And finally evaluate the accuracy\n",
    "  test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "  predictions = model.predict(test_images)\n",
    "  df = pd.DataFrame(predictions, columns=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"])\n",
    "  # Log Pandas DataFrame\n",
    "  layer.log({\"Sample predictions\":df.sample(100)})\n",
    "  test_metrics = {\"Test loss\": test_loss,\"Test accuracy\":test_acc }\n",
    "  layer.log(test_metrics)\n",
    "  return model "
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "layer.run([train])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86,
     "referenced_widgets": [
      "0d96ca000c134d388a4c2adeac22b0eb",
      "de27c289b426468da3a278f1a44735fe"
     ]
    },
    "id": "UfvxfN5A-F9M",
    "outputId": "8080924b-ddef-487e-841a-56d6245c1b3c",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "![Logging with Layer](https://files.slack.com/files-pri/T011VP38L1F-F03N9V32E86/image.png?pub_secret=a9c2cda56b)\n",
    "\n",
    "![Logging with Layer](https://files.slack.com/files-pri/T011VP38L1F-F03NVQK9TJM/image.png?pub_secret=ca7bac09b4)\n",
    "\n"
   ],
   "metadata": {
    "id": "QvaCDxLGFO87"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Log with steps"
   ],
   "metadata": {
    "id": "IIPcJ9e1-BAx"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can also use Layer to log data that involves steps. For example, in the example below we log some sample MNIST images. \n",
    "\n",
    "```\n",
    "mnist_train_sample = mnist_train[[\"images\"]].head(10)\n",
    "  for i in range(10):\n",
    "    layer.log({f\"Image {i}\": mnist_train_sample[\"images\"][i]}, step=i)\n",
    "```"
   ],
   "metadata": {
    "id": "17bbdOvvFrTH"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "@pip_requirements(packages=[\"tensorflow==2.7.0\",\"keras\"])\n",
    "@fabric(\"f-gpu-small\")\n",
    "@model(\"mnist\")\n",
    "def train():\n",
    "  from tensorflow import keras\n",
    "  from tensorflow.keras import layers\n",
    "\n",
    "  train_images = images_to_np_array(mnist_train.images)\n",
    "  test_images = images_to_np_array(mnist_test.images)\n",
    "  train_labels = mnist_train.labels\n",
    "  test_labels = mnist_test.labels\n",
    "  layer.log({\"Description\": \"TensorFlow MNIST project\"})\n",
    "  markdown = \"\"\"\n",
    "  # Layer supports Markdown. \n",
    "  \n",
    "  You can use it to add **some descriptions** in your model development.\n",
    "\n",
    "\n",
    "  In this run we'll add logging images in steps. Let's log some sample images from  \n",
    "  from the MNIST dataset. \n",
    "  \n",
    "  \"\"\"\n",
    "  layer.log({\"Description\":layer.Markdown(markdown)})\n",
    "  mnist_train_sample = mnist_train[[\"images\"]].head(10)\n",
    "  for i in range(10):\n",
    "    layer.log({f\"Image {i}\": mnist_train_sample[\"images\"][i]}, step=i)\n",
    "\n",
    "  parameters = {\"shape\":28, \"activation\": \"relu\", \"classes\": 10, \"units\":12, \"optimizer\":\"adam\", \"epochs\":10,\"kernel_size\":3,\"pool_size\":2, \"dropout\":0.5}\n",
    "  layer.log(parameters)\n",
    "  # Setup the layers\n",
    "  model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(parameters[\"shape\"], parameters[\"shape\"], 1)),\n",
    "        layers.Conv2D(32, kernel_size=(parameters[\"kernel_size\"], parameters[\"kernel_size\"]), activation=parameters[\"activation\"]),\n",
    "        layers.MaxPooling2D(pool_size=(parameters[\"pool_size\"], parameters[\"pool_size\"])),\n",
    "        layers.Conv2D(64, kernel_size=(parameters[\"kernel_size\"], parameters[\"kernel_size\"]), activation=parameters[\"activation\"]),\n",
    "        layers.MaxPooling2D(pool_size=(parameters[\"pool_size\"], parameters[\"pool_size\"])),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(parameters[\"dropout\"]),\n",
    "        layers.Dense(parameters[\"classes\"], activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "    # Compile the model\n",
    "  model.compile(optimizer=parameters[\"optimizer\"],\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "  # Train it!\n",
    "  model.fit(x=train_images, y=train_labels,validation_data=(test_images,test_labels), epochs=parameters[\"epochs\"])\n",
    "  # And finally evaluate the accuracy\n",
    "  test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "  test_metrics = {\"Test loss\": test_loss,\"Test accuracy\":test_acc }\n",
    "  predictions = model.predict(test_images)\n",
    "  df = pd.DataFrame(predictions, columns=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"])\n",
    "  # Log Pandas DataFrame\n",
    "  layer.log({\"Sample predictions\":df.sample(100)})\n",
    "  layer.log(test_metrics)\n",
    "  return model "
   ],
   "metadata": {
    "id": "VzfvjgrD-ARb"
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "layer.run([train])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86,
     "referenced_widgets": [
      "12ed54c9880d45ae900c94ac900c9b0c",
      "8116f303f49b4a6f83a51e1f362ef015"
     ]
    },
    "id": "iho5ibgq-Kr7",
    "outputId": "5a5aab34-a534-45a9-b1ef-143df177507f",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "![Log in steps](https://files.slack.com/files-pri/T011VP38L1F-F03N20QKRHV/image.png?pub_secret=717755ae0a)"
   ],
   "metadata": {
    "id": "c6ZuT-Y1FSrI"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Log using callbacks"
   ],
   "metadata": {
    "id": "LcUIvb3b8fkd"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A better use case for logging with steps is logging the perfomance of the model per epoch. For instance, you can write a custom callback to log the training and validation metrics per epoch. Here is an example of such as callback. "
   ],
   "metadata": {
    "id": "KN_5ynIcGowB"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Pkl-pM-XjaTB"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback \n",
    "class LayerCallback(Callback):\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None): \n",
    "      layer.log({\"Training accuracy over epoch\": logs[\"accuracy\"],\"Training loss over epoch\": logs[\"loss\"]}, epoch)\n",
    "      layer.log({\"Test accuracy over epoch\": logs[\"val_accuracy\"],\"Test loss over epoch\": logs[\"val_loss\"]}, epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The next step is to pass this callback to the model's `fit` function. \n",
    "```\n",
    "model.fit(x=train_images, y=train_labels, validation_data=(test_images,test_labels),epochs=parameters[\"epochs\"], callbacks=[LayerCallback()])\n",
    "\n",
    "```"
   ],
   "metadata": {
    "id": "Ov4yTqx2HcI5"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "G3yMFmvGilrE"
   },
   "outputs": [],
   "source": [
    "@fabric(\"f-gpu-small\")\n",
    "@pip_requirements(packages=[\"tensorflow==2.7.0\",\"keras\"])\n",
    "@model(\"mnist\")\n",
    "def train():\n",
    "  from tensorflow import keras\n",
    "  from tensorflow.keras import layers\n",
    "\n",
    "  train_images = images_to_np_array(mnist_train.images)\n",
    "  test_images = images_to_np_array(mnist_test.images)\n",
    "  train_labels = mnist_train.labels\n",
    "  test_labels = mnist_test.labels\n",
    "  layer.log({\"Description\": \"TensorFlow MNIST project\"})\n",
    "  markdown = \"\"\"\n",
    "  # Layer supports Markdown. \n",
    "  \n",
    "  You can use it to add **some descriptions** in your model development.\n",
    "\n",
    "\n",
    "  In this run we'll add logging images in steps. Let's log some sample images from  \n",
    "  from the MNIST dataset. \n",
    "  \n",
    "  \"\"\"\n",
    "  layer.log({\"Description\":layer.Markdown(markdown)})\n",
    "  mnist_train_sample = mnist_train[[\"images\"]].head(10)\n",
    "  for i in range(10):\n",
    "    layer.log({f\"Image {i}\": mnist_train_sample[\"images\"][i]}, step=i)\n",
    "\n",
    "  parameters = {\"shape\":28, \"activation\": \"relu\", \"classes\": 10, \"units\":12, \"optimizer\":\"adam\", \"epochs\":10,\"kernel_size\":3,\"pool_size\":2, \"dropout\":0.5}\n",
    "  layer.log(parameters)\n",
    "  # Setup the layers\n",
    "  model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(parameters[\"shape\"], parameters[\"shape\"], 1)),\n",
    "        layers.Conv2D(32, kernel_size=(parameters[\"kernel_size\"], parameters[\"kernel_size\"]), activation=parameters[\"activation\"]),\n",
    "        layers.MaxPooling2D(pool_size=(parameters[\"pool_size\"], parameters[\"pool_size\"])),\n",
    "        layers.Conv2D(64, kernel_size=(parameters[\"kernel_size\"], parameters[\"kernel_size\"]), activation=parameters[\"activation\"]),\n",
    "        layers.MaxPooling2D(pool_size=(parameters[\"pool_size\"], parameters[\"pool_size\"])),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(parameters[\"dropout\"]),\n",
    "        layers.Dense(parameters[\"classes\"], activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "    # Compile the model\n",
    "  model.compile(optimizer=parameters[\"optimizer\"],\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "  # Train it!\n",
    "  model.fit(x=train_images, y=train_labels, validation_data=(test_images,test_labels),epochs=parameters[\"epochs\"], callbacks=[LayerCallback()])\n",
    "  # And finally evaluate the accuracy\n",
    "  test_loss, test_acc = model.evaluate(test_images,  test_labels)\n",
    "  test_metrics = {\"Test loss\": test_loss,\"Test accuracy\":test_acc }\n",
    "  predictions = model.predict(test_images)\n",
    "  df = pd.DataFrame(predictions, columns=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"])\n",
    "  # Log Pandas DataFrame\n",
    "  layer.log({\"Sample predictions\":df.sample(100)})\n",
    "  layer.log(test_metrics)\n",
    "  return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86,
     "referenced_widgets": [
      "d1553307fba043f29a9a480dc7fd68e3",
      "bf18c0f074d844b691b54d1b5a388a71"
     ]
    },
    "id": "WmYBDt73kR9S",
    "outputId": "7f0b49f5-fdc9-49fb-ab03-c230b45480f7",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "layer.run([train])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "![Using callbacks](https://files.slack.com/files-pri/T011VP38L1F-F03NK1RJQKW/ezgif.com-gif-maker.gif?pub_secret=dbae18146c)"
   ],
   "metadata": {
    "id": "rJyyjl19FVCL"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Log interactive apps"
   ],
   "metadata": {
    "id": "-9MY5M0Clsis"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can log interactive [Gradio](https://gradio.app/) and [Streamlit](https://streamlit.io/) applications with Layer. Applications are logged by passing the [Hugging Face space link](https://huggingface.co/docs/hub/spaces) to the log function as Markdown. The syntax looks like this: \n",
    "```\n",
    "layer.log({\"demo\":layer.Markdown(\"<iframe width='100%', height='522px' src='https://hf.space/embed/mecevit/english-to-sql/+'></iframe>\")})\n",
    "```"
   ],
   "metadata": {
    "id": "8ZxfpqxFH0-n"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "@fabric(\"f-gpu-small\")\n",
    "@pip_requirements(packages=[\"tensorflow==2.7.0\",\"keras\"])\n",
    "@model(\"mnist\")\n",
    "def train():\n",
    "  from tensorflow import keras\n",
    "  from tensorflow.keras import layers\n",
    "\n",
    "  train_images = images_to_np_array(mnist_train.images)\n",
    "  test_images = images_to_np_array(mnist_test.images)\n",
    "  train_labels = mnist_train.labels\n",
    "  test_labels = mnist_test.labels\n",
    "  layer.log({\"Description\": \"TensorFlow MNIST project\"})\n",
    "  markdown = \"\"\"\n",
    "  # Layer supports Markdown. \n",
    "  \n",
    "  You can use it to add **some descriptions** in your model development.\n",
    "\n",
    "\n",
    "  In this run we'll add logging images in steps. Let's log some sample images from  \n",
    "  from the MNIST dataset. \n",
    "  \n",
    "  \"\"\"\n",
    "  layer.log({\"Description\":layer.Markdown(markdown)})\n",
    "  mnist_train_sample = mnist_train[[\"images\"]].head(10)\n",
    "  for i in range(10):\n",
    "    layer.log({f\"Image {i}\": mnist_train_sample[\"images\"][i]}, step=i)\n",
    "\n",
    "  parameters = {\"shape\":28, \"activation\": \"relu\", \"classes\": 10, \"units\":12, \"optimizer\":\"adam\", \"epochs\":10,\"kernel_size\":3,\"pool_size\":2, \"dropout\":0.5}\n",
    "  layer.log(parameters)\n",
    "  # Setup the layers\n",
    "  model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(parameters[\"shape\"], parameters[\"shape\"], 1)),\n",
    "        layers.Conv2D(32, kernel_size=(parameters[\"kernel_size\"], parameters[\"kernel_size\"]), activation=parameters[\"activation\"]),\n",
    "        layers.MaxPooling2D(pool_size=(parameters[\"pool_size\"], parameters[\"pool_size\"])),\n",
    "        layers.Conv2D(64, kernel_size=(parameters[\"kernel_size\"], parameters[\"kernel_size\"]), activation=parameters[\"activation\"]),\n",
    "        layers.MaxPooling2D(pool_size=(parameters[\"pool_size\"], parameters[\"pool_size\"])),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(parameters[\"dropout\"]),\n",
    "        layers.Dense(parameters[\"classes\"], activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "    # Compile the model\n",
    "  model.compile(optimizer=parameters[\"optimizer\"],\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "  # Train it!\n",
    "  model.fit(x=train_images, y=train_labels,validation_data=(test_images,test_labels), epochs=parameters[\"epochs\"])\n",
    "  # And finally evaluate the accuracy\n",
    "  test_loss, test_acc = model.evaluate(test_images,  test_labels)\n",
    "  test_metrics = {\"Test loss\": test_loss,\"Test accuracy\":test_acc }\n",
    "  predictions = model.predict(test_images)\n",
    "  df = pd.DataFrame(predictions, columns=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"])\n",
    "  # Log Pandas DataFrame\n",
    "  layer.log({\"Sample predictions\":df.sample(100)})\n",
    "  layer.log(test_metrics)\n",
    "  layer.log({\"demo\":layer.Markdown(\"<iframe width='100%', height='522px' src='https://hf.space/embed/mecevit/english-to-sql/+'></iframe>\")})\n",
    "  return model "
   ],
   "metadata": {
    "id": "XRzzidcQ7lKX"
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "layer.run([train])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86,
     "referenced_widgets": [
      "686c1327538849dfaf312b29e5d46d1a",
      "7f1aced83ac04da2ba12b0749b559fe0"
     ]
    },
    "id": "K14jwbhJ4Voc",
    "outputId": "69145f72-fc14-4c9b-f8c5-0241994ecf26",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "![Gradio Demo](https://files.slack.com/files-pri/T011VP38L1F-F03NA1RAGBY/ezgif.com-gif-maker__1_.gif?pub_secret=5e7d9ef214)"
   ],
   "metadata": {
    "id": "LiTP5F6_FYCa"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Log videos and GIFs"
   ],
   "metadata": {
    "id": "faUeCQQpniB-"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Layer supports logging of videos and GIFs. This can come in handy to show \n",
    "short demos. In the example below, we use the [@resources](https://docs.app.layer.ai/docs/sdk-library/resources-decorator) decorator to upload a video and a GIF to Layer then use `layer.log` to log them.\n",
    "```\n",
    "layer.log({\"GIF\": Image.open(\"video.gif\")})\n",
    "video_path = Path(\"video.mp4\")\n",
    "```"
   ],
   "metadata": {
    "id": "waowIUY8Y138"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "@fabric(\"f-gpu-small\")\n",
    "@pip_requirements(packages=[\"tensorflow==2.7.0\",\"keras\"])\n",
    "@resources(\"video.gif\", \"video.mp4\")\n",
    "@model(\"mnist\")\n",
    "def train():\n",
    "  from tensorflow import keras\n",
    "  from tensorflow.keras import layers\n",
    "  from pathlib import Path\n",
    "\n",
    "  train_images = images_to_np_array(mnist_train.images)\n",
    "  test_images = images_to_np_array(mnist_test.images)\n",
    "  train_labels = mnist_train.labels\n",
    "  test_labels = mnist_test.labels\n",
    "  layer.log({\"Description\": \"TensorFlow MNIST project\"})\n",
    "  markdown = \"\"\"\n",
    "  # Layer supports Markdown. \n",
    "  \n",
    "  You can use it to add **some descriptions** in your model development.\n",
    "\n",
    "\n",
    "  In this run we'll add logging images in steps. Let's log some sample images from  \n",
    "  from the MNIST dataset. \n",
    "  \n",
    "  \"\"\"\n",
    "  layer.log({\"Description\":layer.Markdown(markdown)})\n",
    "  mnist_train_sample = mnist_train[[\"images\"]].head(10)\n",
    "  for i in range(10):\n",
    "    layer.log({f\"Image {i}\": mnist_train_sample[\"images\"][i]}, step=i)\n",
    "\n",
    "  parameters = {\"shape\":28, \"activation\": \"relu\", \"classes\": 10, \"units\":12, \"optimizer\":\"adam\", \"epochs\":10,\"kernel_size\":3,\"pool_size\":2, \"dropout\":0.5}\n",
    "  layer.log(parameters)\n",
    "  # Setup the layers\n",
    "  model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(parameters[\"shape\"], parameters[\"shape\"], 1)),\n",
    "        layers.Conv2D(32, kernel_size=(parameters[\"kernel_size\"], parameters[\"kernel_size\"]), activation=parameters[\"activation\"]),\n",
    "        layers.MaxPooling2D(pool_size=(parameters[\"pool_size\"], parameters[\"pool_size\"])),\n",
    "        layers.Conv2D(64, kernel_size=(parameters[\"kernel_size\"], parameters[\"kernel_size\"]), activation=parameters[\"activation\"]),\n",
    "        layers.MaxPooling2D(pool_size=(parameters[\"pool_size\"], parameters[\"pool_size\"])),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(parameters[\"dropout\"]),\n",
    "        layers.Dense(parameters[\"classes\"], activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "    # Compile the model\n",
    "  model.compile(optimizer=parameters[\"optimizer\"],\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "  # Train it!\n",
    "  model.fit(x=train_images, y=train_labels,validation_data=(test_images,test_labels), epochs=parameters[\"epochs\"])\n",
    "  # And finally evaluate the accuracy\n",
    "  test_loss, test_acc = model.evaluate(test_images,  test_labels)\n",
    "  test_metrics = {\"Test loss\": test_loss,\"Test accuracy\":test_acc }\n",
    "  predictions = model.predict(test_images)\n",
    "  df = pd.DataFrame(predictions, columns=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"])\n",
    "  layer.log({\"Sample predictions\":df.sample(100)})\n",
    "  layer.log(test_metrics)\n",
    "  layer.log({\"GIF\": Path(f\"{os.getcwd()}/video.gif\")})\n",
    "  video_path = Path(\"video.mp4\")\n",
    "  layer.log({\"Video\": video_path})\n",
    "  return model "
   ],
   "metadata": {
    "id": "87UhKqOJnmuR"
   },
   "execution_count": 38,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "layer.run([train])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86,
     "referenced_widgets": [
      "87ba8f0199af484fafa1df5430a7f1ff",
      "f651c8bdf7e54ce18a0a349009cd7639"
     ]
    },
    "id": "ch30YneGFcqG",
    "outputId": "084d7d4b-aa81-493d-b4a6-8c1841185712",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "![Log video images](https://files.slack.com/files-pri/T011VP38L1F-F03NAG4FCSJ/ezgif.com-gif-maker.gif?pub_secret=61c1d592eb)"
   ],
   "metadata": {
    "id": "ZkJ3z92RFZ-a"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Where to go from here"
   ],
   "metadata": {
    "id": "01OcRVSRl-9o"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To learn more about using layer, you can: \n",
    "- Join our [Slack Community ](https://bit.ly/layercommunityslack)\n",
    "- Visit [Layer Examples Repo](https://github.com/layerai/examples) for more examples\n",
    "- Browse [Trending Layer Projects](https://layer.ai) on our mainpage\n",
    "- Check out [Layer Documentation](https://docs.app.layer.ai) to learn more"
   ],
   "metadata": {
    "id": "NSKfadABJR0Z"
   }
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "layer log notebook.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0d96ca000c134d388a4c2adeac22b0eb": {
     "model_module": "@jupyter-widgets/output",
     "model_name": "OutputModel",
     "model_module_version": "1.0.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_de27c289b426468da3a278f1a44735fe",
      "msg_id": "",
      "outputs": [
       {
        "output_type": "display_data",
        "data": {
         "text/plain": "\u001B[32m⠹\u001B[0m  mnist                \u001B[38;2;0;0;0m━━━━━━━━━\u001B[0m\u001B[38;2;0;0;0m╸\u001B[0m \u001B[38;2;155;155;159mTRAINING\u001B[0m \u001B[39m[\u001B[0m\u001B[38;2;155;155;159m0:02:33\u001B[0m\u001B[39m]\u001B[0m \n   \u001B[4;38;2;161;161;169m↳ \u001B[0m\u001B]8;id=22964;https://app.layer.ai/layer/logging/models/mnist\u001B\\\u001B[4;38;2;161;161;169mhttps://app.layer.ai/layer/logging/models/mnist\u001B[0m\u001B]8;;\u001B\\  \n",
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">⠹</span>  mnist                <span style=\"color: #000000; text-decoration-color: #000000\">━━━━━━━━━╸</span> <span style=\"color: #9b9b9f; text-decoration-color: #9b9b9f\">TRAINING</span> <span style=\"color: #000000; text-decoration-color: #000000\">[</span><span style=\"color: #9b9b9f; text-decoration-color: #9b9b9f\">0:02:33</span><span style=\"color: #000000; text-decoration-color: #000000\">]</span> \n   <span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">↳ </span><a href=\"https://app.layer.ai/layer/logging/models/mnist\" target=\"_blank\"><span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">https://app.layer.ai/layer/logging/models/mnist</span></a>  \n</pre>\n"
        },
        "metadata": {}
       }
      ]
     }
    },
    "de27c289b426468da3a278f1a44735fe": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "12ed54c9880d45ae900c94ac900c9b0c": {
     "model_module": "@jupyter-widgets/output",
     "model_name": "OutputModel",
     "model_module_version": "1.0.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_8116f303f49b4a6f83a51e1f362ef015",
      "msg_id": "",
      "outputs": [
       {
        "output_type": "display_data",
        "data": {
         "text/plain": "\u001B[32m⠇\u001B[0m  mnist                \u001B[38;2;0;0;0m━━━━\u001B[0m\u001B[39m╺\u001B[0m\u001B[39m━━━━━\u001B[0m \u001B[38;2;155;155;159mTRAINING\u001B[0m \u001B[39m[\u001B[0m\u001B[38;2;155;155;159m0:03:33\u001B[0m\u001B[39m]\u001B[0m \n   \u001B[4;38;2;161;161;169m↳ \u001B[0m\u001B]8;id=73877;https://app.layer.ai/layer/logging/models/mnist\u001B\\\u001B[4;38;2;161;161;169mhttps://app.layer.ai/layer/logging/models/mnist\u001B[0m\u001B]8;;\u001B\\  \n",
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">⠇</span>  mnist                <span style=\"color: #000000; text-decoration-color: #000000\">━━━━</span><span style=\"color: #000000; text-decoration-color: #000000\">╺━━━━━</span> <span style=\"color: #9b9b9f; text-decoration-color: #9b9b9f\">TRAINING</span> <span style=\"color: #000000; text-decoration-color: #000000\">[</span><span style=\"color: #9b9b9f; text-decoration-color: #9b9b9f\">0:03:33</span><span style=\"color: #000000; text-decoration-color: #000000\">]</span> \n   <span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">↳ </span><a href=\"https://app.layer.ai/layer/logging/models/mnist\" target=\"_blank\"><span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">https://app.layer.ai/layer/logging/models/mnist</span></a>  \n</pre>\n"
        },
        "metadata": {}
       }
      ]
     }
    },
    "8116f303f49b4a6f83a51e1f362ef015": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d1553307fba043f29a9a480dc7fd68e3": {
     "model_module": "@jupyter-widgets/output",
     "model_name": "OutputModel",
     "model_module_version": "1.0.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_bf18c0f074d844b691b54d1b5a388a71",
      "msg_id": "",
      "outputs": [
       {
        "output_type": "display_data",
        "data": {
         "text/plain": "\u001B[32m⠦\u001B[0m  mnist                \u001B[38;2;0;0;0m━\u001B[0m\u001B[38;2;0;0;0m╸\u001B[0m\u001B[39m━━━━━━━━\u001B[0m \u001B[38;2;155;155;159mTRAINING\u001B[0m \u001B[39m[\u001B[0m\u001B[38;2;155;155;159m0:02:33\u001B[0m\u001B[39m]\u001B[0m \n   \u001B[4;38;2;161;161;169m↳ \u001B[0m\u001B]8;id=256840;https://app.layer.ai/layer/logging/models/mnist\u001B\\\u001B[4;38;2;161;161;169mhttps://app.layer.ai/layer/logging/models/mnist\u001B[0m\u001B]8;;\u001B\\  \n",
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">⠦</span>  mnist                <span style=\"color: #000000; text-decoration-color: #000000\">━╸</span><span style=\"color: #000000; text-decoration-color: #000000\">━━━━━━━━</span> <span style=\"color: #9b9b9f; text-decoration-color: #9b9b9f\">TRAINING</span> <span style=\"color: #000000; text-decoration-color: #000000\">[</span><span style=\"color: #9b9b9f; text-decoration-color: #9b9b9f\">0:02:33</span><span style=\"color: #000000; text-decoration-color: #000000\">]</span> \n   <span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">↳ </span><a href=\"https://app.layer.ai/layer/logging/models/mnist\" target=\"_blank\"><span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">https://app.layer.ai/layer/logging/models/mnist</span></a>  \n</pre>\n"
        },
        "metadata": {}
       }
      ]
     }
    },
    "bf18c0f074d844b691b54d1b5a388a71": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "686c1327538849dfaf312b29e5d46d1a": {
     "model_module": "@jupyter-widgets/output",
     "model_name": "OutputModel",
     "model_module_version": "1.0.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_7f1aced83ac04da2ba12b0749b559fe0",
      "msg_id": "",
      "outputs": [
       {
        "output_type": "display_data",
        "data": {
         "text/plain": "\u001B[32m⠧\u001B[0m  mnist                \u001B[38;2;0;0;0m━\u001B[0m\u001B[39m╺\u001B[0m\u001B[39m━━━━━━━━\u001B[0m \u001B[38;2;155;155;159mTRAINING\u001B[0m \u001B[39m[\u001B[0m\u001B[38;2;155;155;159m0:02:33\u001B[0m\u001B[39m]\u001B[0m \n   \u001B[4;38;2;161;161;169m↳ \u001B[0m\u001B]8;id=886652;https://app.layer.ai/layer/logging/models/mnist\u001B\\\u001B[4;38;2;161;161;169mhttps://app.layer.ai/layer/logging/models/mnist\u001B[0m\u001B]8;;\u001B\\  \n",
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">⠧</span>  mnist                <span style=\"color: #000000; text-decoration-color: #000000\">━</span><span style=\"color: #000000; text-decoration-color: #000000\">╺━━━━━━━━</span> <span style=\"color: #9b9b9f; text-decoration-color: #9b9b9f\">TRAINING</span> <span style=\"color: #000000; text-decoration-color: #000000\">[</span><span style=\"color: #9b9b9f; text-decoration-color: #9b9b9f\">0:02:33</span><span style=\"color: #000000; text-decoration-color: #000000\">]</span> \n   <span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">↳ </span><a href=\"https://app.layer.ai/layer/logging/models/mnist\" target=\"_blank\"><span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">https://app.layer.ai/layer/logging/models/mnist</span></a>  \n</pre>\n"
        },
        "metadata": {}
       }
      ]
     }
    },
    "7f1aced83ac04da2ba12b0749b559fe0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "87ba8f0199af484fafa1df5430a7f1ff": {
     "model_module": "@jupyter-widgets/output",
     "model_name": "OutputModel",
     "model_module_version": "1.0.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_f651c8bdf7e54ce18a0a349009cd7639",
      "msg_id": "",
      "outputs": [
       {
        "output_type": "display_data",
        "data": {
         "text/plain": "\u001B[32m⠹\u001B[0m  mnist                \u001B[38;2;0;0;0m━━━━━━━━\u001B[0m\u001B[38;2;0;0;0m╸\u001B[0m\u001B[39m━\u001B[0m \u001B[38;2;155;155;159mTRAINING\u001B[0m \u001B[39m[\u001B[0m\u001B[38;2;155;155;159m0:11:33\u001B[0m\u001B[39m]\u001B[0m \n   \u001B[4;38;2;161;161;169m↳ \u001B[0m\u001B]8;id=427476;https://app.layer.ai/layer/logging/models/mnist\u001B\\\u001B[4;38;2;161;161;169mhttps://app.layer.ai/layer/logging/models/mnist\u001B[0m\u001B]8;;\u001B\\  \n",
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">⠹</span>  mnist                <span style=\"color: #000000; text-decoration-color: #000000\">━━━━━━━━╸</span><span style=\"color: #000000; text-decoration-color: #000000\">━</span> <span style=\"color: #9b9b9f; text-decoration-color: #9b9b9f\">TRAINING</span> <span style=\"color: #000000; text-decoration-color: #000000\">[</span><span style=\"color: #9b9b9f; text-decoration-color: #9b9b9f\">0:11:33</span><span style=\"color: #000000; text-decoration-color: #000000\">]</span> \n   <span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">↳ </span><a href=\"https://app.layer.ai/layer/logging/models/mnist\" target=\"_blank\"><span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">https://app.layer.ai/layer/logging/models/mnist</span></a>  \n</pre>\n"
        },
        "metadata": {}
       }
      ]
     }
    },
    "f651c8bdf7e54ce18a0a349009cd7639": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}