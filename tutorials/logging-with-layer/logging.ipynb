{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cXmolSB2_RVO"
   },
   "source": [
    "# Log everything with Layer\n",
    "\n",
    "[![Open in Layer](https://development.layer.co/assets/badge.svg)](https://app.layer.ai/layer/logging/) [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/layerai/examples/blob/main/tutorials//logging-with-layer/logging.ipynb) [![Layer Examples Github](https://badgen.net/badge/icon/github?icon=github&label)](https://github.com/layerai/examples/tree/main/tutorials/logging-with-layer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Layer allows you log your projects metadata such as model metrics, parameters, etc. In this notebook, we'll look through how you can log various items in your project with Layer. Let's start by installing Layer. "
   ],
   "metadata": {
    "id": "ROz3cD4Zmb34"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dW9DDmvb_PFT"
   },
   "outputs": [],
   "source": [
    "!pip install layer -U"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "For this illustration, we'll use the Fashion MNIST dataset to build a simple CNN model. "
   ],
   "metadata": {
    "id": "JIFXDyzxADDK"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "HBgwlVE2gP4x"
   },
   "outputs": [],
   "source": [
    "import layer\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load Fashion Mnist train and test datasets from Layer"
   ],
   "metadata": {
    "id": "iSnBsFinAGMe"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BBXNlEOYgg1L"
   },
   "outputs": [],
   "source": [
    "mnist_train = layer.get_dataset('layer/fashion_mnist/datasets/fashion_mnist_train').to_pandas()\n",
    "mnist_test = layer.get_dataset('layer/fashion_mnist/datasets/fashion_mnist_test').to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "mnist_train.head()"
   ],
   "metadata": {
    "id": "yfcHtYyG_BDG"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "mnist_test.head()"
   ],
   "metadata": {
    "id": "1JA1KcW1_DCA"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Convert the images to a np.array for TF"
   ],
   "metadata": {
    "id": "AR60yxcHATrF"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "NbLG9uUngjwR"
   },
   "outputs": [],
   "source": [
    "def images_to_np_array(image_column):\n",
    "    return np.array([np.array(im.getdata()).reshape((im.size[1], im.size[0])) for im in image_column])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Adding Layer to your project is as simple as wrapping your functions with Layer decorators. Let's import the ones we'll be using."
   ],
   "metadata": {
    "id": "F2mFfZpvAYca"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "pjXRqbpCgnqG"
   },
   "outputs": [],
   "source": [
    "from layer.decorators import model, fabric,pip_requirements, resources"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, let's authenticate your Layer account. Click the generated link to log in or sing up. Copy and paste the code generated on the textbox on this notebook and press enter. "
   ],
   "metadata": {
    "id": "O78HGAudAwHl"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "yeI3XaoUgz0q"
   },
   "outputs": [],
   "source": [
    "layer.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initialize a Layer project \n",
    "\n",
    "Layer stores all your project's metadata in a project. You create multiple projects for free. Each project can hold multiple datasets and models. Projects are created using the `init` function. "
   ],
   "metadata": {
    "id": "zrAno9lXBFN-"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PNlJSC85klHD"
   },
   "outputs": [],
   "source": [
    "layer.init(\"logging\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Logging with Layer"
   ],
   "metadata": {
    "id": "UG-ErCKp8VvE"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Some of the items you can log with Layer include: \n",
    "\n",
    "- Project description. \n",
    "- Markdown. \n",
    "- Model parameters. \n",
    "- Model training and evaluation metrics.\n",
    "- Pandas DataFrame.\n",
    "- Matplotlib charts.\n",
    "\n",
    "Logging in Layer is done inside a function wrapped with the [@model](https://docs.app.layer.ai/docs/sdk-library/model-decorator) and the [@dataset](https://docs.app.layer.ai/docs/sdk-library/dataset-decorator) decorators. The [log](https://docs.app.layer.ai/docs/sdk-library/layer-log) function is used to log everything in Layer. This function expects a dictionary. \n",
    "\n",
    "\n",
    "\n",
    "In the snippet below we use Layer to log the model parameters, description, validation metrics sample prediction DataFrame. \n",
    "\n",
    "```\n",
    " layer.log({\"Description\": \"TensorFlow MNIST project\"})\n",
    "  markdown = \"\"\"\n",
    "  # Layer supports Markdown. \n",
    "  \n",
    "  You can use it to add **some descriptions** in your model development. \n",
    "  \n",
    "  \"\"\"\n",
    "  layer.log({\"Description\":layer.Markdown(markdown)})\n",
    "  parameters = {\"shape\":28, \"activation\": \"relu\", \"classes\": 10, \"units\":12, \"optimizer\":\"adam\", \"epochs\":10,\"kernel_size\":3,\"pool_size\":2, \"dropout\":0.5}\n",
    "  layer.log(parameters)\n",
    "\n",
    "  df = pd.DataFrame(predictions, columns=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"])\n",
    "  # Log Pandas DataFrame\n",
    "  layer.log({\"Sample predictions\":df.sample(100)})\n",
    "  test_metrics = {\"Test loss\": test_loss,\"Test accuracy\":test_acc }\n",
    "  layer.log(test_metrics)\n",
    "  layer.log({\"Accuracy plot\": plt.gcf()})\n",
    "\n",
    "```"
   ],
   "metadata": {
    "id": "JG2zMCViBfNz"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "0hpIWvsbgwb_"
   },
   "outputs": [],
   "source": [
    "@pip_requirements(packages=[\"tensorflow==2.7.0\",\"keras\"])\n",
    "@fabric(\"f-gpu-small\")\n",
    "@model(\"mnist\")\n",
    "def train():\n",
    "  from tensorflow import keras\n",
    "  from tensorflow.keras import layers\n",
    "  import matplotlib.pyplot as plt\n",
    "  train_images = images_to_np_array(mnist_train.images)\n",
    "  test_images = images_to_np_array(mnist_test.images)\n",
    "  train_labels = mnist_train.labels\n",
    "  test_labels = mnist_test.labels\n",
    "  layer.log({\"Description\": \"TensorFlow MNIST project\"})\n",
    "  markdown = \"\"\"\n",
    "  # Layer supports Markdown. \n",
    "  \n",
    "  You can use it to add **some descriptions** in your model development. \n",
    "  \n",
    "  \"\"\"\n",
    "  layer.log({\"Description\":layer.Markdown(markdown)})\n",
    "  parameters = {\"shape\":28, \"activation\": \"relu\", \"classes\": 10, \"units\":12, \"optimizer\":\"adam\", \"epochs\":10,\"kernel_size\":3,\"pool_size\":2, \"dropout\":0.5}\n",
    "  layer.log(parameters)\n",
    "  # Setup the layers\n",
    "  model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(parameters[\"shape\"], parameters[\"shape\"], 1)),\n",
    "        layers.Conv2D(32, kernel_size=(parameters[\"kernel_size\"], parameters[\"kernel_size\"]), activation=parameters[\"activation\"]),\n",
    "        layers.MaxPooling2D(pool_size=(parameters[\"pool_size\"], parameters[\"pool_size\"])),\n",
    "        layers.Conv2D(64, kernel_size=(parameters[\"kernel_size\"], parameters[\"kernel_size\"]), activation=parameters[\"activation\"]),\n",
    "        layers.MaxPooling2D(pool_size=(parameters[\"pool_size\"], parameters[\"pool_size\"])),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(parameters[\"dropout\"]),\n",
    "        layers.Dense(parameters[\"classes\"], activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "    # Compile the model\n",
    "  model.compile(optimizer=parameters[\"optimizer\"],\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "  # Train it!\n",
    "  history = model.fit(x=train_images, y=train_labels,validation_data=(test_images,test_labels), epochs=parameters[\"epochs\"])\n",
    "  metrics_df = pd.DataFrame(history.history)\n",
    "  layer.log({\"Metrics DF\":metrics_df })\n",
    "  metrics_df[[\"loss\",\"val_loss\"]].plot()\n",
    "  layer.log({\"Loss plot\": plt.gcf()})\n",
    "  metrics_df[[\"accuracy\",\"val_accuracy\"]].plot()\n",
    "  layer.log({\"Accuracy plot\": plt.gcf()})\n",
    "  # And finally evaluate the accuracy\n",
    "  test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "  predictions = model.predict(test_images)\n",
    "  df = pd.DataFrame(predictions, columns=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"])\n",
    "  # Log Pandas DataFrame\n",
    "  layer.log({\"Sample predictions\":df.sample(100)})\n",
    "  test_metrics = {\"Test loss\": test_loss,\"Test accuracy\":test_acc }\n",
    "  layer.log(test_metrics)\n",
    "  return model "
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "layer.run([train])"
   ],
   "metadata": {
    "id": "PzA7frxfHe9m"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "![Logging with Layer](https://files.slack.com/files-pri/T011VP38L1F-F03N9V32E86/image.png?pub_secret=a9c2cda56b)\n",
    "\n",
    "![Logging with Layer](https://files.slack.com/files-pri/T011VP38L1F-F03NVQK9TJM/image.png?pub_secret=ca7bac09b4)\n",
    "\n"
   ],
   "metadata": {
    "id": "QvaCDxLGFO87"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Log with steps"
   ],
   "metadata": {
    "id": "IIPcJ9e1-BAx"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can also use Layer to log data that involves steps. For example, in the example below we log some sample MNIST images. \n",
    "\n",
    "```\n",
    "mnist_train_sample = mnist_train[[\"images\"]].head(10)\n",
    "  for i in range(10):\n",
    "    layer.log({f\"Image {i}\": mnist_train_sample[\"images\"][i]}, step=i)\n",
    "```"
   ],
   "metadata": {
    "id": "17bbdOvvFrTH"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "@pip_requirements(packages=[\"tensorflow==2.7.0\",\"keras\"])\n",
    "@fabric(\"f-gpu-small\")\n",
    "@model(\"mnist\")\n",
    "def train():\n",
    "  from tensorflow import keras\n",
    "  from tensorflow.keras import layers\n",
    "\n",
    "  train_images = images_to_np_array(mnist_train.images)\n",
    "  test_images = images_to_np_array(mnist_test.images)\n",
    "  train_labels = mnist_train.labels\n",
    "  test_labels = mnist_test.labels\n",
    "  layer.log({\"Description\": \"TensorFlow MNIST project\"})\n",
    "  markdown = \"\"\"\n",
    "  # Layer supports Markdown. \n",
    "  \n",
    "  You can use it to add **some descriptions** in your model development.\n",
    "\n",
    "\n",
    "  In this run we'll add logging images in steps. Let's log some sample images from  \n",
    "  from the MNIST dataset. \n",
    "  \n",
    "  \"\"\"\n",
    "  layer.log({\"Description\":layer.Markdown(markdown)})\n",
    "  mnist_train_sample = mnist_train[[\"images\"]].head(10)\n",
    "  for i in range(10):\n",
    "    layer.log({f\"Image\": mnist_train_sample[\"images\"][i]}, step=i)\n",
    "\n",
    "  parameters = {\"shape\":28, \"activation\": \"relu\", \"classes\": 10, \"units\":12, \"optimizer\":\"adam\", \"epochs\":10,\"kernel_size\":3,\"pool_size\":2, \"dropout\":0.5}\n",
    "  layer.log(parameters)\n",
    "  # Setup the layers\n",
    "  model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(parameters[\"shape\"], parameters[\"shape\"], 1)),\n",
    "        layers.Conv2D(32, kernel_size=(parameters[\"kernel_size\"], parameters[\"kernel_size\"]), activation=parameters[\"activation\"]),\n",
    "        layers.MaxPooling2D(pool_size=(parameters[\"pool_size\"], parameters[\"pool_size\"])),\n",
    "        layers.Conv2D(64, kernel_size=(parameters[\"kernel_size\"], parameters[\"kernel_size\"]), activation=parameters[\"activation\"]),\n",
    "        layers.MaxPooling2D(pool_size=(parameters[\"pool_size\"], parameters[\"pool_size\"])),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(parameters[\"dropout\"]),\n",
    "        layers.Dense(parameters[\"classes\"], activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "    # Compile the model\n",
    "  model.compile(optimizer=parameters[\"optimizer\"],\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "  # Train it!\n",
    "  model.fit(x=train_images, y=train_labels,validation_data=(test_images,test_labels), epochs=parameters[\"epochs\"])\n",
    "  # And finally evaluate the accuracy\n",
    "  test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "  test_metrics = {\"Test loss\": test_loss,\"Test accuracy\":test_acc }\n",
    "  predictions = model.predict(test_images)\n",
    "  df = pd.DataFrame(predictions, columns=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"])\n",
    "  # Log Pandas DataFrame\n",
    "  layer.log({\"Sample predictions\":df.sample(100)})\n",
    "  layer.log(test_metrics)\n",
    "  return model "
   ],
   "metadata": {
    "id": "VzfvjgrD-ARb"
   },
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "layer.run([train])"
   ],
   "metadata": {
    "id": "iho5ibgq-Kr7",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notice how can can use the slider to view images at every step."
   ],
   "metadata": {
    "id": "uOMGtyXY_6W_"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![Log in steps](https://files.slack.com/files-pri/T011VP38L1F-F03Q104988G/ezgif.com-gif-maker__2_.gif?pub_secret=e82ad20587)"
   ],
   "metadata": {
    "id": "c6ZuT-Y1FSrI"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Log using callbacks"
   ],
   "metadata": {
    "id": "LcUIvb3b8fkd"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A better use case for logging with steps is logging the perfomance of the model per epoch. For instance, you can write a custom callback to log the training and validation metrics per epoch. Here is an example of such as callback. "
   ],
   "metadata": {
    "id": "KN_5ynIcGowB"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "Pkl-pM-XjaTB"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback \n",
    "class LayerCallback(Callback):\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None): \n",
    "      layer.log({\"Training accuracy over epoch\": logs[\"accuracy\"],\"Training loss over epoch\": logs[\"loss\"]}, epoch)\n",
    "      layer.log({\"Test accuracy over epoch\": logs[\"val_accuracy\"],\"Test loss over epoch\": logs[\"val_loss\"]}, epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The next step is to pass this callback to the model's `fit` function. \n",
    "```\n",
    "model.fit(x=train_images, y=train_labels, validation_data=(test_images,test_labels),epochs=parameters[\"epochs\"], callbacks=[LayerCallback()])\n",
    "\n",
    "```"
   ],
   "metadata": {
    "id": "Ov4yTqx2HcI5"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "G3yMFmvGilrE"
   },
   "outputs": [],
   "source": [
    "@fabric(\"f-gpu-small\")\n",
    "@pip_requirements(packages=[\"tensorflow==2.7.0\",\"keras\"])\n",
    "@model(\"mnist\")\n",
    "def train():\n",
    "  from tensorflow import keras\n",
    "  from tensorflow.keras import layers\n",
    "\n",
    "  train_images = images_to_np_array(mnist_train.images)\n",
    "  test_images = images_to_np_array(mnist_test.images)\n",
    "  train_labels = mnist_train.labels\n",
    "  test_labels = mnist_test.labels\n",
    "  layer.log({\"Description\": \"TensorFlow MNIST project\"})\n",
    "  markdown = \"\"\"\n",
    "  # Layer supports Markdown. \n",
    "  \n",
    "  You can use it to add **some descriptions** in your model development.\n",
    "\n",
    "\n",
    "  In this run we'll add logging images in steps. Let's log some sample images from  \n",
    "  from the MNIST dataset. \n",
    "  \n",
    "  \"\"\"\n",
    "  layer.log({\"Description\":layer.Markdown(markdown)})\n",
    "  mnist_train_sample = mnist_train[[\"images\"]].head(10)\n",
    "  for i in range(10):\n",
    "    layer.log({f\"Image\": mnist_train_sample[\"images\"][i]}, step=i)\n",
    "\n",
    "  parameters = {\"shape\":28, \"activation\": \"relu\", \"classes\": 10, \"units\":12, \"optimizer\":\"adam\", \"epochs\":10,\"kernel_size\":3,\"pool_size\":2, \"dropout\":0.5}\n",
    "  layer.log(parameters)\n",
    "  # Setup the layers\n",
    "  model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(parameters[\"shape\"], parameters[\"shape\"], 1)),\n",
    "        layers.Conv2D(32, kernel_size=(parameters[\"kernel_size\"], parameters[\"kernel_size\"]), activation=parameters[\"activation\"]),\n",
    "        layers.MaxPooling2D(pool_size=(parameters[\"pool_size\"], parameters[\"pool_size\"])),\n",
    "        layers.Conv2D(64, kernel_size=(parameters[\"kernel_size\"], parameters[\"kernel_size\"]), activation=parameters[\"activation\"]),\n",
    "        layers.MaxPooling2D(pool_size=(parameters[\"pool_size\"], parameters[\"pool_size\"])),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(parameters[\"dropout\"]),\n",
    "        layers.Dense(parameters[\"classes\"], activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "    # Compile the model\n",
    "  model.compile(optimizer=parameters[\"optimizer\"],\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "  # Train it!\n",
    "  model.fit(x=train_images, y=train_labels, validation_data=(test_images,test_labels),epochs=parameters[\"epochs\"], callbacks=[LayerCallback()])\n",
    "  # And finally evaluate the accuracy\n",
    "  test_loss, test_acc = model.evaluate(test_images,  test_labels)\n",
    "  test_metrics = {\"Test loss\": test_loss,\"Test accuracy\":test_acc }\n",
    "  predictions = model.predict(test_images)\n",
    "  df = pd.DataFrame(predictions, columns=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"])\n",
    "  # Log Pandas DataFrame\n",
    "  layer.log({\"Sample predictions\":df.sample(100)})\n",
    "  layer.log(test_metrics)\n",
    "  return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WmYBDt73kR9S",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "layer.run([train])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "![Using callbacks](https://files.slack.com/files-pri/T011VP38L1F-F03NK1RJQKW/ezgif.com-gif-maker.gif?pub_secret=dbae18146c)"
   ],
   "metadata": {
    "id": "rJyyjl19FVCL"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Log interactive apps"
   ],
   "metadata": {
    "id": "-9MY5M0Clsis"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can log interactive [Gradio](https://gradio.app/) and [Streamlit](https://streamlit.io/) applications with Layer. Applications are logged by passing the [Hugging Face space link](https://huggingface.co/docs/hub/spaces) to the log function as Markdown. The syntax looks like this: \n",
    "```\n",
    "layer.log({\"demo\":layer.Markdown(\"<iframe width='100%', height='522px' src='https://hf.space/embed/mecevit/english-to-sql/+'></iframe>\")})\n",
    "```"
   ],
   "metadata": {
    "id": "8ZxfpqxFH0-n"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "@fabric(\"f-gpu-small\")\n",
    "@pip_requirements(packages=[\"tensorflow==2.7.0\",\"keras\"])\n",
    "@model(\"mnist\")\n",
    "def train():\n",
    "  from tensorflow import keras\n",
    "  from tensorflow.keras import layers\n",
    "\n",
    "  train_images = images_to_np_array(mnist_train.images)\n",
    "  test_images = images_to_np_array(mnist_test.images)\n",
    "  train_labels = mnist_train.labels\n",
    "  test_labels = mnist_test.labels\n",
    "  layer.log({\"Description\": \"TensorFlow MNIST project\"})\n",
    "  markdown = \"\"\"\n",
    "  # Layer supports Markdown. \n",
    "  \n",
    "  You can use it to add **some descriptions** in your model development.\n",
    "\n",
    "\n",
    "  In this run we'll add logging images in steps. Let's log some sample images from  \n",
    "  from the MNIST dataset. \n",
    "  \n",
    "  \"\"\"\n",
    "  layer.log({\"Description\":layer.Markdown(markdown)})\n",
    "  mnist_train_sample = mnist_train[[\"images\"]].head(10)\n",
    "  for i in range(10):\n",
    "    layer.log({f\"Image\": mnist_train_sample[\"images\"][i]}, step=i)\n",
    "\n",
    "  parameters = {\"shape\":28, \"activation\": \"relu\", \"classes\": 10, \"units\":12, \"optimizer\":\"adam\", \"epochs\":10,\"kernel_size\":3,\"pool_size\":2, \"dropout\":0.5}\n",
    "  layer.log(parameters)\n",
    "  # Setup the layers\n",
    "  model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(parameters[\"shape\"], parameters[\"shape\"], 1)),\n",
    "        layers.Conv2D(32, kernel_size=(parameters[\"kernel_size\"], parameters[\"kernel_size\"]), activation=parameters[\"activation\"]),\n",
    "        layers.MaxPooling2D(pool_size=(parameters[\"pool_size\"], parameters[\"pool_size\"])),\n",
    "        layers.Conv2D(64, kernel_size=(parameters[\"kernel_size\"], parameters[\"kernel_size\"]), activation=parameters[\"activation\"]),\n",
    "        layers.MaxPooling2D(pool_size=(parameters[\"pool_size\"], parameters[\"pool_size\"])),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(parameters[\"dropout\"]),\n",
    "        layers.Dense(parameters[\"classes\"], activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "    # Compile the model\n",
    "  model.compile(optimizer=parameters[\"optimizer\"],\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "  # Train it!\n",
    "  model.fit(x=train_images, y=train_labels,validation_data=(test_images,test_labels), epochs=parameters[\"epochs\"])\n",
    "  # And finally evaluate the accuracy\n",
    "  test_loss, test_acc = model.evaluate(test_images,  test_labels)\n",
    "  test_metrics = {\"Test loss\": test_loss,\"Test accuracy\":test_acc }\n",
    "  predictions = model.predict(test_images)\n",
    "  df = pd.DataFrame(predictions, columns=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"])\n",
    "  # Log Pandas DataFrame\n",
    "  layer.log({\"Sample predictions\":df.sample(100)})\n",
    "  layer.log(test_metrics)\n",
    "  layer.log({\"demo\":layer.Markdown(\"<iframe width='100%', height='522px' src='https://hf.space/embed/mecevit/english-to-sql/+'></iframe>\")})\n",
    "  return model "
   ],
   "metadata": {
    "id": "XRzzidcQ7lKX"
   },
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "layer.run([train])"
   ],
   "metadata": {
    "id": "K14jwbhJ4Voc",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "![Gradio Demo](https://files.slack.com/files-pri/T011VP38L1F-F03NA1RAGBY/ezgif.com-gif-maker__1_.gif?pub_secret=5e7d9ef214)"
   ],
   "metadata": {
    "id": "LiTP5F6_FYCa"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Log videos and GIFs"
   ],
   "metadata": {
    "id": "faUeCQQpniB-"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Layer supports logging of videos and GIFs. This can come in handy to show \n",
    "short demos. In the example below, we use the [@resources](https://docs.app.layer.ai/docs/sdk-library/resources-decorator) decorator to upload a video and a GIF to Layer then use `layer.log` to log them.\n",
    "```\n",
    "layer.log({\"GIF\": Image.open(\"video.gif\")})\n",
    "video_path = Path(\"video.mp4\")\n",
    "```"
   ],
   "metadata": {
    "id": "waowIUY8Y138"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "@fabric(\"f-gpu-small\")\n",
    "@pip_requirements(packages=[\"tensorflow==2.7.0\",\"keras\"])\n",
    "@resources(\"video.gif\", \"video.mp4\")\n",
    "@model(\"mnist\")\n",
    "def train():\n",
    "  from tensorflow import keras\n",
    "  from tensorflow.keras import layers\n",
    "  from pathlib import Path\n",
    "\n",
    "  train_images = images_to_np_array(mnist_train.images)\n",
    "  test_images = images_to_np_array(mnist_test.images)\n",
    "  train_labels = mnist_train.labels\n",
    "  test_labels = mnist_test.labels\n",
    "  layer.log({\"Description\": \"TensorFlow MNIST project\"})\n",
    "  markdown = \"\"\"\n",
    "  ## Metadata about experiments and model training runs\n",
    "Layer allows you to store metadata about experiments and model training runs. This information includes but is not limited to:\n",
    "\n",
    "- **Dataset version** used for model training.\n",
    "- **Model hyperparameters** yielding the best results.\n",
    "- **Training loss and metrics** to understand if the model is learning.    \n",
    "- **Testing metrics and loss** to quickly see if the model is overfitting.\n",
    "- **Model predictions** to get a rough idea of its performance.\n",
    "- **Hardware metrics** to inform you of GPU and CPU utilization.    \n",
    "- **Performance charts** such as accuracy and loss plots, confusion matrix, Precision-Recall Curve, ROC curve, etc.\n",
    "- **Package versions** to ensure the project runs without failing.\n",
    "- **Model training logs** to make it easy to debug the project.\n",
    "- **Information that is specific** to the domain of your problem. \n",
    "\n",
    "Layer stores information regarding the trained models too. This information includes:\n",
    "\n",
    "- The person who trained the model.\n",
    "- Model version.\n",
    "- The infrastructure used to train the model could be local or cloud.\n",
    "- Machine learning packages used to train the model, for example, TensorFlow, PyTorch, Scikit-learn, etc.\n",
    "- Model description.\n",
    "- When the model was trained.\n",
    "- How long it took to train the model.\n",
    "\n",
    "Layer stores the resulting model and makes it accessible for immediate use. You can fetch the model and use it for predictions right away.\n",
    "  \"\"\"\n",
    "  layer.log({\"Description\":layer.Markdown(markdown)})\n",
    "  mnist_train_sample = mnist_train[[\"images\"]].head(10)\n",
    "  for i in range(10):\n",
    "    layer.log({f\"Image\": mnist_train_sample[\"images\"][i]}, step=i)\n",
    "\n",
    "  parameters = {\"shape\":28, \"activation\": \"relu\", \"classes\": 10, \"units\":12, \"optimizer\":\"adam\", \"epochs\":10,\"kernel_size\":3,\"pool_size\":2, \"dropout\":0.5}\n",
    "  layer.log(parameters)\n",
    "  # Setup the layers\n",
    "  model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(parameters[\"shape\"], parameters[\"shape\"], 1)),\n",
    "        layers.Conv2D(32, kernel_size=(parameters[\"kernel_size\"], parameters[\"kernel_size\"]), activation=parameters[\"activation\"]),\n",
    "        layers.MaxPooling2D(pool_size=(parameters[\"pool_size\"], parameters[\"pool_size\"])),\n",
    "        layers.Conv2D(64, kernel_size=(parameters[\"kernel_size\"], parameters[\"kernel_size\"]), activation=parameters[\"activation\"]),\n",
    "        layers.MaxPooling2D(pool_size=(parameters[\"pool_size\"], parameters[\"pool_size\"])),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(parameters[\"dropout\"]),\n",
    "        layers.Dense(parameters[\"classes\"], activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "    # Compile the model\n",
    "  model.compile(optimizer=parameters[\"optimizer\"],\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "  # Train it!\n",
    "  model.fit(x=train_images, y=train_labels,validation_data=(test_images,test_labels), epochs=parameters[\"epochs\"])\n",
    "  # And finally evaluate the accuracy\n",
    "  test_loss, test_acc = model.evaluate(test_images,  test_labels)\n",
    "  test_metrics = {\"Test loss\": test_loss,\"Test accuracy\":test_acc }\n",
    "  predictions = model.predict(test_images)\n",
    "  df = pd.DataFrame(predictions, columns=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"])\n",
    "  layer.log({\"Sample predictions\":df.sample(100)})\n",
    "  layer.log(test_metrics)\n",
    "  layer.log({\"GIF\": Path(f\"{os.getcwd()}/video.gif\")})\n",
    "  video_path = Path(\"video.mp4\")\n",
    "  layer.log({\"Video\": video_path})\n",
    "  return model "
   ],
   "metadata": {
    "id": "87UhKqOJnmuR"
   },
   "execution_count": 37,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "layer.run([train])"
   ],
   "metadata": {
    "id": "ch30YneGFcqG",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "![Log video images](https://files.slack.com/files-pri/T011VP38L1F-F03NAG4FCSJ/ezgif.com-gif-maker.gif?pub_secret=61c1d592eb)"
   ],
   "metadata": {
    "id": "ZkJ3z92RFZ-a"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Where to go from here"
   ],
   "metadata": {
    "id": "01OcRVSRl-9o"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To learn more about using layer, you can: \n",
    "- Join our [Slack Community ](https://bit.ly/layercommunityslack)\n",
    "- Visit [Layer Examples Repo](https://github.com/layerai/examples) for more examples\n",
    "- Browse [Trending Layer Projects](https://layer.ai) on our mainpage\n",
    "- Check out [Layer Documentation](https://docs.app.layer.ai) to learn more"
   ],
   "metadata": {
    "id": "NSKfadABJR0Z"
   }
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "layer log notebook.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}