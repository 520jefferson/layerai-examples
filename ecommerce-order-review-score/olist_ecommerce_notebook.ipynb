{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":58434,"status":"ok","timestamp":1651052523745,"user":{"displayName":"Burak Özen","userId":"11994329513809852046"},"user_tz":-120},"id":"5A-d7YtmwmrH","outputId":"f5f4d98a-124a-4169-8603-00a0bfd1f576"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting layer_sdk\n","  Downloading layer_sdk-0.9.351275-py3-none-any.whl (471 kB)\n","\u001b[K     |████████████████████████████████| 471 kB 5.3 MB/s \n","\u001b[?25hCollecting aiohttp<3.8.0,>=3.7.3\n","  Downloading aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 52.8 MB/s \n","\u001b[?25hCollecting grpcio-tools==1.45.0\n","  Downloading grpcio_tools-1.45.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n","\u001b[K     |████████████████████████████████| 2.4 MB 26.2 MB/s \n","\u001b[?25hCollecting grpcio==1.45.0\n","  Downloading grpcio-1.45.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n","\u001b[K     |████████████████████████████████| 4.4 MB 30.8 MB/s \n","\u001b[?25hCollecting polling>=0.3.1\n","  Downloading polling-0.3.2.tar.gz (5.2 kB)\n","Collecting prompt-toolkit>=3.0.8\n","  Downloading prompt_toolkit-3.0.29-py3-none-any.whl (381 kB)\n","\u001b[K     |████████████████████████████████| 381 kB 44.9 MB/s \n","\u001b[?25hCollecting GitPython==3.1.14\n","  Downloading GitPython-3.1.14-py3-none-any.whl (159 kB)\n","\u001b[K     |████████████████████████████████| 159 kB 43.5 MB/s \n","\u001b[?25hRequirement already satisfied: networkx>=2.5 in /usr/local/lib/python3.7/dist-packages (from layer_sdk) (2.6.3)\n","Collecting jsonschema==3.1.1\n","  Downloading jsonschema-3.1.1-py2.py3-none-any.whl (56 kB)\n","\u001b[K     |████████████████████████████████| 56 kB 3.3 MB/s \n","\u001b[?25hCollecting pyjwt<2.0.0,>=1.7.1\n","  Downloading PyJWT-1.7.1-py2.py3-none-any.whl (18 kB)\n","Collecting validate-email==1.3\n","  Downloading validate_email-1.3.tar.gz (4.7 kB)\n","Collecting pickle5~=0.0.11\n","  Downloading pickle5-0.0.12-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (256 kB)\n","\u001b[K     |████████████████████████████████| 256 kB 35.8 MB/s \n","\u001b[?25hCollecting mlflow>=1.25.0\n","  Downloading mlflow-1.25.1-py3-none-any.whl (16.8 MB)\n","\u001b[K     |████████████████████████████████| 16.8 MB 1.7 MB/s \n","\u001b[?25hCollecting packaging<=21.0\n","  Downloading packaging-21.0-py3-none-any.whl (40 kB)\n","\u001b[K     |████████████████████████████████| 40 kB 5.3 MB/s \n","\u001b[?25hCollecting humanize>=3.11.0\n","  Downloading humanize-4.0.0-py3-none-any.whl (97 kB)\n","\u001b[K     |████████████████████████████████| 97 kB 7.0 MB/s \n","\u001b[?25hCollecting pyarrow==7.0.0\n","  Downloading pyarrow-7.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n","\u001b[K     |████████████████████████████████| 26.7 MB 15.8 MB/s \n","\u001b[?25hCollecting typing-extensions<4.0.0\n","  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n","Collecting cloudpickle>=2.0.0\n","  Downloading cloudpickle-2.0.0-py3-none-any.whl (25 kB)\n","Collecting transformers\n","  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n","\u001b[K     |████████████████████████████████| 4.0 MB 31.7 MB/s \n","\u001b[?25hRequirement already satisfied: Jinja2>=2.11.3 in /usr/local/lib/python3.7/dist-packages (from layer_sdk) (2.11.3)\n","Collecting rich~=10.12.0\n","  Downloading rich-10.12.0-py3-none-any.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 45.3 MB/s \n","\u001b[?25hRequirement already satisfied: wrapt>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from layer_sdk) (1.14.0)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from layer_sdk) (3.17.3)\n","Collecting boto3>=1.16.24\n","  Downloading boto3-1.22.1-py3-none-any.whl (132 kB)\n","\u001b[K     |████████████████████████████████| 132 kB 49.4 MB/s \n","\u001b[?25hCollecting yarl>=1.6.3\n","  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n","\u001b[K     |████████████████████████████████| 271 kB 34.4 MB/s \n","\u001b[?25hCollecting cryptography>=3.4.7\n","  Downloading cryptography-37.0.0-cp36-abi3-manylinux_2_24_x86_64.whl (4.0 MB)\n","\u001b[K     |████████████████████████████████| 4.0 MB 10.9 MB/s \n","\u001b[?25hCollecting aiodocker>=0.19.1\n","  Downloading aiodocker-0.21.0-py3-none-any.whl (34 kB)\n","Requirement already satisfied: pandas>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from layer_sdk) (1.3.5)\n","Requirement already satisfied: idna<3 in /usr/local/lib/python3.7/dist-packages (from layer_sdk) (2.10)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio==1.45.0->layer_sdk) (1.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from grpcio-tools==1.45.0->layer_sdk) (57.4.0)\n","Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema==3.1.1->layer_sdk) (0.18.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema==3.1.1->layer_sdk) (4.11.3)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema==3.1.1->layer_sdk) (21.4.0)\n","Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from pyarrow==7.0.0->layer_sdk) (1.21.6)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n","\u001b[K     |████████████████████████████████| 94 kB 3.4 MB/s \n","\u001b[?25hRequirement already satisfied: chardet<5.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp<3.8.0,>=3.7.3->layer_sdk) (3.0.4)\n","Collecting async-timeout<4.0,>=3.0\n","  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n","Collecting botocore<1.26.0,>=1.25.1\n","  Downloading botocore-1.25.1-py3-none-any.whl (8.7 MB)\n","\u001b[K     |████████████████████████████████| 8.7 MB 41.1 MB/s \n","\u001b[?25hCollecting s3transfer<0.6.0,>=0.5.0\n","  Downloading s3transfer-0.5.2-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 8.5 MB/s \n","\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n","  Downloading jmespath-1.0.0-py3-none-any.whl (23 kB)\n","Collecting urllib3<1.27,>=1.25.4\n","  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n","\u001b[K     |████████████████████████████████| 138 kB 41.5 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.26.0,>=1.25.1->boto3>=1.16.24->layer_sdk) (2.8.2)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=3.4.7->layer_sdk) (1.15.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=3.4.7->layer_sdk) (2.21)\n","Collecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.11.3->layer_sdk) (2.0.1)\n","Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.7/dist-packages (from mlflow>=1.25.0->layer_sdk) (1.4.35)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 59.4 MB/s \n","\u001b[?25hCollecting docker>=4.0.0\n","  Downloading docker-5.0.3-py2.py3-none-any.whl (146 kB)\n","\u001b[K     |████████████████████████████████| 146 kB 53.5 MB/s \n","\u001b[?25hRequirement already satisfied: sqlparse>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from mlflow>=1.25.0->layer_sdk) (0.4.2)\n","Collecting alembic\n","  Downloading alembic-1.7.7-py3-none-any.whl (210 kB)\n","\u001b[K     |████████████████████████████████| 210 kB 53.7 MB/s \n","\u001b[?25hCollecting querystring-parser\n","  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n","Collecting prometheus-flask-exporter\n","  Downloading prometheus_flask_exporter-0.20.1-py3-none-any.whl (18 kB)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow>=1.25.0->layer_sdk) (7.1.2)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from mlflow>=1.25.0->layer_sdk) (2022.1)\n","Requirement already satisfied: Flask in /usr/local/lib/python3.7/dist-packages (from mlflow>=1.25.0->layer_sdk) (1.1.4)\n","Requirement already satisfied: requests>=2.17.3 in /usr/local/lib/python3.7/dist-packages (from mlflow>=1.25.0->layer_sdk) (2.23.0)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from mlflow>=1.25.0->layer_sdk) (0.4)\n","Collecting databricks-cli>=0.8.7\n","  Downloading databricks-cli-0.16.6.tar.gz (62 kB)\n","\u001b[K     |████████████████████████████████| 62 kB 768 kB/s \n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from mlflow>=1.25.0->layer_sdk) (1.4.1)\n","Collecting gunicorn\n","  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 8.2 MB/s \n","\u001b[?25hRequirement already satisfied: oauthlib>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from databricks-cli>=0.8.7->mlflow>=1.25.0->layer_sdk) (3.2.0)\n","Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from databricks-cli>=0.8.7->mlflow>=1.25.0->layer_sdk) (0.8.9)\n","Collecting websocket-client>=0.32.0\n","  Downloading websocket_client-1.3.2-py3-none-any.whl (54 kB)\n","\u001b[K     |████████████████████████████████| 54 kB 2.7 MB/s \n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->jsonschema==3.1.1->layer_sdk) (3.8.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging<=21.0->layer_sdk) (3.0.8)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit>=3.0.8->layer_sdk) (0.2.5)\n","Collecting urllib3<1.27,>=1.25.4\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 59.8 MB/s \n","\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.17.3->mlflow>=1.25.0->layer_sdk) (2021.10.8)\n","Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich~=10.12.0->layer_sdk) (2.6.1)\n","Collecting commonmark<0.10.0,>=0.9.0\n","  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n","\u001b[K     |████████████████████████████████| 51 kB 6.8 MB/s \n","\u001b[?25hCollecting colorama<0.5.0,>=0.4.0\n","  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->mlflow>=1.25.0->layer_sdk) (5.7.1)\n","Collecting Mako\n","  Downloading Mako-1.2.0-py3-none-any.whl (78 kB)\n","\u001b[K     |████████████████████████████████| 78 kB 7.3 MB/s \n","\u001b[?25hRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy->mlflow>=1.25.0->layer_sdk) (1.1.2)\n","Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow>=1.25.0->layer_sdk) (1.0.1)\n","Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow>=1.25.0->layer_sdk) (1.1.0)\n","Requirement already satisfied: prometheus-client in /usr/local/lib/python3.7/dist-packages (from prometheus-flask-exporter->mlflow>=1.25.0->layer_sdk) (0.14.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers->layer_sdk) (2019.12.20)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 49.1 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 44.2 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers->layer_sdk) (4.64.0)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n","\u001b[K     |████████████████████████████████| 77 kB 6.6 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers->layer_sdk) (3.6.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers->layer_sdk) (1.1.0)\n","\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'grpcio' candidate (version 1.45.0 at https://files.pythonhosted.org/packages/b8/ab/c7abc950e222c4cab5f7fd92107f3b09553061f673f1a670e6569105f584/grpcio-1.45.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl#sha256=cc135b77f384a84bac67a37947886986be136356446338d64160a30c85f20c6d (from https://pypi.org/simple/grpcio/) (requires-python:>=3.6))\n","Reason for being yanked: Segfaults\u001b[0m\n","\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'grpcio-tools' candidate (version 1.45.0 at https://files.pythonhosted.org/packages/be/e1/70dac693e6df7e4f3108dfd3a82f86f0cd3742d9afe98bb2fe4333a3edd7/grpcio_tools-1.45.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl#sha256=7db11a65e07410db1c31cbeb9afe344a6bd88a63dcd819557707ca7318478727 (from https://pypi.org/simple/grpcio-tools/) (requires-python:>=3.6))\n","Reason for being yanked: grpcio 1.45.0 was yanked\u001b[0m\n","Building wheels for collected packages: validate-email, databricks-cli, polling\n","  Building wheel for validate-email (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for validate-email: filename=validate_email-1.3-py3-none-any.whl size=5482 sha256=cb092477346e54d9eaccbb798e67de4f7d34250bd1a40554a9cfd7bea014d21b\n","  Stored in directory: /root/.cache/pip/wheels/ff/8f/92/c43287715852eaa75e0d8aa1941c481072b4a82c4f4975074e\n","  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for databricks-cli: filename=databricks_cli-0.16.6-py3-none-any.whl size=112631 sha256=83d024d0353d4467d59dc61c617ad6ba92ed9c5b3630dc16f4463e6d8d1e81bf\n","  Stored in directory: /root/.cache/pip/wheels/96/c1/f8/d75a22e789ab6a4dff11f18338c3af4360189aa371295cc934\n","  Building wheel for polling (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for polling: filename=polling-0.3.2-py3-none-any.whl size=4129 sha256=1539dd52ca098f7b1383810470238414f1dbba54fd6806f74d211f57a3049355\n","  Stored in directory: /root/.cache/pip/wheels/e5/3f/0c/54a03b715fce3176335c957ae94d7d0b2a918e89b1b195bace\n","Successfully built validate-email databricks-cli polling\n","Installing collected packages: typing-extensions, urllib3, smmap, multidict, jmespath, yarl, websocket-client, pyyaml, pyjwt, packaging, Mako, gitdb, botocore, async-timeout, tokenizers, sacremoses, s3transfer, querystring-parser, prometheus-flask-exporter, huggingface-hub, gunicorn, grpcio, GitPython, docker, databricks-cli, commonmark, colorama, cloudpickle, alembic, aiohttp, validate-email, transformers, rich, pyarrow, prompt-toolkit, polling, pickle5, mlflow, jsonschema, humanize, grpcio-tools, cryptography, boto3, aiodocker, layer-sdk\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing-extensions 4.2.0\n","    Uninstalling typing-extensions-4.2.0:\n","      Successfully uninstalled typing-extensions-4.2.0\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: packaging\n","    Found existing installation: packaging 21.3\n","    Uninstalling packaging-21.3:\n","      Successfully uninstalled packaging-21.3\n","  Attempting uninstall: grpcio\n","    Found existing installation: grpcio 1.44.0\n","    Uninstalling grpcio-1.44.0:\n","      Successfully uninstalled grpcio-1.44.0\n","  Attempting uninstall: cloudpickle\n","    Found existing installation: cloudpickle 1.3.0\n","    Uninstalling cloudpickle-1.3.0:\n","      Successfully uninstalled cloudpickle-1.3.0\n","  Attempting uninstall: pyarrow\n","    Found existing installation: pyarrow 6.0.1\n","    Uninstalling pyarrow-6.0.1:\n","      Successfully uninstalled pyarrow-6.0.1\n","  Attempting uninstall: prompt-toolkit\n","    Found existing installation: prompt-toolkit 1.0.18\n","    Uninstalling prompt-toolkit-1.0.18:\n","      Successfully uninstalled prompt-toolkit-1.0.18\n","  Attempting uninstall: jsonschema\n","    Found existing installation: jsonschema 4.3.3\n","    Uninstalling jsonschema-4.3.3:\n","      Successfully uninstalled jsonschema-4.3.3\n","  Attempting uninstall: humanize\n","    Found existing installation: humanize 0.5.1\n","    Uninstalling humanize-0.5.1:\n","      Successfully uninstalled humanize-0.5.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n","nbclient 0.6.0 requires jupyter-client>=6.1.5, but you have jupyter-client 5.3.5 which is incompatible.\n","jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.29 which is incompatible.\n","ipython 5.5.0 requires prompt-toolkit<2.0.0,>=1.0.4, but you have prompt-toolkit 3.0.29 which is incompatible.\n","gym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.0.0 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed GitPython-3.1.14 Mako-1.2.0 aiodocker-0.21.0 aiohttp-3.7.4.post0 alembic-1.7.7 async-timeout-3.0.1 boto3-1.22.1 botocore-1.25.1 cloudpickle-2.0.0 colorama-0.4.4 commonmark-0.9.1 cryptography-37.0.0 databricks-cli-0.16.6 docker-5.0.3 gitdb-4.0.9 grpcio-1.45.0 grpcio-tools-1.45.0 gunicorn-20.1.0 huggingface-hub-0.5.1 humanize-4.0.0 jmespath-1.0.0 jsonschema-3.1.1 layer-sdk-0.9.351275 mlflow-1.25.1 multidict-6.0.2 packaging-21.0 pickle5-0.0.12 polling-0.3.2 prometheus-flask-exporter-0.20.1 prompt-toolkit-3.0.29 pyarrow-7.0.0 pyjwt-1.7.1 pyyaml-6.0 querystring-parser-1.2.4 rich-10.12.0 s3transfer-0.5.2 sacremoses-0.0.49 smmap-5.0.0 tokenizers-0.12.1 transformers-4.18.0 typing-extensions-3.10.0.2 urllib3-1.25.11 validate-email-1.3 websocket-client-1.3.2 yarl-1.7.2\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["prompt_toolkit"]}}},"metadata":{},"output_type":"display_data"}],"source":["!pip install layer_sdk --upgrade"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6626,"status":"ok","timestamp":1651149550237,"user":{"displayName":"Burak Özen","userId":"16794056347198304221"},"user_tz":-120},"id":"tIGFI7xQLZTH","outputId":"0fed184e-403d-4232-ab4c-b854d499832c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'ecommerce_order_review_score_prediction'...\n","remote: Enumerating objects: 5, done.\u001b[K\n","remote: Counting objects: 100% (5/5), done.\u001b[K\n","remote: Compressing objects: 100% (5/5), done.\u001b[K\n","remote: Total 5 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n","Unpacking objects: 100% (5/5), done.\n"]}],"source":["!rm -rf ecommerce_order_review_score_prediction\n","!git clone https://github.com/layerml/ecommerce_order_review_score_prediction"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":175,"status":"ok","timestamp":1651150115261,"user":{"displayName":"Burak Özen","userId":"16794056347198304221"},"user_tz":-120},"id":"xmjdLhCNwrS1"},"outputs":[],"source":["#from layer.v2.assertions import greatexpectations, assert_true, assert_valid_values, assert_not_null, assert_unique\n","from layer.decorators import dataset, model,resources, pip_requirements, assertions, fabric\n","from layer.decorators.assertions import assert_unique, assert_valid_values\n","from layer.client import Dataset, Model\n","import layer\n","\n","#layer.logout()\n","layer.login()\n","#layer.login(\"https://development.layer.co/\")"]},{"cell_type":"markdown","metadata":{"id":"v29GUhIGha35"},"source":["# ***ML PROJECT: Predict review score of an order based on its information***"]},{"cell_type":"markdown","metadata":{"id":"3vE8xVJGKy6l"},"source":["# **Data Transformation**"]},{"cell_type":"code","execution_count":35,"metadata":{"executionInfo":{"elapsed":504,"status":"ok","timestamp":1651152079385,"user":{"displayName":"Burak Özen","userId":"16794056347198304221"},"user_tz":-120},"id":"quz2sjuoKu9Z"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","@resources(\"ecommerce_order_review_score_prediction/olist_orders_dataset.csv\")\n","@dataset(\"orders_raw_table\")\n","def load_order_table():\n","  orders_df = pd.read_csv(\"ecommerce_order_review_score_prediction/olist_orders_dataset.csv\")\n","\n","  layer.log({\"Dataset Description\": \"Raw orders table by loading from a csv file\"})\n","\n","  return orders_df\n","\n","@dataset(\"orders_clean_table\",dependencies=[Dataset('orders_raw_table')])\n","def clean_order_table():\n","  # Load dataset\n","  orders_df = layer.get_dataset(\"orders_raw_table\").to_pandas()\n","\n","  # Drop all the rows having at least 1 null value - Since there are just a few null values in the data, we could just drop all of them.\n","  df = orders_df.dropna()\n","\n","  # We will do our analysis only on the delivered orders\n","  df = df[df['order_status'] == 'delivered']\n","\n","  # Drop rows that don't meet the requirement: order_purchase_timestamp <= order_approved_at <= order_delivered_carrier_date <= order_delivered_customer_date\n","  df = df[~((df['order_purchase_timestamp'] >= df['order_approved_at']) | (df['order_approved_at'] >= df['order_delivered_carrier_date']) | (df['order_delivered_carrier_date'] >= df['order_delivered_customer_date']))]\n","\n","  layer.log({\"Dataset Description\": \"Cleaned version of the orders table by dropping na rows, selecting only 'delivered' orders and doing sanity checks on timestamp columns.\"})\n","\n","  return df\n","\n","\n","def bucketize_actual_delivery_vs_expectation (row):\n","  if row['days_between_delivery_expectation'] <= 0 :\n","    return -1\n","  elif row['days_between_delivery_expectation'] <= 7 :\n","    return 1\n","  elif row['days_between_delivery_expectation'] <= 14 :\n","    return 2\n","  else:\n","    return 3\n","\n","@dataset(\"orders_based_features\",dependencies=[Dataset('orders_clean_table')])\n","def extract_features_order_table():\n","  # Load dataset\n","  df = layer.get_dataset(\"orders_clean_table\").to_pandas()\n","\n","  # Days between purchase and delivery dates\n","  df['days_between_purhcase_and_delivery'] = (pd.to_datetime(df['order_delivered_customer_date']) - pd.to_datetime(df['order_purchase_timestamp'])).dt.days\n","\n","  # if the order was approved late or on time (0=on time, 1=late)\n","  df['order_approved_late']=np.where((pd.to_datetime(df['order_approved_at']) - pd.to_datetime(df['order_purchase_timestamp'])).dt.days == 0, 0, 1)\n","\n","  # Actual delivery vs. Expected delivery: 1=Delivered before expected date, 2= Delivered one week later than expected date, 3= Delivered two weeks later than expected date, 4= Delivered more than two weeks later than expected date\n","  df['days_between_delivery_expectation']=(pd.to_datetime(df['order_estimated_delivery_date']) - pd.to_datetime(df['order_delivered_customer_date'])).dt.days\n","  df['actual_delivery_vs_expectation_bucket'] = df.apply (lambda row: bucketize_actual_delivery_vs_expectation(row), axis=1)\n","\n","  layer.log({\"Dataset Description\": \"Features extracted only from the orders table\"})\n","  layer.log({\"days_between_purchase_and_delivery\":\"Days between delivery date and purchase date\",\n","             \"order_approved_late\":\"0: Order payment is approved on the same day with purchase -- 1: Otherwise\",\n","             \"actual_delivery_vs_expectation_bucket\":\"It represents the days between estimated delivery date and actual delivery date -- 1: Less than 7 days, 2: Less than 14 days more than 7 days, 3: More than 14 days, -1: Order delivered later than estimated date\",\n","             \"order_delivered_carrier_date\":\"The date order delivered to carrier\"\n","             })\n","\n","  df = df[['order_id','days_between_purhcase_and_delivery','order_approved_late','actual_delivery_vs_expectation_bucket','order_delivered_carrier_date']]\n","  return df\n","\n","@resources(\"ecommerce_order_review_score_prediction/olist_order_items_dataset.csv\")\n","@dataset(\"items_raw_table\")\n","def load_item_table():\n","  # Load items table from csv file\n","  items_df = pd.read_csv(\"ecommerce_order_review_score_prediction/olist_order_items_dataset.csv\")\n","\n","  layer.log({\"Dataset Description\": \"Raw items table by loading from a csv file\"})\n","\n","  return items_df  \n","\n","\n","@dataset(\"items_clean_table\",dependencies=[Dataset('items_raw_table')])\n","def clean_items_table():\n","  # Load dataset\n","  items_df = layer.get_dataset(\"items_raw_table\").to_pandas()\n","\n","  # Select relevant columns and drop any na valued rows\n","  df = items_df[['order_id','shipping_limit_date','price','freight_value']].dropna()\n","\n","  # Price and Freight Value must be non-negative\n","  df = df[(items_df['price']>=0) & (items_df['freight_value']>=0)]\n","\n","  layer.log({\"Dataset Description\": \"Cleaned version of the raw items table by selecting some relevant columns out of it, dropping na rows and doing some sanity checks on 'price' and 'freight_value' columns\"})\n","\n","  return df\n","\n","@dataset(\"items_based_features\",dependencies=[Dataset('items_clean_table')])\n","def extract_features_items_table():\n","  # Load dataset\n","  df = layer.get_dataset(\"items_clean_table\").to_pandas()\n","  # Extract 3 features: total_order_price & total_order_freight\n","  df1 = df.groupby('order_id').agg(total_order_price=('price', 'sum'), total_order_freight=('freight_value','sum'),max_shipping_limit_date=('shipping_limit_date','max')).reset_index()\n","\n","  # Extract 1 feature: is_multiItems_order -- If the order has multiple items or not (1 or 0)\n","  df2 = df.groupby('order_id').agg(cnt=('price', 'count')).reset_index()\n","  df2['is_multiItems_order'] = np.where(df2['cnt'] > 1, 1, 0)\n","\n","  df3 = df1.merge(df2, how=\"inner\", on='order_id')[['order_id','is_multiItems_order','total_order_price','total_order_freight','max_shipping_limit_date']]\n","\n","  layer.log({\"Dataset Description\": \"Features extracted only from the items table\"})\n","  layer.log({\"total_order_price\":\"Total price paid for the order\",\n","             \"total_order_freight\":\"Total price paid for freight transport\",\n","             \"max_shipping_limit_date\":\"Maximum of expected shipping date if order has many items\",\n","             \"is_multiItems_order\":\"If the order has multiple items or not. 0: Single item order -- 1: Multiple items order\"\n","             })\n","\n","  return df3\n","\n","@resources(\"ecommerce_order_review_score_prediction/olist_order_reviews_dataset.csv\")\n","@dataset(\"reviews_raw_table\")\n","def load_reviews_table():\n","  # Load the reviews table from csv file\n","  reviews_df = pd.read_csv(\"ecommerce_order_review_score_prediction/olist_order_reviews_dataset.csv\")\n","\n","  layer.log({\"Dataset Description\": \"Raw reviews table by loading from a csv file\"})\n","\n","  return reviews_df\n","\n","@dataset(\"reviews_clean_table\",dependencies=[Dataset('reviews_raw_table')])\n","def clean_reviews_table():\n","  # Load dataset\n","  reviews_df = layer.get_dataset(\"reviews_raw_table\").to_pandas()\n","\n","  # Drop extra reviews if an order has multiple order review scores\n","  df = reviews_df.groupby('order_id', as_index= False).agg(review_score=('review_score', 'max'))\n","\n","  layer.log({\"Dataset Description\": \"This table is used to create labels (target variable) which is review scores.\"})\n","  \n","  return df\n","\n","@assert_unique([\"order_id\"])\n","@assert_valid_values(\"review_score\", [1,2,3,4,5])\n","@dataset(\"training_data\",dependencies=[Dataset('orders_based_features'),Dataset('items_based_features'),Dataset('reviews_clean_table')])\n","def generate_training_data():\n","  from functools import reduce\n","  # Merge all clean datasets\n","  orders_data = layer.get_dataset(\"orders_based_features\").to_pandas()\n","  items_data = layer.get_dataset(\"items_based_features\").to_pandas()\n","  reviews_data = layer.get_dataset(\"reviews_clean_table\").to_pandas()\n","\n","  data_frames = [orders_data, items_data, reviews_data]\n","  df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['order_id'],how='inner'), data_frames)\n","\n","  # Create a new feature: seller_shipped_late\n","  df_merged['days_between_delivered_carrier_and_shipping_limit'] = (pd.to_datetime(df_merged['order_delivered_carrier_date']) - pd.to_datetime(df_merged['max_shipping_limit_date'])).dt.days\n","  df_merged['seller_shipped_late'] = np.where(df_merged['days_between_delivered_carrier_and_shipping_limit'] > 0 , 1 ,0) \n","\n","  # Select only relevant columns (features)\n","  df_merged = df_merged.drop(columns=['order_delivered_carrier_date', 'max_shipping_limit_date','days_between_delivered_carrier_and_shipping_limit'])\n","\n","  layer.log({\"Dataset Description\": \"All features from the orders and items tables. Final training dataset.\"})\n","  layer.log({\"order_id\":\"Unique id for the order\",\n","             \"days_between_purchase_and_delivery\":\"Days between delivery date and purchase date\",\n","             \"order_approved_late\":\"0: Order payment is approved on the same day with purchase -- 1: Otherwise\",\n","             \"actual_delivery_vs_expectation_bucket\":\"Days between estimated delivery date and actual delivery date -- 1: Less than 7 days, 2: Less than 14 days more than 7 days, 3: More than 14 days, -1: Order delivered later than estimated date\",\n","             \"total_order_price\":\"Total price paid for the order\",\n","             \"total_order_freight\":\"Total price paid for freight transport\",\n","             \"is_multiItems_order\":\"If the order has multiple items or not. 0: Single item order -- 1: Multiple items order\",\n","             \"seller_shipped_late\":\"if seller shipped items later than promised date. 1: Late - 0: Before or on time\",\n","             \"review_score\":\"Review score for the order between 1 and 5\",\n","             })\n","  \n","  \n","  return df_merged\n"]},{"cell_type":"markdown","metadata":{"id":"vhHQZ4Olk2Mc"},"source":["# **Model Functions Refined**"]},{"cell_type":"code","execution_count":45,"metadata":{"executionInfo":{"elapsed":437,"status":"ok","timestamp":1651155581177,"user":{"displayName":"Burak Özen","userId":"16794056347198304221"},"user_tz":-120},"id":"tsv9TVtIk5YU"},"outputs":[],"source":["import xgboost\n","from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import KFold\n","from xgboost import XGBRegressor\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import time\n","\n","def data_split(data):\n","  data = layer.get_dataset(\"training_data\").to_pandas()\n","\n","  training_data, testing_data = train_test_split(data, test_size=0.1, random_state=42)\n","\n","  # split data into train and test sets\n","  X_train, X_valid, y_train, y_valid = train_test_split(training_data.drop(['review_score', 'order_id'], axis=1), training_data['review_score'], test_size=0.1, random_state=7)\n","\n","  data_pair = [(X_train, y_train), (X_valid, y_valid)]\n","\n","  return data_pair\n","\n","\n","def model_overfit_check(X_train, y_train, eval_set):\n","  param_dict = {\n","    'colsample_bytree' : 1.0,\n","    'learning_rate': 0.02,\n","    'max_depth': 5,\n","    'min_child_weight': 10,\n","    'subsample' : 0.5\n","  }\n","\n","  xgb_model = XGBRegressor(n_estimators=1000, objective='reg:squarederror', colsample_bytree = param_dict['colsample_bytree'], learning_rate=param_dict['learning_rate'], max_depth=param_dict['max_depth'], min_child_weight=param_dict['min_child_weight'], subsample=param_dict['subsample'])\n","\n","  xgb_model.fit(X_train, y_train, eval_metric='rmse', eval_set=eval_set, verbose=False)\n","\n","  # retrieve performance metrics\n","  results = xgb_model.evals_result()\n","  epochs = len(results['validation_0']['rmse'])\n","  x_axis = range(0, epochs)\n","\n","  # plot rmse - train vs. test\n","  fig, ax = plt.subplots()\n","  ax.plot(x_axis, results['validation_0']['rmse'], label='Train')\n","  ax.plot(x_axis, results['validation_1']['rmse'], label='Test')\n","  ax.legend()\n","  ax.set_ylim([1.135, 1.18])\n","  plt.ylabel('Root Mean Square Error')\n","  plt.title('XGBoost RMSE')\n","  fig = plt.gcf()\n","\n","  # Layer logs the plot\n","  layer.log({\"Train vs Test - Model Overfit Check\": fig})\n","\n","  # clear all plots and figures from memory\n","  plt.figure().clear()\n","  plt.close()\n","  plt.cla()\n","  plt.clf()\n","\n","\n","def check_model_performance(xgb_model: XGBRegressor, test_data_X, test_data_Y):\n","  # PLOT 1: make predictions and show in a bar distribution plot\n","  yhat = xgb_model.predict(test_data_X)\n","  plt.hist(yhat)\n","  fig1 = plt.gcf()\n","\n","  # Layer logs the plot\n","  layer.log({\"Test Data Predicted Review Score Distribution\": fig1})\n","\n","  # clear all plots and figures from memory\n","  plt.figure().clear()\n","  plt.close()\n","  plt.cla()\n","  plt.clf()\n","\n","  # PLOT 2: distribution of actual review scores\n","  plt.hist(test_data_Y)\n","  fig2 = plt.gcf()\n","\n","  # Layer logs the plot\n","  layer.log({\"Test Data Real Review Score Distribution\": fig2})\n","\n","  # clear all plots and figures from memory\n","  plt.figure().clear()\n","  plt.close()\n","  plt.cla()\n","  plt.clf()\n","\n","@pip_requirements(packages=[\"xgboost==0.90\"])\n","@fabric(\"f-medium\")\n","@model(\"review_score_predictor_model\",dependencies=[Dataset('training_data')])\n","def train_final_model():\n","  # The best parameter combination\n","  param_dict = {\n","    'colsample_bytree' : 1.0,\n","    'learning_rate': 0.02,\n","    'max_depth': 5,\n","    'min_child_weight': 10,\n","    'subsample' : 0.5\n","  }\n","\n","  # Layer logs model description and model parameters\n","  layer.log({\"Model Description\" : \"XGBRegressor with squared error objective function to predict review scores of orders based on their high level features.\"})\n","  layer.log(param_dict)\n","\n","  training_data = layer.get_dataset(\"training_data\").to_pandas()\n","  data_pair = data_split(training_data)\n","\n","  train_data_X = data_pair[0][0]\n","  train_data_Y = data_pair[0][1]\n","\n","  test_data_X = data_pair[1][0]\n","  test_data_Y = data_pair[1][1]\n","\n","  xgb_model_final = XGBRegressor(objective='reg:squarederror', n_estimators=200, colsample_bytree = param_dict['colsample_bytree'], learning_rate=param_dict['learning_rate'], max_depth=param_dict['max_depth'], min_child_weight=param_dict['min_child_weight'], subsample=param_dict['subsample'])\n","  xgb_model_final.fit(train_data_X, train_data_Y,verbose=False)\n","\n","  model_overfit_check(train_data_X,train_data_Y, data_pair)\n","  check_model_performance(xgb_model_final, test_data_X, test_data_Y)\n","\n","\n","  return xgb_model_final\n"]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["b16e4a393e154a6aba14094e2e0b30ad","24a1246eebae40829bf30bf8b0702822"]},"executionInfo":{"elapsed":254707,"status":"ok","timestamp":1651155128057,"user":{"displayName":"Burak Özen","userId":"16794056347198304221"},"user_tz":-120},"id":"h0jOuxgR74VP","outputId":"a1fcf3f4-d6bf-49c1-d3be-1a15b575ba72"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b16e4a393e154a6aba14094e2e0b30ad","version_major":2,"version_minor":0},"text/plain":["Output()"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[0;33m14:08:29 \u001b[1;32mitems_raw_table\u001b[0m: Starting setup of dependencies...\n","\u001b[0;33m14:08:29 \u001b[1;32mitems_raw_table\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:08:29 \u001b[1;32mitems_raw_table\u001b[0m: Successfully logged into https://app.layer.ai\n","\u001b[0;33m14:08:29 \u001b[1;32mitems_raw_table\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:08:29 \u001b[1;32mitems_raw_table\u001b[0m: Downloading execution artifacts data-catalog--layer2022040715233801730000001e/add1b570-c8e7-4187-b747-1d01104893a9/ecommerce_olist_order_review_score_prediction/items_raw_table/9f1c7c8c-8366-4c91-b13c-cea6b00fb38a/items_raw_table.tgz to ~/source\n","\u001b[0;33m14:08:29 \u001b[1;32mitems_raw_table\u001b[0m: Creating directory ~/source\n","\u001b[0;33m14:08:29 \u001b[1;32mitems_raw_table\u001b[0m: Place __init__.py in ~/source\n","\u001b[0;33m14:08:29 \u001b[1;32mitems_raw_table\u001b[0m: Download binary(add1b570-c8e7-4187-b747-1d01104893a9/ecommerce_olist_order_review_score_prediction/items_raw_table/9f1c7c8c-8366-4c91-b13c-cea6b00fb38a/items_raw_table.tgz) to temp directory\n","\u001b[0;33m14:08:30 \u001b[1;32mitems_raw_table\u001b[0m: Binary archive items_raw_table.tgz downloaded and extracted to ~/source successfully\n","\u001b[0;33m14:08:30 \u001b[1;32mitems_raw_table\u001b[0m: Execution artifacts data-catalog--layer2022040715233801730000001e/add1b570-c8e7-4187-b747-1d01104893a9/ecommerce_olist_order_review_score_prediction/items_raw_table/9f1c7c8c-8366-4c91-b13c-cea6b00fb38a/items_raw_table.tgz downloaded successfully to ~/source\n","\u001b[0;33m14:08:30 \u001b[1;32mitems_raw_table\u001b[0m: Installing python dependencies from ~/source/requirements.txt\n","\u001b[0;33m14:08:30 \u001b[1;32mitems_raw_table\u001b[0m: Requirement already satisfied: numpy in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from -r /root/source/requirements.txt (line 1)) (1.21.6)\n","\u001b[0;33m14:08:30 \u001b[1;32mitems_raw_table\u001b[0m: Collecting sklearn\n","\u001b[0;33m14:08:30 \u001b[1;32mitems_raw_table\u001b[0m:   Downloading sklearn-0.0.tar.gz (1.1 kB)\n","\u001b[0;33m14:08:31 \u001b[1;32mitems_raw_table\u001b[0m: Requirement already satisfied: pandas in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from -r /root/source/requirements.txt (line 3)) (1.3.5)\n","\u001b[0;33m14:08:31 \u001b[1;32mitems_raw_table\u001b[0m: Requirement already satisfied: pytz>=2017.3 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from pandas->-r /root/source/requirements.txt (line 3)) (2022.1)\n","\u001b[0;33m14:08:31 \u001b[1;32mitems_raw_table\u001b[0m: Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from pandas->-r /root/source/requirements.txt (line 3)) (2.8.2)\n","\u001b[0;33m14:08:31 \u001b[1;32mitems_raw_table\u001b[0m: Requirement already satisfied: six>=1.5 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->-r /root/source/requirements.txt (line 3)) (1.16.0)\n","\u001b[0;33m14:08:31 \u001b[1;32mitems_raw_table\u001b[0m: Collecting scikit-learn\n","\u001b[0;33m14:08:32 \u001b[1;32mitems_raw_table\u001b[0m:   Downloading scikit_learn-1.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.8 MB)\n","\u001b[0;33m14:08:32 \u001b[1;32mitems_raw_table\u001b[0m: Requirement already satisfied: joblib>=0.11 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from scikit-learn->sklearn->-r /root/source/requirements.txt (line 2)) (1.1.0)\n","\u001b[0;33m14:08:32 \u001b[1;32mitems_raw_table\u001b[0m: Requirement already satisfied: scipy>=1.1.0 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from scikit-learn->sklearn->-r /root/source/requirements.txt (line 2)) (1.7.3)\n","\u001b[0;33m14:08:32 \u001b[1;32mitems_raw_table\u001b[0m: Collecting threadpoolctl>=2.0.0\n","\u001b[0;33m14:08:32 \u001b[1;32mitems_raw_table\u001b[0m:   Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n","\u001b[0;33m14:08:32 \u001b[1;32mitems_raw_table\u001b[0m: Building wheels for collected packages: sklearn\n","\u001b[0;33m14:08:32 \u001b[1;32mitems_raw_table\u001b[0m:   Building wheel for sklearn (setup.py): started\n","\u001b[0;33m14:08:33 \u001b[1;32mitems_raw_table\u001b[0m:   Building wheel for sklearn (setup.py): finished with status 'done'\n","\u001b[0;33m14:08:33 \u001b[1;32mitems_raw_table\u001b[0m:   Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1310 sha256=d1235dea75633d636a27fa656405803ce584d07673985f126f1c73cf5d417b14\n","\u001b[0;33m14:08:33 \u001b[1;32mitems_raw_table\u001b[0m:   Stored in directory: /root/.cache/pip/wheels/46/ef/c3/157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n","\u001b[0;33m14:08:33 \u001b[1;32mitems_raw_table\u001b[0m: Successfully built sklearn\n","\u001b[0;33m14:08:34 \u001b[1;32mitems_raw_table\u001b[0m: Installing collected packages: threadpoolctl, scikit-learn, sklearn\n","\u001b[0;33m14:08:36 \u001b[1;32mitems_raw_table\u001b[0m: Successfully installed scikit-learn-1.0.2 sklearn-0.0 threadpoolctl-3.1.0\n","\u001b[0;33m14:08:36 \u001b[1;32mitems_raw_table\u001b[0m: Python dependencies from ~/source/requirements.txt installed successfully\n","\u001b[0;33m14:08:38 \u001b[1;32mitems_raw_table\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:08:38 \u001b[1;32mitems_raw_table\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:08:38 \u001b[1;32mitems_raw_table\u001b[0m: Importing user code(items_raw_table.pkl) from ~/source\n","\u001b[0;33m14:08:38 \u001b[1;32mitems_raw_table\u001b[0m: build_dataset function imported successfully\n","\u001b[0;33m14:08:38 \u001b[1;32mitems_raw_table\u001b[0m: Downloading resources\n","\u001b[0;33m14:08:38 \u001b[1;32mitems_raw_table\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:08:38 \u001b[1;32mitems_raw_table\u001b[0m: Downloaded /add1b570-c8e7-4187-b747-1d01104893a9/ecommerce_olist_order_review_score_prediction/resources/load_item_table/ecommerce_order_review_score_prediction/olist_order_items_dataset.csv to /root/source/ecommerce_order_review_score_prediction/olist_order_items_dataset.csv, bytes total: 15438671\n","\u001b[0;33m14:08:38 \u001b[1;32mitems_raw_table\u001b[0m: Injecting the dependencies\n","\u001b[0;33m14:08:38 \u001b[1;32mitems_raw_table\u001b[0m: Annotations: {}\n","\u001b[0;33m14:08:38 \u001b[1;32mitems_raw_table\u001b[0m: Entity dependencies: {'models': {}, 'raw_datasets': {}, 'derived_datasets': {}, 'context': None, 'train': None}\n","\u001b[0;33m14:08:38 \u001b[1;32mitems_raw_table\u001b[0m: Injected dependencies successfully: [$]\n","\u001b[0;33m14:08:38 \u001b[1;32mitems_raw_table\u001b[0m: Executing the build_dataset\n","\u001b[0;33m14:08:39 \u001b[1;32mitems_raw_table\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:08:39 \u001b[1;32mitems_raw_table\u001b[0m: Executed build_dataset successfully\n","\u001b[0;33m14:08:39 \u001b[1;32mitems_raw_table\u001b[0m: Storing built derived_dataset\n","\u001b[0;33m14:08:27 \u001b[1;32morders_raw_table\u001b[0m: Starting setup of dependencies...\n","\u001b[0;33m14:08:27 \u001b[1;32morders_raw_table\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:08:27 \u001b[1;32morders_raw_table\u001b[0m: Successfully logged into https://app.layer.ai\n","\u001b[0;33m14:08:27 \u001b[1;32morders_raw_table\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:08:27 \u001b[1;32morders_raw_table\u001b[0m: Downloading execution artifacts data-catalog--layer2022040715233801730000001e/add1b570-c8e7-4187-b747-1d01104893a9/ecommerce_olist_order_review_score_prediction/orders_raw_table/164c33d8-ca6a-4865-888e-99667dbe98ff/orders_raw_table.tgz to ~/source\n","\u001b[0;33m14:08:27 \u001b[1;32morders_raw_table\u001b[0m: Creating directory ~/source\n","\u001b[0;33m14:08:27 \u001b[1;32morders_raw_table\u001b[0m: Place __init__.py in ~/source\n","\u001b[0;33m14:08:27 \u001b[1;32morders_raw_table\u001b[0m: Download binary(add1b570-c8e7-4187-b747-1d01104893a9/ecommerce_olist_order_review_score_prediction/orders_raw_table/164c33d8-ca6a-4865-888e-99667dbe98ff/orders_raw_table.tgz) to temp directory\n","\u001b[0;33m14:08:27 \u001b[1;32morders_raw_table\u001b[0m: Binary archive orders_raw_table.tgz downloaded and extracted to ~/source successfully\n","\u001b[0;33m14:08:27 \u001b[1;32morders_raw_table\u001b[0m: Execution artifacts data-catalog--layer2022040715233801730000001e/add1b570-c8e7-4187-b747-1d01104893a9/ecommerce_olist_order_review_score_prediction/orders_raw_table/164c33d8-ca6a-4865-888e-99667dbe98ff/orders_raw_table.tgz downloaded successfully to ~/source\n","\u001b[0;33m14:08:27 \u001b[1;32morders_raw_table\u001b[0m: Installing python dependencies from ~/source/requirements.txt\n","\u001b[0;33m14:08:28 \u001b[1;32morders_raw_table\u001b[0m: Requirement already satisfied: numpy in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from -r /root/source/requirements.txt (line 1)) (1.21.6)\n","\u001b[0;33m14:08:28 \u001b[1;32morders_raw_table\u001b[0m: Collecting sklearn\n","\u001b[0;33m14:08:28 \u001b[1;32morders_raw_table\u001b[0m:   Downloading sklearn-0.0.tar.gz (1.1 kB)\n","\u001b[0;33m14:08:29 \u001b[1;32morders_raw_table\u001b[0m: Requirement already satisfied: pandas in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from -r /root/source/requirements.txt (line 3)) (1.3.5)\n","\u001b[0;33m14:08:29 \u001b[1;32morders_raw_table\u001b[0m: Requirement already satisfied: pytz>=2017.3 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from pandas->-r /root/source/requirements.txt (line 3)) (2022.1)\n","\u001b[0;33m14:08:29 \u001b[1;32morders_raw_table\u001b[0m: Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from pandas->-r /root/source/requirements.txt (line 3)) (2.8.2)\n","\u001b[0;33m14:08:29 \u001b[1;32morders_raw_table\u001b[0m: Requirement already satisfied: six>=1.5 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->-r /root/source/requirements.txt (line 3)) (1.16.0)\n","\u001b[0;33m14:08:29 \u001b[1;32morders_raw_table\u001b[0m: Collecting scikit-learn\n","\u001b[0;33m14:08:29 \u001b[1;32morders_raw_table\u001b[0m:   Downloading scikit_learn-1.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.8 MB)\n","\u001b[0;33m14:08:30 \u001b[1;32morders_raw_table\u001b[0m: Collecting threadpoolctl>=2.0.0\n","\u001b[0;33m14:08:30 \u001b[1;32morders_raw_table\u001b[0m:   Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n","\u001b[0;33m14:08:30 \u001b[1;32morders_raw_table\u001b[0m: Requirement already satisfied: scipy>=1.1.0 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from scikit-learn->sklearn->-r /root/source/requirements.txt (line 2)) (1.7.3)\n","\u001b[0;33m14:08:30 \u001b[1;32morders_raw_table\u001b[0m: Requirement already satisfied: joblib>=0.11 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from scikit-learn->sklearn->-r /root/source/requirements.txt (line 2)) (1.1.0)\n","\u001b[0;33m14:08:30 \u001b[1;32morders_raw_table\u001b[0m: Building wheels for collected packages: sklearn\n","\u001b[0;33m14:08:30 \u001b[1;32morders_raw_table\u001b[0m:   Building wheel for sklearn (setup.py): started\n","\u001b[0;33m14:08:31 \u001b[1;32morders_raw_table\u001b[0m:   Building wheel for sklearn (setup.py): finished with status 'done'\n","\u001b[0;33m14:08:31 \u001b[1;32morders_raw_table\u001b[0m:   Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1310 sha256=872d00aff8c2638d0eea4154283510e56f96cfbe68de6fe23e8983bb028676d5\n","\u001b[0;33m14:08:31 \u001b[1;32morders_raw_table\u001b[0m:   Stored in directory: /root/.cache/pip/wheels/46/ef/c3/157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n","\u001b[0;33m14:08:31 \u001b[1;32morders_raw_table\u001b[0m: Successfully built sklearn\n","\u001b[0;33m14:08:32 \u001b[1;32morders_raw_table\u001b[0m: Installing collected packages: threadpoolctl, scikit-learn, sklearn\n","\u001b[0;33m14:08:34 \u001b[1;32morders_raw_table\u001b[0m: Successfully installed scikit-learn-1.0.2 sklearn-0.0 threadpoolctl-3.1.0\n","\u001b[0;33m14:08:34 \u001b[1;32morders_raw_table\u001b[0m: Python dependencies from ~/source/requirements.txt installed successfully\n","\u001b[0;33m14:08:36 \u001b[1;32morders_raw_table\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:08:36 \u001b[1;32morders_raw_table\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:08:36 \u001b[1;32morders_raw_table\u001b[0m: Importing user code(orders_raw_table.pkl) from ~/source\n","\u001b[0;33m14:08:36 \u001b[1;32morders_raw_table\u001b[0m: build_dataset function imported successfully\n","\u001b[0;33m14:08:36 \u001b[1;32morders_raw_table\u001b[0m: Downloading resources\n","\u001b[0;33m14:08:36 \u001b[1;32morders_raw_table\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:08:36 \u001b[1;32morders_raw_table\u001b[0m: Downloaded /add1b570-c8e7-4187-b747-1d01104893a9/ecommerce_olist_order_review_score_prediction/resources/load_order_table/ecommerce_order_review_score_prediction/olist_orders_dataset.csv to /root/source/ecommerce_order_review_score_prediction/olist_orders_dataset.csv, bytes total: 17654914\n","\u001b[0;33m14:08:36 \u001b[1;32morders_raw_table\u001b[0m: Injecting the dependencies\n","\u001b[0;33m14:08:36 \u001b[1;32morders_raw_table\u001b[0m: Annotations: {}\n","\u001b[0;33m14:08:36 \u001b[1;32morders_raw_table\u001b[0m: Entity dependencies: {'models': {}, 'raw_datasets': {}, 'derived_datasets': {}, 'context': None, 'train': None}\n","\u001b[0;33m14:08:36 \u001b[1;32morders_raw_table\u001b[0m: Injected dependencies successfully: [$]\n","\u001b[0;33m14:08:36 \u001b[1;32morders_raw_table\u001b[0m: Executing the build_dataset\n","\u001b[0;33m14:08:37 \u001b[1;32morders_raw_table\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:08:37 \u001b[1;32morders_raw_table\u001b[0m: Executed build_dataset successfully\n","\u001b[0;33m14:08:37 \u001b[1;32morders_raw_table\u001b[0m: Storing built derived_dataset\n","\u001b[0;33m14:08:29 \u001b[1;32mreviews_raw_table\u001b[0m: Starting setup of dependencies...\n","\u001b[0;33m14:08:29 \u001b[1;32mreviews_raw_table\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:08:29 \u001b[1;32mreviews_raw_table\u001b[0m: Successfully logged into https://app.layer.ai\n","\u001b[0;33m14:08:29 \u001b[1;32mreviews_raw_table\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:08:29 \u001b[1;32mreviews_raw_table\u001b[0m: Downloading execution artifacts data-catalog--layer2022040715233801730000001e/add1b570-c8e7-4187-b747-1d01104893a9/ecommerce_olist_order_review_score_prediction/reviews_raw_table/a41df71c-d920-4da1-83ef-efe324b9f9c7/reviews_raw_table.tgz to ~/source\n","\u001b[0;33m14:08:29 \u001b[1;32mreviews_raw_table\u001b[0m: Creating directory ~/source\n","\u001b[0;33m14:08:29 \u001b[1;32mreviews_raw_table\u001b[0m: Place __init__.py in ~/source\n","\u001b[0;33m14:08:29 \u001b[1;32mreviews_raw_table\u001b[0m: Download binary(add1b570-c8e7-4187-b747-1d01104893a9/ecommerce_olist_order_review_score_prediction/reviews_raw_table/a41df71c-d920-4da1-83ef-efe324b9f9c7/reviews_raw_table.tgz) to temp directory\n","\u001b[0;33m14:08:29 \u001b[1;32mreviews_raw_table\u001b[0m: Binary archive reviews_raw_table.tgz downloaded and extracted to ~/source successfully\n","\u001b[0;33m14:08:29 \u001b[1;32mreviews_raw_table\u001b[0m: Execution artifacts data-catalog--layer2022040715233801730000001e/add1b570-c8e7-4187-b747-1d01104893a9/ecommerce_olist_order_review_score_prediction/reviews_raw_table/a41df71c-d920-4da1-83ef-efe324b9f9c7/reviews_raw_table.tgz downloaded successfully to ~/source\n","\u001b[0;33m14:08:29 \u001b[1;32mreviews_raw_table\u001b[0m: Installing python dependencies from ~/source/requirements.txt\n","\u001b[0;33m14:08:30 \u001b[1;32mreviews_raw_table\u001b[0m: Requirement already satisfied: numpy in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from -r /root/source/requirements.txt (line 1)) (1.21.6)\n","\u001b[0;33m14:08:30 \u001b[1;32mreviews_raw_table\u001b[0m: Collecting sklearn\n","\u001b[0;33m14:08:30 \u001b[1;32mreviews_raw_table\u001b[0m:   Downloading sklearn-0.0.tar.gz (1.1 kB)\n","\u001b[0;33m14:08:31 \u001b[1;32mreviews_raw_table\u001b[0m: Requirement already satisfied: pandas in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from -r /root/source/requirements.txt (line 3)) (1.3.5)\n","\u001b[0;33m14:08:31 \u001b[1;32mreviews_raw_table\u001b[0m: Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from pandas->-r /root/source/requirements.txt (line 3)) (2.8.2)\n","\u001b[0;33m14:08:31 \u001b[1;32mreviews_raw_table\u001b[0m: Requirement already satisfied: pytz>=2017.3 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from pandas->-r /root/source/requirements.txt (line 3)) (2022.1)\n","\u001b[0;33m14:08:31 \u001b[1;32mreviews_raw_table\u001b[0m: Requirement already satisfied: six>=1.5 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->-r /root/source/requirements.txt (line 3)) (1.16.0)\n","\u001b[0;33m14:08:31 \u001b[1;32mreviews_raw_table\u001b[0m: Collecting scikit-learn\n","\u001b[0;33m14:08:31 \u001b[1;32mreviews_raw_table\u001b[0m:   Downloading scikit_learn-1.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.8 MB)\n","\u001b[0;33m14:08:32 \u001b[1;32mreviews_raw_table\u001b[0m: Requirement already satisfied: scipy>=1.1.0 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from scikit-learn->sklearn->-r /root/source/requirements.txt (line 2)) (1.7.3)\n","\u001b[0;33m14:08:32 \u001b[1;32mreviews_raw_table\u001b[0m: Collecting threadpoolctl>=2.0.0\n","\u001b[0;33m14:08:32 \u001b[1;32mreviews_raw_table\u001b[0m:   Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n","\u001b[0;33m14:08:32 \u001b[1;32mreviews_raw_table\u001b[0m: Requirement already satisfied: joblib>=0.11 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from scikit-learn->sklearn->-r /root/source/requirements.txt (line 2)) (1.1.0)\n","\u001b[0;33m14:08:32 \u001b[1;32mreviews_raw_table\u001b[0m: Building wheels for collected packages: sklearn\n","\u001b[0;33m14:08:32 \u001b[1;32mreviews_raw_table\u001b[0m:   Building wheel for sklearn (setup.py): started\n","\u001b[0;33m14:08:33 \u001b[1;32mreviews_raw_table\u001b[0m:   Building wheel for sklearn (setup.py): finished with status 'done'\n","\u001b[0;33m14:08:33 \u001b[1;32mreviews_raw_table\u001b[0m:   Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1310 sha256=d1235dea75633d636a27fa656405803ce584d07673985f126f1c73cf5d417b14\n","\u001b[0;33m14:08:33 \u001b[1;32mreviews_raw_table\u001b[0m:   Stored in directory: /root/.cache/pip/wheels/46/ef/c3/157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n","\u001b[0;33m14:08:33 \u001b[1;32mreviews_raw_table\u001b[0m: Successfully built sklearn\n","\u001b[0;33m14:08:34 \u001b[1;32mreviews_raw_table\u001b[0m: Installing collected packages: threadpoolctl, scikit-learn, sklearn\n","\u001b[0;33m14:08:35 \u001b[1;32mreviews_raw_table\u001b[0m: Successfully installed scikit-learn-1.0.2 sklearn-0.0 threadpoolctl-3.1.0\n","\u001b[0;33m14:08:36 \u001b[1;32mreviews_raw_table\u001b[0m: Python dependencies from ~/source/requirements.txt installed successfully\n","\u001b[0;33m14:08:38 \u001b[1;32mreviews_raw_table\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:08:38 \u001b[1;32mreviews_raw_table\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:08:38 \u001b[1;32mreviews_raw_table\u001b[0m: Importing user code(reviews_raw_table.pkl) from ~/source\n","\u001b[0;33m14:08:38 \u001b[1;32mreviews_raw_table\u001b[0m: build_dataset function imported successfully\n","\u001b[0;33m14:08:38 \u001b[1;32mreviews_raw_table\u001b[0m: Downloading resources\n","\u001b[0;33m14:08:38 \u001b[1;32mreviews_raw_table\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:08:38 \u001b[1;32mreviews_raw_table\u001b[0m: Downloaded /add1b570-c8e7-4187-b747-1d01104893a9/ecommerce_olist_order_review_score_prediction/resources/load_reviews_table/ecommerce_order_review_score_prediction/olist_order_reviews_dataset.csv to /root/source/ecommerce_order_review_score_prediction/olist_order_reviews_dataset.csv, bytes total: 14409007\n","\u001b[0;33m14:08:38 \u001b[1;32mreviews_raw_table\u001b[0m: Injecting the dependencies\n","\u001b[0;33m14:08:38 \u001b[1;32mreviews_raw_table\u001b[0m: Annotations: {}\n","\u001b[0;33m14:08:38 \u001b[1;32mreviews_raw_table\u001b[0m: Entity dependencies: {'models': {}, 'raw_datasets': {}, 'derived_datasets': {}, 'context': None, 'train': None}\n","\u001b[0;33m14:08:38 \u001b[1;32mreviews_raw_table\u001b[0m: Injected dependencies successfully: [$]\n","\u001b[0;33m14:08:38 \u001b[1;32mreviews_raw_table\u001b[0m: Executing the build_dataset\n","\u001b[0;33m14:08:38 \u001b[1;32mreviews_raw_table\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:08:39 \u001b[1;32mreviews_raw_table\u001b[0m: Executed build_dataset successfully\n","\u001b[0;33m14:08:39 \u001b[1;32mreviews_raw_table\u001b[0m: Storing built derived_dataset\n","\u001b[0;33m14:08:48 \u001b[1;32mitems_raw_table\u001b[0m: Built derived_dataset stored successfully\n","\u001b[0;33m14:08:45 \u001b[1;32morders_raw_table\u001b[0m: Built derived_dataset stored successfully\n","\u001b[0;33m14:08:48 \u001b[1;32mreviews_raw_table\u001b[0m: Built derived_dataset stored successfully\n","\u001b[0;33m14:09:06 \u001b[1;32morders_clean_table\u001b[0m: Starting setup of dependencies...\n","\u001b[0;33m14:09:06 \u001b[1;32morders_clean_table\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:09:06 \u001b[1;32morders_clean_table\u001b[0m: Successfully logged into https://app.layer.ai\n","\u001b[0;33m14:09:06 \u001b[1;32morders_clean_table\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:09:06 \u001b[1;32morders_clean_table\u001b[0m: Downloading execution artifacts data-catalog--layer2022040715233801730000001e/add1b570-c8e7-4187-b747-1d01104893a9/ecommerce_olist_order_review_score_prediction/orders_clean_table/8f3be31d-0716-4463-a509-b040f00abdcd/orders_clean_table.tgz to ~/source\n","\u001b[0;33m14:09:06 \u001b[1;32morders_clean_table\u001b[0m: Creating directory ~/source\n","\u001b[0;33m14:09:06 \u001b[1;32morders_clean_table\u001b[0m: Place __init__.py in ~/source\n","\u001b[0;33m14:09:06 \u001b[1;32morders_clean_table\u001b[0m: Download binary(add1b570-c8e7-4187-b747-1d01104893a9/ecommerce_olist_order_review_score_prediction/orders_clean_table/8f3be31d-0716-4463-a509-b040f00abdcd/orders_clean_table.tgz) to temp directory\n","\u001b[0;33m14:09:06 \u001b[1;32morders_clean_table\u001b[0m: Binary archive orders_clean_table.tgz downloaded and extracted to ~/source successfully\n","\u001b[0;33m14:09:06 \u001b[1;32morders_clean_table\u001b[0m: Execution artifacts data-catalog--layer2022040715233801730000001e/add1b570-c8e7-4187-b747-1d01104893a9/ecommerce_olist_order_review_score_prediction/orders_clean_table/8f3be31d-0716-4463-a509-b040f00abdcd/orders_clean_table.tgz downloaded successfully to ~/source\n","\u001b[0;33m14:09:06 \u001b[1;32morders_clean_table\u001b[0m: Installing python dependencies from ~/source/requirements.txt\n","\u001b[0;33m14:09:06 \u001b[1;32morders_clean_table\u001b[0m: Requirement already satisfied: numpy in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from -r /root/source/requirements.txt (line 1)) (1.21.6)\n","\u001b[0;33m14:09:06 \u001b[1;32morders_clean_table\u001b[0m: Collecting sklearn\n","\u001b[0;33m14:09:06 \u001b[1;32morders_clean_table\u001b[0m:   Downloading sklearn-0.0.tar.gz (1.1 kB)\n","\u001b[0;33m14:09:08 \u001b[1;32morders_clean_table\u001b[0m: Requirement already satisfied: pandas in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from -r /root/source/requirements.txt (line 3)) (1.3.5)\n","\u001b[0;33m14:09:08 \u001b[1;32morders_clean_table\u001b[0m: Requirement already satisfied: pytz>=2017.3 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from pandas->-r /root/source/requirements.txt (line 3)) (2022.1)\n","\u001b[0;33m14:09:08 \u001b[1;32morders_clean_table\u001b[0m: Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from pandas->-r /root/source/requirements.txt (line 3)) (2.8.2)\n","\u001b[0;33m14:09:08 \u001b[1;32morders_clean_table\u001b[0m: Requirement already satisfied: six>=1.5 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->-r /root/source/requirements.txt (line 3)) (1.16.0)\n","\u001b[0;33m14:09:08 \u001b[1;32morders_clean_table\u001b[0m: Collecting scikit-learn\n","\u001b[0;33m14:09:08 \u001b[1;32morders_clean_table\u001b[0m:   Downloading scikit_learn-1.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.8 MB)\n","\u001b[0;33m14:09:08 \u001b[1;32morders_clean_table\u001b[0m: Collecting threadpoolctl>=2.0.0\n","\u001b[0;33m14:09:08 \u001b[1;32morders_clean_table\u001b[0m:   Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n","\u001b[0;33m14:09:08 \u001b[1;32morders_clean_table\u001b[0m: Requirement already satisfied: joblib>=0.11 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from scikit-learn->sklearn->-r /root/source/requirements.txt (line 2)) (1.1.0)\n","\u001b[0;33m14:09:08 \u001b[1;32morders_clean_table\u001b[0m: Requirement already satisfied: scipy>=1.1.0 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from scikit-learn->sklearn->-r /root/source/requirements.txt (line 2)) (1.7.3)\n","\u001b[0;33m14:09:08 \u001b[1;32morders_clean_table\u001b[0m: Building wheels for collected packages: sklearn\n","\u001b[0;33m14:09:08 \u001b[1;32morders_clean_table\u001b[0m:   Building wheel for sklearn (setup.py): started\n","\u001b[0;33m14:09:10 \u001b[1;32morders_clean_table\u001b[0m:   Building wheel for sklearn (setup.py): finished with status 'done'\n","\u001b[0;33m14:09:10 \u001b[1;32morders_clean_table\u001b[0m:   Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1310 sha256=3d75de9c6dbffdd353042416a656ae02382f3aeff9befbd63ac4892db5e4a985\n","\u001b[0;33m14:09:10 \u001b[1;32morders_clean_table\u001b[0m:   Stored in directory: /root/.cache/pip/wheels/46/ef/c3/157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n","\u001b[0;33m14:09:10 \u001b[1;32morders_clean_table\u001b[0m: Successfully built sklearn\n","\u001b[0;33m14:09:10 \u001b[1;32morders_clean_table\u001b[0m: Installing collected packages: threadpoolctl, scikit-learn, sklearn\n","\u001b[0;33m14:09:12 \u001b[1;32morders_clean_table\u001b[0m: Successfully installed scikit-learn-1.0.2 sklearn-0.0 threadpoolctl-3.1.0\n","\u001b[0;33m14:09:12 \u001b[1;32morders_clean_table\u001b[0m: Python dependencies from ~/source/requirements.txt installed successfully\n","\u001b[0;33m14:09:14 \u001b[1;32morders_clean_table\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:09:14 \u001b[1;32morders_clean_table\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:09:14 \u001b[1;32morders_clean_table\u001b[0m: Importing user code(orders_clean_table.pkl) from ~/source\n","\u001b[0;33m14:09:14 \u001b[1;32morders_clean_table\u001b[0m: build_dataset function imported successfully\n","\u001b[0;33m14:09:14 \u001b[1;32morders_clean_table\u001b[0m: Downloading resources\n","\u001b[0;33m14:09:14 \u001b[1;32morders_clean_table\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:09:14 \u001b[1;32morders_clean_table\u001b[0m: Injecting the dependencies\n","\u001b[0;33m14:09:14 \u001b[1;32morders_clean_table\u001b[0m: Annotations: {}\n","\u001b[0;33m14:09:14 \u001b[1;32morders_clean_table\u001b[0m: Entity dependencies: {'models': {}, 'raw_datasets': {}, 'derived_datasets': {}, 'context': None, 'train': None}\n","\u001b[0;33m14:09:14 \u001b[1;32morders_clean_table\u001b[0m: Injected dependencies successfully: [$]\n","\u001b[0;33m14:09:14 \u001b[1;32morders_clean_table\u001b[0m: Executing the build_dataset\n","\u001b[0;33m14:09:14 \u001b[1;32morders_clean_table\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:09:19 \u001b[1;32morders_clean_table\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:09:19 \u001b[1;32morders_clean_table\u001b[0m: Executed build_dataset successfully\n","\u001b[0;33m14:09:19 \u001b[1;32morders_clean_table\u001b[0m: Storing built derived_dataset\n","\u001b[0;33m14:09:23 \u001b[1;32morders_clean_table\u001b[0m: Built derived_dataset stored successfully\n","\u001b[0;33m14:09:21 \u001b[1;32mitems_clean_table\u001b[0m: Starting setup of dependencies...\n","\u001b[0;33m14:09:21 \u001b[1;32mitems_clean_table\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:09:21 \u001b[1;32mitems_clean_table\u001b[0m: Successfully logged into https://app.layer.ai\n","\u001b[0;33m14:09:21 \u001b[1;32mitems_clean_table\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:09:21 \u001b[1;32mitems_clean_table\u001b[0m: Downloading execution artifacts data-catalog--layer2022040715233801730000001e/add1b570-c8e7-4187-b747-1d01104893a9/ecommerce_olist_order_review_score_prediction/items_clean_table/04e58eec-7fa7-4f3e-8c14-f288f61544c9/items_clean_table.tgz to ~/source\n","\u001b[0;33m14:09:21 \u001b[1;32mitems_clean_table\u001b[0m: Creating directory ~/source\n","\u001b[0;33m14:09:21 \u001b[1;32mitems_clean_table\u001b[0m: Place __init__.py in ~/source\n","\u001b[0;33m14:09:21 \u001b[1;32mitems_clean_table\u001b[0m: Download binary(add1b570-c8e7-4187-b747-1d01104893a9/ecommerce_olist_order_review_score_prediction/items_clean_table/04e58eec-7fa7-4f3e-8c14-f288f61544c9/items_clean_table.tgz) to temp directory\n","\u001b[0;33m14:09:21 \u001b[1;32mitems_clean_table\u001b[0m: Binary archive items_clean_table.tgz downloaded and extracted to ~/source successfully\n","\u001b[0;33m14:09:21 \u001b[1;32mitems_clean_table\u001b[0m: Execution artifacts data-catalog--layer2022040715233801730000001e/add1b570-c8e7-4187-b747-1d01104893a9/ecommerce_olist_order_review_score_prediction/items_clean_table/04e58eec-7fa7-4f3e-8c14-f288f61544c9/items_clean_table.tgz downloaded successfully to ~/source\n","\u001b[0;33m14:09:21 \u001b[1;32mitems_clean_table\u001b[0m: Installing python dependencies from ~/source/requirements.txt\n","\u001b[0;33m14:09:21 \u001b[1;32mitems_clean_table\u001b[0m: Requirement already satisfied: numpy in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from -r /root/source/requirements.txt (line 1)) (1.21.6)\n","\u001b[0;33m14:09:22 \u001b[1;32mitems_clean_table\u001b[0m: Collecting sklearn\n","\u001b[0;33m14:09:22 \u001b[1;32mitems_clean_table\u001b[0m:   Downloading sklearn-0.0.tar.gz (1.1 kB)\n","\u001b[0;33m14:09:23 \u001b[1;32mitems_clean_table\u001b[0m: Requirement already satisfied: pandas in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from -r /root/source/requirements.txt (line 3)) (1.3.5)\n","\u001b[0;33m14:09:23 \u001b[1;32mitems_clean_table\u001b[0m: Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from pandas->-r /root/source/requirements.txt (line 3)) (2.8.2)\n","\u001b[0;33m14:09:23 \u001b[1;32mitems_clean_table\u001b[0m: Requirement already satisfied: pytz>=2017.3 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from pandas->-r /root/source/requirements.txt (line 3)) (2022.1)\n","\u001b[0;33m14:09:23 \u001b[1;32mitems_clean_table\u001b[0m: Requirement already satisfied: six>=1.5 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->-r /root/source/requirements.txt (line 3)) (1.16.0)\n","\u001b[0;33m14:09:23 \u001b[1;32mitems_clean_table\u001b[0m: Collecting scikit-learn\n","\u001b[0;33m14:09:23 \u001b[1;32mitems_clean_table\u001b[0m:   Downloading scikit_learn-1.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.8 MB)\n","\u001b[0;33m14:09:24 \u001b[1;32mitems_clean_table\u001b[0m: Collecting threadpoolctl>=2.0.0\n","\u001b[0;33m14:09:24 \u001b[1;32mitems_clean_table\u001b[0m:   Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n","\u001b[0;33m14:09:24 \u001b[1;32mitems_clean_table\u001b[0m: Requirement already satisfied: joblib>=0.11 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from scikit-learn->sklearn->-r /root/source/requirements.txt (line 2)) (1.1.0)\n","\u001b[0;33m14:09:24 \u001b[1;32mitems_clean_table\u001b[0m: Requirement already satisfied: scipy>=1.1.0 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from scikit-learn->sklearn->-r /root/source/requirements.txt (line 2)) (1.7.3)\n","\u001b[0;33m14:09:24 \u001b[1;32mitems_clean_table\u001b[0m: Building wheels for collected packages: sklearn\n","\u001b[0;33m14:09:24 \u001b[1;32mitems_clean_table\u001b[0m:   Building wheel for sklearn (setup.py): started\n","\u001b[0;33m14:09:25 \u001b[1;32mitems_clean_table\u001b[0m:   Building wheel for sklearn (setup.py): finished with status 'done'\n","\u001b[0;33m14:09:25 \u001b[1;32mitems_clean_table\u001b[0m:   Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1310 sha256=41dec6df08430a26302d0ea694f7c7097c1351f7301578ae201ed8958235e38f\n","\u001b[0;33m14:09:25 \u001b[1;32mitems_clean_table\u001b[0m:   Stored in directory: /root/.cache/pip/wheels/46/ef/c3/157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n","\u001b[0;33m14:09:25 \u001b[1;32mitems_clean_table\u001b[0m: Successfully built sklearn\n","\u001b[0;33m14:09:26 \u001b[1;32mitems_clean_table\u001b[0m: Installing collected packages: threadpoolctl, scikit-learn, sklearn\n","\u001b[0;33m14:09:27 \u001b[1;32mitems_clean_table\u001b[0m: Successfully installed scikit-learn-1.0.2 sklearn-0.0 threadpoolctl-3.1.0\n","\u001b[0;33m14:09:28 \u001b[1;32mitems_clean_table\u001b[0m: Python dependencies from ~/source/requirements.txt installed successfully\n","\u001b[0;33m14:09:29 \u001b[1;32mitems_clean_table\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:09:29 \u001b[1;32mitems_clean_table\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:09:29 \u001b[1;32mitems_clean_table\u001b[0m: Importing user code(items_clean_table.pkl) from ~/source\n","\u001b[0;33m14:09:29 \u001b[1;32mitems_clean_table\u001b[0m: build_dataset function imported successfully\n","\u001b[0;33m14:09:30 \u001b[1;32mitems_clean_table\u001b[0m: Downloading resources\n","\u001b[0;33m14:09:30 \u001b[1;32mitems_clean_table\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:09:30 \u001b[1;32mitems_clean_table\u001b[0m: Injecting the dependencies\n","\u001b[0;33m14:09:30 \u001b[1;32mitems_clean_table\u001b[0m: Annotations: {}\n","\u001b[0;33m14:09:30 \u001b[1;32mitems_clean_table\u001b[0m: Entity dependencies: {'models': {}, 'raw_datasets': {}, 'derived_datasets': {}, 'context': None, 'train': None}\n","\u001b[0;33m14:09:30 \u001b[1;32mitems_clean_table\u001b[0m: Injected dependencies successfully: [$]\n","\u001b[0;33m14:09:30 \u001b[1;32mitems_clean_table\u001b[0m: Executing the build_dataset\n","\u001b[0;33m14:09:30 \u001b[1;32mitems_clean_table\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:09:30 \u001b[1;32mitems_clean_table\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:09:31 \u001b[1;32mitems_clean_table\u001b[0m: Executed build_dataset successfully\n","\u001b[0;33m14:09:31 \u001b[1;32mitems_clean_table\u001b[0m: Storing built derived_dataset\n","\u001b[0;33m14:09:21 \u001b[1;32mreviews_clean_table\u001b[0m: Starting setup of dependencies...\n","\u001b[0;33m14:09:21 \u001b[1;32mreviews_clean_table\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:09:21 \u001b[1;32mreviews_clean_table\u001b[0m: Successfully logged into https://app.layer.ai\n","\u001b[0;33m14:09:21 \u001b[1;32mreviews_clean_table\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:09:21 \u001b[1;32mreviews_clean_table\u001b[0m: Downloading execution artifacts data-catalog--layer2022040715233801730000001e/add1b570-c8e7-4187-b747-1d01104893a9/ecommerce_olist_order_review_score_prediction/reviews_clean_table/0b8f260e-dab4-46ed-82b5-7b9170c55077/reviews_clean_table.tgz to ~/source\n","\u001b[0;33m14:09:21 \u001b[1;32mreviews_clean_table\u001b[0m: Creating directory ~/source\n","\u001b[0;33m14:09:21 \u001b[1;32mreviews_clean_table\u001b[0m: Place __init__.py in ~/source\n","\u001b[0;33m14:09:21 \u001b[1;32mreviews_clean_table\u001b[0m: Download binary(add1b570-c8e7-4187-b747-1d01104893a9/ecommerce_olist_order_review_score_prediction/reviews_clean_table/0b8f260e-dab4-46ed-82b5-7b9170c55077/reviews_clean_table.tgz) to temp directory\n","\u001b[0;33m14:09:21 \u001b[1;32mreviews_clean_table\u001b[0m: Binary archive reviews_clean_table.tgz downloaded and extracted to ~/source successfully\n","\u001b[0;33m14:09:21 \u001b[1;32mreviews_clean_table\u001b[0m: Execution artifacts data-catalog--layer2022040715233801730000001e/add1b570-c8e7-4187-b747-1d01104893a9/ecommerce_olist_order_review_score_prediction/reviews_clean_table/0b8f260e-dab4-46ed-82b5-7b9170c55077/reviews_clean_table.tgz downloaded successfully to ~/source\n","\u001b[0;33m14:09:21 \u001b[1;32mreviews_clean_table\u001b[0m: Installing python dependencies from ~/source/requirements.txt\n","\u001b[0;33m14:09:21 \u001b[1;32mreviews_clean_table\u001b[0m: Requirement already satisfied: numpy in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from -r /root/source/requirements.txt (line 1)) (1.21.6)\n","\u001b[0;33m14:09:22 \u001b[1;32mreviews_clean_table\u001b[0m: Collecting sklearn\n","\u001b[0;33m14:09:22 \u001b[1;32mreviews_clean_table\u001b[0m:   Downloading sklearn-0.0.tar.gz (1.1 kB)\n","\u001b[0;33m14:09:23 \u001b[1;32mreviews_clean_table\u001b[0m: Requirement already satisfied: pandas in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from -r /root/source/requirements.txt (line 3)) (1.3.5)\n","\u001b[0;33m14:09:23 \u001b[1;32mreviews_clean_table\u001b[0m: Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from pandas->-r /root/source/requirements.txt (line 3)) (2.8.2)\n","\u001b[0;33m14:09:23 \u001b[1;32mreviews_clean_table\u001b[0m: Requirement already satisfied: pytz>=2017.3 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from pandas->-r /root/source/requirements.txt (line 3)) (2022.1)\n","\u001b[0;33m14:09:23 \u001b[1;32mreviews_clean_table\u001b[0m: Requirement already satisfied: six>=1.5 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->-r /root/source/requirements.txt (line 3)) (1.16.0)\n","\u001b[0;33m14:09:23 \u001b[1;32mreviews_clean_table\u001b[0m: Collecting scikit-learn\n","\u001b[0;33m14:09:23 \u001b[1;32mreviews_clean_table\u001b[0m:   Downloading scikit_learn-1.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.8 MB)\n","\u001b[0;33m14:09:23 \u001b[1;32mreviews_clean_table\u001b[0m: Requirement already satisfied: scipy>=1.1.0 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from scikit-learn->sklearn->-r /root/source/requirements.txt (line 2)) (1.7.3)\n","\u001b[0;33m14:09:24 \u001b[1;32mreviews_clean_table\u001b[0m: Collecting threadpoolctl>=2.0.0\n","\u001b[0;33m14:09:24 \u001b[1;32mreviews_clean_table\u001b[0m:   Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n","\u001b[0;33m14:09:24 \u001b[1;32mreviews_clean_table\u001b[0m: Requirement already satisfied: joblib>=0.11 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from scikit-learn->sklearn->-r /root/source/requirements.txt (line 2)) (1.1.0)\n","\u001b[0;33m14:09:24 \u001b[1;32mreviews_clean_table\u001b[0m: Building wheels for collected packages: sklearn\n","\u001b[0;33m14:09:24 \u001b[1;32mreviews_clean_table\u001b[0m:   Building wheel for sklearn (setup.py): started\n","\u001b[0;33m14:09:25 \u001b[1;32mreviews_clean_table\u001b[0m:   Building wheel for sklearn (setup.py): finished with status 'done'\n","\u001b[0;33m14:09:25 \u001b[1;32mreviews_clean_table\u001b[0m:   Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1310 sha256=41dec6df08430a26302d0ea694f7c7097c1351f7301578ae201ed8958235e38f\n","\u001b[0;33m14:09:25 \u001b[1;32mreviews_clean_table\u001b[0m:   Stored in directory: /root/.cache/pip/wheels/46/ef/c3/157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n","\u001b[0;33m14:09:25 \u001b[1;32mreviews_clean_table\u001b[0m: Successfully built sklearn\n","\u001b[0;33m14:09:26 \u001b[1;32mreviews_clean_table\u001b[0m: Installing collected packages: threadpoolctl, scikit-learn, sklearn\n","\u001b[0;33m14:09:27 \u001b[1;32mreviews_clean_table\u001b[0m: Successfully installed scikit-learn-1.0.2 sklearn-0.0 threadpoolctl-3.1.0\n","\u001b[0;33m14:09:28 \u001b[1;32mreviews_clean_table\u001b[0m: Python dependencies from ~/source/requirements.txt installed successfully\n","\u001b[0;33m14:09:30 \u001b[1;32mreviews_clean_table\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:09:30 \u001b[1;32mreviews_clean_table\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:09:30 \u001b[1;32mreviews_clean_table\u001b[0m: Importing user code(reviews_clean_table.pkl) from ~/source\n","\u001b[0;33m14:09:30 \u001b[1;32mreviews_clean_table\u001b[0m: build_dataset function imported successfully\n","\u001b[0;33m14:09:30 \u001b[1;32mreviews_clean_table\u001b[0m: Downloading resources\n","\u001b[0;33m14:09:30 \u001b[1;32mreviews_clean_table\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:09:30 \u001b[1;32mreviews_clean_table\u001b[0m: Injecting the dependencies\n","\u001b[0;33m14:09:30 \u001b[1;32mreviews_clean_table\u001b[0m: Annotations: {}\n","\u001b[0;33m14:09:30 \u001b[1;32mreviews_clean_table\u001b[0m: Entity dependencies: {'models': {}, 'raw_datasets': {}, 'derived_datasets': {}, 'context': None, 'train': None}\n","\u001b[0;33m14:09:30 \u001b[1;32mreviews_clean_table\u001b[0m: Injected dependencies successfully: [$]\n","\u001b[0;33m14:09:30 \u001b[1;32mreviews_clean_table\u001b[0m: Executing the build_dataset\n","\u001b[0;33m14:09:30 \u001b[1;32mreviews_clean_table\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:09:31 \u001b[1;32mreviews_clean_table\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:09:31 \u001b[1;32mreviews_clean_table\u001b[0m: Executed build_dataset successfully\n","\u001b[0;33m14:09:31 \u001b[1;32mreviews_clean_table\u001b[0m: Storing built derived_dataset\n","\u001b[0;33m14:09:40 \u001b[1;32mitems_clean_table\u001b[0m: Built derived_dataset stored successfully\n","\u001b[0;33m14:09:40 \u001b[1;32mreviews_clean_table\u001b[0m: Built derived_dataset stored successfully\n","\u001b[0;33m14:09:44 \u001b[1;32mitems_based_features\u001b[0m: Starting setup of dependencies...\n","\u001b[0;33m14:09:44 \u001b[1;32mitems_based_features\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:09:44 \u001b[1;32mitems_based_features\u001b[0m: Successfully logged into https://app.layer.ai\n","\u001b[0;33m14:09:44 \u001b[1;32mitems_based_features\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:09:44 \u001b[1;32mitems_based_features\u001b[0m: Downloading execution artifacts data-catalog--layer2022040715233801730000001e/add1b570-c8e7-4187-b747-1d01104893a9/ecommerce_olist_order_review_score_prediction/items_based_features/459d1502-a125-4752-8245-c7d61ebdb0ab/items_based_features.tgz to ~/source\n","\u001b[0;33m14:09:44 \u001b[1;32mitems_based_features\u001b[0m: Creating directory ~/source\n","\u001b[0;33m14:09:44 \u001b[1;32mitems_based_features\u001b[0m: Place __init__.py in ~/source\n","\u001b[0;33m14:09:44 \u001b[1;32mitems_based_features\u001b[0m: Download binary(add1b570-c8e7-4187-b747-1d01104893a9/ecommerce_olist_order_review_score_prediction/items_based_features/459d1502-a125-4752-8245-c7d61ebdb0ab/items_based_features.tgz) to temp directory\n","\u001b[0;33m14:09:44 \u001b[1;32mitems_based_features\u001b[0m: Binary archive items_based_features.tgz downloaded and extracted to ~/source successfully\n","\u001b[0;33m14:09:44 \u001b[1;32mitems_based_features\u001b[0m: Execution artifacts data-catalog--layer2022040715233801730000001e/add1b570-c8e7-4187-b747-1d01104893a9/ecommerce_olist_order_review_score_prediction/items_based_features/459d1502-a125-4752-8245-c7d61ebdb0ab/items_based_features.tgz downloaded successfully to ~/source\n","\u001b[0;33m14:09:44 \u001b[1;32mitems_based_features\u001b[0m: Installing python dependencies from ~/source/requirements.txt\n","\u001b[0;33m14:09:45 \u001b[1;32mitems_based_features\u001b[0m: Requirement already satisfied: numpy in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from -r /root/source/requirements.txt (line 1)) (1.21.6)\n","\u001b[0;33m14:09:45 \u001b[1;32mitems_based_features\u001b[0m: Collecting sklearn\n","\u001b[0;33m14:09:45 \u001b[1;32mitems_based_features\u001b[0m:   Downloading sklearn-0.0.tar.gz (1.1 kB)\n","\u001b[0;33m14:09:46 \u001b[1;32mitems_based_features\u001b[0m: Requirement already satisfied: pandas in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from -r /root/source/requirements.txt (line 3)) (1.3.5)\n","\u001b[0;33m14:09:46 \u001b[1;32mitems_based_features\u001b[0m: Requirement already satisfied: pytz>=2017.3 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from pandas->-r /root/source/requirements.txt (line 3)) (2022.1)\n","\u001b[0;33m14:09:46 \u001b[1;32mitems_based_features\u001b[0m: Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from pandas->-r /root/source/requirements.txt (line 3)) (2.8.2)\n","\u001b[0;33m14:09:46 \u001b[1;32mitems_based_features\u001b[0m: Requirement already satisfied: six>=1.5 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->-r /root/source/requirements.txt (line 3)) (1.16.0)\n","\u001b[0;33m14:09:46 \u001b[1;32mitems_based_features\u001b[0m: Collecting scikit-learn\n","\u001b[0;33m14:09:46 \u001b[1;32mitems_based_features\u001b[0m:   Downloading scikit_learn-1.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.8 MB)\n","\u001b[0;33m14:09:47 \u001b[1;32mitems_based_features\u001b[0m: Collecting threadpoolctl>=2.0.0\n","\u001b[0;33m14:09:47 \u001b[1;32mitems_based_features\u001b[0m:   Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n","\u001b[0;33m14:09:47 \u001b[1;32mitems_based_features\u001b[0m: Requirement already satisfied: scipy>=1.1.0 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from scikit-learn->sklearn->-r /root/source/requirements.txt (line 2)) (1.7.3)\n","\u001b[0;33m14:09:47 \u001b[1;32mitems_based_features\u001b[0m: Requirement already satisfied: joblib>=0.11 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from scikit-learn->sklearn->-r /root/source/requirements.txt (line 2)) (1.1.0)\n","\u001b[0;33m14:09:47 \u001b[1;32mitems_based_features\u001b[0m: Building wheels for collected packages: sklearn\n","\u001b[0;33m14:09:47 \u001b[1;32mitems_based_features\u001b[0m:   Building wheel for sklearn (setup.py): started\n","\u001b[0;33m14:09:48 \u001b[1;32mitems_based_features\u001b[0m:   Building wheel for sklearn (setup.py): finished with status 'done'\n","\u001b[0;33m14:09:48 \u001b[1;32mitems_based_features\u001b[0m:   Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1310 sha256=1551f4647ec3110f9b61da1b9b715410c0d9740017fc349239049340d3046fb4\n","\u001b[0;33m14:09:48 \u001b[1;32mitems_based_features\u001b[0m:   Stored in directory: /root/.cache/pip/wheels/46/ef/c3/157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n","\u001b[0;33m14:09:48 \u001b[1;32mitems_based_features\u001b[0m: Successfully built sklearn\n","\u001b[0;33m14:09:49 \u001b[1;32mitems_based_features\u001b[0m: Installing collected packages: threadpoolctl, scikit-learn, sklearn\n","\u001b[0;33m14:09:50 \u001b[1;32mitems_based_features\u001b[0m: Successfully installed scikit-learn-1.0.2 sklearn-0.0 threadpoolctl-3.1.0\n","\u001b[0;33m14:09:51 \u001b[1;32mitems_based_features\u001b[0m: Python dependencies from ~/source/requirements.txt installed successfully\n","\u001b[0;33m14:09:53 \u001b[1;32mitems_based_features\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:09:53 \u001b[1;32mitems_based_features\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:09:53 \u001b[1;32mitems_based_features\u001b[0m: Importing user code(items_based_features.pkl) from ~/source\n","\u001b[0;33m14:09:53 \u001b[1;32mitems_based_features\u001b[0m: build_dataset function imported successfully\n","\u001b[0;33m14:09:53 \u001b[1;32mitems_based_features\u001b[0m: Downloading resources\n","\u001b[0;33m14:09:53 \u001b[1;32mitems_based_features\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:09:53 \u001b[1;32mitems_based_features\u001b[0m: Injecting the dependencies\n","\u001b[0;33m14:09:53 \u001b[1;32mitems_based_features\u001b[0m: Annotations: {}\n","\u001b[0;33m14:09:53 \u001b[1;32mitems_based_features\u001b[0m: Entity dependencies: {'models': {}, 'raw_datasets': {}, 'derived_datasets': {}, 'context': None, 'train': None}\n","\u001b[0;33m14:09:53 \u001b[1;32mitems_based_features\u001b[0m: Injected dependencies successfully: [$]\n","\u001b[0;33m14:09:53 \u001b[1;32mitems_based_features\u001b[0m: Executing the build_dataset\n","\u001b[0;33m14:09:53 \u001b[1;32mitems_based_features\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:09:44 \u001b[1;32morders_based_features\u001b[0m: Starting setup of dependencies...\n","\u001b[0;33m14:09:44 \u001b[1;32morders_based_features\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:09:44 \u001b[1;32morders_based_features\u001b[0m: Successfully logged into https://app.layer.ai\n","\u001b[0;33m14:09:44 \u001b[1;32morders_based_features\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:09:44 \u001b[1;32morders_based_features\u001b[0m: Downloading execution artifacts data-catalog--layer2022040715233801730000001e/add1b570-c8e7-4187-b747-1d01104893a9/ecommerce_olist_order_review_score_prediction/orders_based_features/dc4c9740-7c38-458c-90db-f49ca8896a90/orders_based_features.tgz to ~/source\n","\u001b[0;33m14:09:44 \u001b[1;32morders_based_features\u001b[0m: Creating directory ~/source\n","\u001b[0;33m14:09:44 \u001b[1;32morders_based_features\u001b[0m: Place __init__.py in ~/source\n","\u001b[0;33m14:09:44 \u001b[1;32morders_based_features\u001b[0m: Download binary(add1b570-c8e7-4187-b747-1d01104893a9/ecommerce_olist_order_review_score_prediction/orders_based_features/dc4c9740-7c38-458c-90db-f49ca8896a90/orders_based_features.tgz) to temp directory\n","\u001b[0;33m14:09:44 \u001b[1;32morders_based_features\u001b[0m: Binary archive orders_based_features.tgz downloaded and extracted to ~/source successfully\n","\u001b[0;33m14:09:44 \u001b[1;32morders_based_features\u001b[0m: Execution artifacts data-catalog--layer2022040715233801730000001e/add1b570-c8e7-4187-b747-1d01104893a9/ecommerce_olist_order_review_score_prediction/orders_based_features/dc4c9740-7c38-458c-90db-f49ca8896a90/orders_based_features.tgz downloaded successfully to ~/source\n","\u001b[0;33m14:09:44 \u001b[1;32morders_based_features\u001b[0m: Installing python dependencies from ~/source/requirements.txt\n","\u001b[0;33m14:09:45 \u001b[1;32morders_based_features\u001b[0m: Requirement already satisfied: numpy in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from -r /root/source/requirements.txt (line 1)) (1.21.6)\n","\u001b[0;33m14:09:45 \u001b[1;32morders_based_features\u001b[0m: Collecting sklearn\n","\u001b[0;33m14:09:45 \u001b[1;32morders_based_features\u001b[0m:   Downloading sklearn-0.0.tar.gz (1.1 kB)\n","\u001b[0;33m14:09:46 \u001b[1;32morders_based_features\u001b[0m: Requirement already satisfied: pandas in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from -r /root/source/requirements.txt (line 3)) (1.3.5)\n","\u001b[0;33m14:09:46 \u001b[1;32morders_based_features\u001b[0m: Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from pandas->-r /root/source/requirements.txt (line 3)) (2.8.2)\n","\u001b[0;33m14:09:46 \u001b[1;32morders_based_features\u001b[0m: Requirement already satisfied: pytz>=2017.3 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from pandas->-r /root/source/requirements.txt (line 3)) (2022.1)\n","\u001b[0;33m14:09:46 \u001b[1;32morders_based_features\u001b[0m: Requirement already satisfied: six>=1.5 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->-r /root/source/requirements.txt (line 3)) (1.16.0)\n","\u001b[0;33m14:09:46 \u001b[1;32morders_based_features\u001b[0m: Collecting scikit-learn\n","\u001b[0;33m14:09:46 \u001b[1;32morders_based_features\u001b[0m:   Downloading scikit_learn-1.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.8 MB)\n","\u001b[0;33m14:09:47 \u001b[1;32morders_based_features\u001b[0m: Collecting threadpoolctl>=2.0.0\n","\u001b[0;33m14:09:47 \u001b[1;32morders_based_features\u001b[0m:   Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n","\u001b[0;33m14:09:47 \u001b[1;32morders_based_features\u001b[0m: Requirement already satisfied: scipy>=1.1.0 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from scikit-learn->sklearn->-r /root/source/requirements.txt (line 2)) (1.7.3)\n","\u001b[0;33m14:09:47 \u001b[1;32morders_based_features\u001b[0m: Requirement already satisfied: joblib>=0.11 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from scikit-learn->sklearn->-r /root/source/requirements.txt (line 2)) (1.1.0)\n","\u001b[0;33m14:09:47 \u001b[1;32morders_based_features\u001b[0m: Building wheels for collected packages: sklearn\n","\u001b[0;33m14:09:47 \u001b[1;32morders_based_features\u001b[0m:   Building wheel for sklearn (setup.py): started\n","\u001b[0;33m14:09:48 \u001b[1;32morders_based_features\u001b[0m:   Building wheel for sklearn (setup.py): finished with status 'done'\n","\u001b[0;33m14:09:48 \u001b[1;32morders_based_features\u001b[0m:   Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1310 sha256=1551f4647ec3110f9b61da1b9b715410c0d9740017fc349239049340d3046fb4\n","\u001b[0;33m14:09:48 \u001b[1;32morders_based_features\u001b[0m:   Stored in directory: /root/.cache/pip/wheels/46/ef/c3/157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n","\u001b[0;33m14:09:48 \u001b[1;32morders_based_features\u001b[0m: Successfully built sklearn\n","\u001b[0;33m14:09:49 \u001b[1;32morders_based_features\u001b[0m: Installing collected packages: threadpoolctl, scikit-learn, sklearn\n","\u001b[0;33m14:09:50 \u001b[1;32morders_based_features\u001b[0m: Successfully installed scikit-learn-1.0.2 sklearn-0.0 threadpoolctl-3.1.0\n","\u001b[0;33m14:09:51 \u001b[1;32morders_based_features\u001b[0m: Python dependencies from ~/source/requirements.txt installed successfully\n","\u001b[0;33m14:09:53 \u001b[1;32morders_based_features\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:09:53 \u001b[1;32morders_based_features\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:09:53 \u001b[1;32morders_based_features\u001b[0m: Importing user code(orders_based_features.pkl) from ~/source\n","\u001b[0;33m14:09:53 \u001b[1;32morders_based_features\u001b[0m: build_dataset function imported successfully\n","\u001b[0;33m14:09:53 \u001b[1;32morders_based_features\u001b[0m: Downloading resources\n","\u001b[0;33m14:09:53 \u001b[1;32morders_based_features\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:09:53 \u001b[1;32morders_based_features\u001b[0m: Injecting the dependencies\n","\u001b[0;33m14:09:53 \u001b[1;32morders_based_features\u001b[0m: Annotations: {}\n","\u001b[0;33m14:09:53 \u001b[1;32morders_based_features\u001b[0m: Entity dependencies: {'models': {}, 'raw_datasets': {}, 'derived_datasets': {}, 'context': None, 'train': None}\n","\u001b[0;33m14:09:53 \u001b[1;32morders_based_features\u001b[0m: Injected dependencies successfully: [$]\n","\u001b[0;33m14:09:53 \u001b[1;32morders_based_features\u001b[0m: Executing the build_dataset\n","\u001b[0;33m14:09:53 \u001b[1;32morders_based_features\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:09:55 \u001b[1;32morders_based_features\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:09:55 \u001b[1;32morders_based_features\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:09:55 \u001b[1;32morders_based_features\u001b[0m: Executed build_dataset successfully\n","\u001b[0;33m14:09:55 \u001b[1;32morders_based_features\u001b[0m: Storing built derived_dataset\n","\u001b[0;33m14:10:09 \u001b[1;32mtraining_data\u001b[0m: Starting setup of dependencies...\n","\u001b[0;33m14:10:09 \u001b[1;32mtraining_data\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:10:09 \u001b[1;32mtraining_data\u001b[0m: Successfully logged into https://app.layer.ai\n","\u001b[0;33m14:10:09 \u001b[1;32mtraining_data\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:10:09 \u001b[1;32mtraining_data\u001b[0m: Downloading execution artifacts data-catalog--layer2022040715233801730000001e/add1b570-c8e7-4187-b747-1d01104893a9/ecommerce_olist_order_review_score_prediction/training_data/5d11eb42-5319-4c78-8207-1b56d31d789d/training_data.tgz to ~/source\n","\u001b[0;33m14:10:09 \u001b[1;32mtraining_data\u001b[0m: Creating directory ~/source\n","\u001b[0;33m14:10:09 \u001b[1;32mtraining_data\u001b[0m: Place __init__.py in ~/source\n","\u001b[0;33m14:10:09 \u001b[1;32mtraining_data\u001b[0m: Download binary(add1b570-c8e7-4187-b747-1d01104893a9/ecommerce_olist_order_review_score_prediction/training_data/5d11eb42-5319-4c78-8207-1b56d31d789d/training_data.tgz) to temp directory\n","\u001b[0;33m14:10:09 \u001b[1;32mtraining_data\u001b[0m: Binary archive training_data.tgz downloaded and extracted to ~/source successfully\n","\u001b[0;33m14:10:09 \u001b[1;32mtraining_data\u001b[0m: Execution artifacts data-catalog--layer2022040715233801730000001e/add1b570-c8e7-4187-b747-1d01104893a9/ecommerce_olist_order_review_score_prediction/training_data/5d11eb42-5319-4c78-8207-1b56d31d789d/training_data.tgz downloaded successfully to ~/source\n","\u001b[0;33m14:10:09 \u001b[1;32mtraining_data\u001b[0m: Installing python dependencies from ~/source/requirements.txt\n","\u001b[0;33m14:10:09 \u001b[1;32mtraining_data\u001b[0m: Requirement already satisfied: numpy in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from -r /root/source/requirements.txt (line 1)) (1.21.6)\n","\u001b[0;33m14:10:09 \u001b[1;32mtraining_data\u001b[0m: Collecting sklearn\n","\u001b[0;33m14:10:09 \u001b[1;32mtraining_data\u001b[0m:   Downloading sklearn-0.0.tar.gz (1.1 kB)\n","\u001b[0;33m14:10:10 \u001b[1;32mtraining_data\u001b[0m: Requirement already satisfied: pandas in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from -r /root/source/requirements.txt (line 3)) (1.3.5)\n","\u001b[0;33m14:10:10 \u001b[1;32mtraining_data\u001b[0m: Requirement already satisfied: pytz>=2017.3 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from pandas->-r /root/source/requirements.txt (line 3)) (2022.1)\n","\u001b[0;33m14:10:10 \u001b[1;32mtraining_data\u001b[0m: Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from pandas->-r /root/source/requirements.txt (line 3)) (2.8.2)\n","\u001b[0;33m14:10:10 \u001b[1;32mtraining_data\u001b[0m: Requirement already satisfied: six>=1.5 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->-r /root/source/requirements.txt (line 3)) (1.16.0)\n","\u001b[0;33m14:10:11 \u001b[1;32mtraining_data\u001b[0m: Collecting scikit-learn\n","\u001b[0;33m14:10:11 \u001b[1;32mtraining_data\u001b[0m:   Downloading scikit_learn-1.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.8 MB)\n","\u001b[0;33m14:10:11 \u001b[1;32mtraining_data\u001b[0m: Requirement already satisfied: scipy>=1.1.0 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from scikit-learn->sklearn->-r /root/source/requirements.txt (line 2)) (1.7.3)\n","\u001b[0;33m14:10:11 \u001b[1;32mtraining_data\u001b[0m: Requirement already satisfied: joblib>=0.11 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from scikit-learn->sklearn->-r /root/source/requirements.txt (line 2)) (1.1.0)\n","\u001b[0;33m14:10:11 \u001b[1;32mtraining_data\u001b[0m: Collecting threadpoolctl>=2.0.0\n","\u001b[0;33m14:10:11 \u001b[1;32mtraining_data\u001b[0m:   Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n","\u001b[0;33m14:10:11 \u001b[1;32mtraining_data\u001b[0m: Building wheels for collected packages: sklearn\n","\u001b[0;33m14:10:11 \u001b[1;32mtraining_data\u001b[0m:   Building wheel for sklearn (setup.py): started\n","\u001b[0;33m14:10:13 \u001b[1;32mtraining_data\u001b[0m:   Building wheel for sklearn (setup.py): finished with status 'done'\n","\u001b[0;33m14:10:13 \u001b[1;32mtraining_data\u001b[0m:   Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1310 sha256=68f14286460ebf828ec09aba2c1b2f8f4875d77825a84e7476a56e831998f32a\n","\u001b[0;33m14:10:13 \u001b[1;32mtraining_data\u001b[0m:   Stored in directory: /root/.cache/pip/wheels/46/ef/c3/157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n","\u001b[0;33m14:10:13 \u001b[1;32mtraining_data\u001b[0m: Successfully built sklearn\n","\u001b[0;33m14:10:13 \u001b[1;32mtraining_data\u001b[0m: Installing collected packages: threadpoolctl, scikit-learn, sklearn\n","\u001b[0;33m14:10:15 \u001b[1;32mtraining_data\u001b[0m: Successfully installed scikit-learn-1.0.2 sklearn-0.0 threadpoolctl-3.1.0\n","\u001b[0;33m14:10:15 \u001b[1;32mtraining_data\u001b[0m: Python dependencies from ~/source/requirements.txt installed successfully\n","\u001b[0;33m14:10:17 \u001b[1;32mtraining_data\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:10:17 \u001b[1;32mtraining_data\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:10:17 \u001b[1;32mtraining_data\u001b[0m: Importing user code(training_data.pkl) from ~/source\n","\u001b[0;33m14:10:17 \u001b[1;32mtraining_data\u001b[0m: build_dataset function imported successfully\n","\u001b[0;33m14:10:17 \u001b[1;32mtraining_data\u001b[0m: Downloading resources\n","\u001b[0;33m14:10:17 \u001b[1;32mtraining_data\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:10:17 \u001b[1;32mtraining_data\u001b[0m: Injecting the dependencies\n","\u001b[0;33m14:10:17 \u001b[1;32mtraining_data\u001b[0m: Annotations: {'return': typing.Callable[..., typing.Any]}\n","\u001b[0;33m14:10:17 \u001b[1;32mtraining_data\u001b[0m: Entity dependencies: {'models': {}, 'raw_datasets': {}, 'derived_datasets': {}, 'context': None, 'train': None}\n","\u001b[0;33m14:10:17 \u001b[1;32mtraining_data\u001b[0m: Injected dependencies successfully: [$]\n","\u001b[0;33m14:10:17 \u001b[1;32mtraining_data\u001b[0m: Executing the build_dataset\n","\u001b[0;33m14:10:17 \u001b[1;32mtraining_data\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:10:18 \u001b[1;32mtraining_data\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:10:18 \u001b[1;32mtraining_data\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:10:19 \u001b[1;32mtraining_data\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:10:19 \u001b[1;32mtraining_data\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:10:19 \u001b[1;32mtraining_data\u001b[0m: Test SUCCESS: assert_valid_values('review_score', [1, 2, 3, 4, 5]).\n","\u001b[0;33m14:10:19 \u001b[1;32mtraining_data\u001b[0m: Test SUCCESS: assert_unique(['order_id']).\n","\u001b[0;33m14:10:19 \u001b[1;32mtraining_data\u001b[0m: Executed build_dataset successfully\n","\u001b[0;33m14:10:19 \u001b[1;32mtraining_data\u001b[0m: Storing built derived_dataset\n","\u001b[0;33m14:10:22 \u001b[1;32mtraining_data\u001b[0m: Built derived_dataset stored successfully\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: Matching sans\\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: Matching sans\\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: Matching sans\\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0.\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: Matching sans\\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0 to DejaVu Sans ('/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: Matching sans\\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05\n","\u001b[0;33m14:11:44 \u001b[1;32mreview_score_predictor_model\u001b[0m: findfont: Matching sans\\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/python_3_7/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.\n","\u001b[0;33m14:11:45 \u001b[1;32mreview_score_predictor_model\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:11:45 \u001b[1;32mreview_score_predictor_model\u001b[0m: Using selector: EpollSelector\n","\u001b[0;33m14:11:45 \u001b[1;32mreview_score_predictor_model\u001b[0m: Executed train_model_func successfully\n","\u001b[0;33m14:11:45 \u001b[1;32mreview_score_predictor_model\u001b[0m: Saving model artifact XGBRegressor(colsample_bytree=1.0, learning_rate=0.02, max_depth=5,_             min_child_weight=10, n_estimators=200,_             objective='reg:squarederror', subsample=0.5) to model registry\n","\u001b[0;33m14:11:46 \u001b[1;32mreview_score_predictor_model\u001b[0m: Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.\n","\u001b[0;33m14:11:46 \u001b[1;32mreview_score_predictor_model\u001b[0m: Creating converter from 7 to 5\n","\u001b[0;33m14:11:46 \u001b[1;32mreview_score_predictor_model\u001b[0m: Creating converter from 5 to 7\n","\u001b[0;33m14:11:46 \u001b[1;32mreview_score_predictor_model\u001b[0m: Creating converter from 7 to 5\n","\u001b[0;33m14:11:46 \u001b[1;32mreview_score_predictor_model\u001b[0m: Creating converter from 5 to 7\n","\u001b[0;33m14:11:47 \u001b[1;32mreview_score_predictor_model\u001b[0m: Matching flavor: <layer.mlmodels.flavors.flavor.ScikitLearnModelFlavor object at 0x7f45ba15c290>\n","\u001b[0;33m14:11:47 \u001b[1;32mreview_score_predictor_model\u001b[0m: flavor name: ScikitLearnModelFlavor, proto flavor: 5\n","\u001b[0;33m14:11:47 \u001b[1;32mreview_score_predictor_model\u001b[0m: Storing given model XGBRegressor(colsample_bytree=1.0, learning_rate=0.02, max_depth=5,_             min_child_weight=10, n_estimators=200,_             objective='reg:squarederror', subsample=0.5) with definition ModelDefinition{model_name:review_score_predictor_modelmodel_train_id:500dc2d3-5a49-4786-b092-4db8a5ac35eaproto_flavor:5s3_path:bucket: \"model-catalog--layer20220407152331648300000019\"_key: \"add1b570-c8e7-4187-b747-1d01104893a9/500dc2d3-5a49-4786-b092-4db8a5ac35ea/\"_}\n","\u001b[0;33m14:11:47 \u001b[1;32mreview_score_predictor_model\u001b[0m: Saving user model review_score_predictor_model(XGBRegressor(colsample_bytree=1.0, learning_rate=0.02, max_depth=5,_             min_child_weight=10, n_estimators=200,_             objective='reg:squarederror', subsample=0.5))\n","\u001b[0;33m14:11:47 \u001b[1;32mreview_score_predictor_model\u001b[0m: Writing model ModelDefinition{model_name:review_score_predictor_modelmodel_train_id:500dc2d3-5a49-4786-b092-4db8a5ac35eaproto_flavor:5s3_path:bucket: \"model-catalog--layer20220407152331648300000019\"_key: \"add1b570-c8e7-4187-b747-1d01104893a9/500dc2d3-5a49-4786-b092-4db8a5ac35ea/\"_}\n","\u001b[0;33m14:11:48 \u001b[1;32mreview_score_predictor_model\u001b[0m: User model review_score_predictor_model saved successfully\n","\u001b[0;33m14:11:48 \u001b[1;32mreview_score_predictor_model\u001b[0m: Saved model artifact XGBRegressor(colsample_bytree=1.0, learning_rate=0.02, max_depth=5,_             min_child_weight=10, n_estimators=200,_             objective='reg:squarederror', subsample=0.5) to model registry successfully\n","\u001b[0;33m14:11:49 \u001b[1;32mreview_score_predictor_model\u001b[0m: ['/opt/conda/envs/python_3_7/bin/python -X faulthandler -m pyruntime.model.train_executor 2>/proc/1/fd/2' exited with 0]\n","\u001b[0;33m14:11:49 \u001b[1;32mreview_score_predictor_model\u001b[0m: Process exit code: 0\n"]},{"data":{"text/plain":["Run(project_name='ecommerce_olist_order_review_score_prediction')"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["## LAYER Project Initialize\n","layer.init('ecommerce_olist_order_review_score_prediction',\n","           fabric=\"f-small\",\n","           pip_packages=[\"numpy\",\"sklearn\",\"pandas\"]\n","           )\n","\n","## LAYER REMOTE MODE\n","layer.run([load_order_table,\n","           clean_order_table,\n","           extract_features_order_table,\n","           load_item_table,\n","           clean_items_table,\n","           extract_features_items_table,\n","           load_reviews_table,\n","           clean_reviews_table,\n","           generate_training_data,\n","           train_final_model], debug=True)\n","\n","## LAYER LOCAL MODEL - Run your functions in order\n","# load_order_table()\n","# clean_order_table()\n","# extract_features_order_table()\n","# load_item_table()\n","# clean_items_table()\n","# extract_features_items_table()\n","# load_reviews_table()\n","# clean_reviews_table()\n","# generate_training_data()\n","# train_final_model()"]},{"cell_type":"code","execution_count":41,"metadata":{"executionInfo":{"elapsed":5306,"status":"ok","timestamp":1651155407721,"user":{"displayName":"Burak Özen","userId":"16794056347198304221"},"user_tz":-120},"id":"r3tGmiIthr1E"},"outputs":[],"source":["import layer\n","\n","my_model = layer.get_model('layer/ecommerce_olist_order_review_score_prediction/models/review_score_predictor_model:2.1').get_train()\n","\n","df = layer.get_dataset('layer/ecommerce_olist_order_review_score_prediction/datasets/training_data:1.2').to_pandas()\n"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3353,"status":"ok","timestamp":1651155467347,"user":{"displayName":"Burak Özen","userId":"16794056347198304221"},"user_tz":-120},"id":"yqZJSwHCqtJw","outputId":"d05ea456-f983-49ad-e019-6fa9385ae02b"},"outputs":[{"name":"stdout","output_type":"stream","text":["PREDICTED REVIEW SCORE [1-5]:\n"," [1.6939433]\n","\n","ORDER FEATURES: \n","        days_between_purhcase_and_delivery  order_approved_late  \\\n","65905                                  57                    0   \n","\n","       actual_delivery_vs_expectation_bucket  is_multiItems_order  \\\n","65905                                     -1                    0   \n","\n","       total_order_price  total_order_freight  seller_shipped_late  \n","65905              49.95                16.79                    0  \n"]}],"source":["test_sample = df.drop(['review_score', 'order_id'], axis=1).sample()\n","predicted_review_score = layer.get_model(\"review_score_predictor_model\").get_train().predict(test_sample)\n","print(\"PREDICTED REVIEW SCORE [1-5]: \",predicted_review_score)"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"ecommerce_order_review_score_prediction.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"24a1246eebae40829bf30bf8b0702822":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b16e4a393e154a6aba14094e2e0b30ad":{"model_module":"@jupyter-widgets/output","model_module_version":"1.0.0","model_name":"OutputModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_24a1246eebae40829bf30bf8b0702822","msg_id":"","outputs":[{"data":{"text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅  orders_raw_table     <span style=\"color: #34d399; text-decoration-color: #34d399\">━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #34d399; text-decoration-color: #34d399\">        done         </span> <span style=\"color: #000000; text-decoration-color: #000000\">[ </span><span style=\"color: #808000; text-decoration-color: #808000\">0:00:23</span><span style=\"color: #000000; text-decoration-color: #000000\"> ]</span>            \n    <a href=\"https://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/datasets/orders_raw_table\"><span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">https://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/datasets/orders</span></a> \n    <a href=\"https://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/datasets/orders_raw_table\"><span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">_raw_table</span></a>                                                                               \n✅  orders_clean_table   <span style=\"color: #34d399; text-decoration-color: #34d399\">━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #34d399; text-decoration-color: #34d399\">        done         </span> <span style=\"color: #000000; text-decoration-color: #000000\">[ </span><span style=\"color: #808000; text-decoration-color: #808000\">0:00:34</span><span style=\"color: #000000; text-decoration-color: #000000\"> ]</span>            \n    <a href=\"https://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/datasets/orders_clean_table\"><span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">https://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/datasets/orders</span></a> \n    <a href=\"https://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/datasets/orders_clean_table\"><span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">_clean_table</span></a>                                                                             \n✅  orders_based_featur… <span style=\"color: #34d399; text-decoration-color: #34d399\">━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #34d399; text-decoration-color: #34d399\">        done         </span> <span style=\"color: #000000; text-decoration-color: #000000\">[ </span><span style=\"color: #808000; text-decoration-color: #808000\">0:00:18</span><span style=\"color: #000000; text-decoration-color: #000000\"> ]</span>            \n    <a href=\"https://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/datasets/orders_based_features\"><span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">https://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/datasets/orders</span></a> \n    <a href=\"https://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/datasets/orders_based_features\"><span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">_based_features</span></a>                                                                          \n✅  items_raw_table      <span style=\"color: #34d399; text-decoration-color: #34d399\">━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #34d399; text-decoration-color: #34d399\">        done         </span> <span style=\"color: #000000; text-decoration-color: #000000\">[ </span><span style=\"color: #808000; text-decoration-color: #808000\">0:00:29</span><span style=\"color: #000000; text-decoration-color: #000000\"> ]</span>            \n    <a href=\"https://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/datasets/items_raw_table\"><span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">https://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/datasets/items_</span></a> \n    <a href=\"https://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/datasets/items_raw_table\"><span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">raw_table</span></a>                                                                                \n✅  items_clean_table    <span style=\"color: #34d399; text-decoration-color: #34d399\">━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #34d399; text-decoration-color: #34d399\">        done         </span> <span style=\"color: #000000; text-decoration-color: #000000\">[ </span><span style=\"color: #808000; text-decoration-color: #808000\">0:00:50</span><span style=\"color: #000000; text-decoration-color: #000000\"> ]</span>            \n    <a href=\"https://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/datasets/items_clean_table\"><span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">https://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/datasets/items_</span></a> \n    <a href=\"https://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/datasets/items_clean_table\"><span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">clean_table</span></a>                                                                              \n✅  items_based_features <span style=\"color: #34d399; text-decoration-color: #34d399\">━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #34d399; text-decoration-color: #34d399\">        done         </span> <span style=\"color: #000000; text-decoration-color: #000000\">[ </span><span style=\"color: #808000; text-decoration-color: #808000\">0:00:25</span><span style=\"color: #000000; text-decoration-color: #000000\"> ]</span>            \n    <a href=\"https://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/datasets/items_based_features\"><span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">https://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/datasets/items_</span></a> \n    <a href=\"https://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/datasets/items_based_features\"><span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">based_features</span></a>                                                                           \n✅  reviews_raw_table    <span style=\"color: #34d399; text-decoration-color: #34d399\">━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #34d399; text-decoration-color: #34d399\">        done         </span> <span style=\"color: #000000; text-decoration-color: #000000\">[ </span><span style=\"color: #808000; text-decoration-color: #808000\">0:00:26</span><span style=\"color: #000000; text-decoration-color: #000000\"> ]</span>            \n    <a href=\"https://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/datasets/reviews_raw_table\"><span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">https://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/datasets/review</span></a> \n    <a href=\"https://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/datasets/reviews_raw_table\"><span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">s_raw_table</span></a>                                                                              \n✅  reviews_clean_table  <span style=\"color: #34d399; text-decoration-color: #34d399\">━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #34d399; text-decoration-color: #34d399\">        done         </span> <span style=\"color: #000000; text-decoration-color: #000000\">[ </span><span style=\"color: #808000; text-decoration-color: #808000\">0:00:50</span><span style=\"color: #000000; text-decoration-color: #000000\"> ]</span>            \n    <a href=\"https://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/datasets/reviews_clean_table\"><span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">https://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/datasets/review</span></a> \n    <a href=\"https://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/datasets/reviews_clean_table\"><span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">s_clean_table</span></a>                                                                            \n✅  training_data        <span style=\"color: #34d399; text-decoration-color: #34d399\">━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #34d399; text-decoration-color: #34d399\">        done         </span> <span style=\"color: #000000; text-decoration-color: #000000\">[ </span><span style=\"color: #808000; text-decoration-color: #808000\">0:00:18</span><span style=\"color: #000000; text-decoration-color: #000000\"> ]</span>            \n    <a href=\"https://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/datasets/training_data\"><span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">https://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/datasets/traini</span></a> \n    <a href=\"https://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/datasets/training_data\"><span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">ng_data</span></a>                                                                                  \n✅  review_score_predic… <span style=\"color: #34d399; text-decoration-color: #34d399\">━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #34d399; text-decoration-color: #34d399\">        done         </span> <span style=\"color: #000000; text-decoration-color: #000000\">[ </span><span style=\"color: #808000; text-decoration-color: #808000\">0:01:24</span><span style=\"color: #000000; text-decoration-color: #000000\"> ]</span>            \n    <a href=\"https://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/models/review_score_predictor_model\"><span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">https://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/models/review_s</span></a> \n    <a href=\"https://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/models/review_score_predictor_model\"><span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">core_predictor_model</span></a>                                                                     \n</pre>\n","text/plain":"✅  orders_raw_table     \u001b[38;2;52;211;153m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[38;2;52;211;153m        done         \u001b[0m \u001b[39m[ \u001b[0m\u001b[33m0:00:23\u001b[0m\u001b[39m ]\u001b[0m            \n    \u001b]8;id=845374;https://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/datasets/orders_raw_table\u001b\\\u001b[4;38;2;161;161;169mhttps://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/datasets/orders\u001b[0m\u001b]8;;\u001b\\ \n    \u001b]8;id=845374;https://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/datasets/orders_raw_table\u001b\\\u001b[4;38;2;161;161;169m_raw_table\u001b[0m\u001b]8;;\u001b\\                                                                               \n✅  orders_clean_table   \u001b[38;2;52;211;153m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[38;2;52;211;153m        done         \u001b[0m \u001b[39m[ \u001b[0m\u001b[33m0:00:34\u001b[0m\u001b[39m ]\u001b[0m            \n    \u001b]8;id=429220;https://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/datasets/orders_clean_table\u001b\\\u001b[4;38;2;161;161;169mhttps://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/datasets/orders\u001b[0m\u001b]8;;\u001b\\ \n    \u001b]8;id=429220;https://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/datasets/orders_clean_table\u001b\\\u001b[4;38;2;161;161;169m_clean_table\u001b[0m\u001b]8;;\u001b\\                                                                             \n✅  orders_based_featur… \u001b[38;2;52;211;153m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[38;2;52;211;153m        done         \u001b[0m \u001b[39m[ \u001b[0m\u001b[33m0:00:18\u001b[0m\u001b[39m ]\u001b[0m            \n    \u001b]8;id=314249;https://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/datasets/orders_based_features\u001b\\\u001b[4;38;2;161;161;169mhttps://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/datasets/orders\u001b[0m\u001b]8;;\u001b\\ \n    \u001b]8;id=314249;https://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/datasets/orders_based_features\u001b\\\u001b[4;38;2;161;161;169m_based_features\u001b[0m\u001b]8;;\u001b\\                                                                          \n✅  items_raw_table      \u001b[38;2;52;211;153m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[38;2;52;211;153m        done         \u001b[0m \u001b[39m[ \u001b[0m\u001b[33m0:00:29\u001b[0m\u001b[39m ]\u001b[0m            \n    \u001b]8;id=983603;https://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/datasets/items_raw_table\u001b\\\u001b[4;38;2;161;161;169mhttps://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/datasets/items_\u001b[0m\u001b]8;;\u001b\\ \n    \u001b]8;id=983603;https://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/datasets/items_raw_table\u001b\\\u001b[4;38;2;161;161;169mraw_table\u001b[0m\u001b]8;;\u001b\\                                                                                \n✅  items_clean_table    \u001b[38;2;52;211;153m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[38;2;52;211;153m        done         \u001b[0m \u001b[39m[ \u001b[0m\u001b[33m0:00:50\u001b[0m\u001b[39m ]\u001b[0m            \n    \u001b]8;id=545646;https://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/datasets/items_clean_table\u001b\\\u001b[4;38;2;161;161;169mhttps://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/datasets/items_\u001b[0m\u001b]8;;\u001b\\ \n    \u001b]8;id=545646;https://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/datasets/items_clean_table\u001b\\\u001b[4;38;2;161;161;169mclean_table\u001b[0m\u001b]8;;\u001b\\                                                                              \n✅  items_based_features \u001b[38;2;52;211;153m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[38;2;52;211;153m        done         \u001b[0m \u001b[39m[ \u001b[0m\u001b[33m0:00:25\u001b[0m\u001b[39m ]\u001b[0m            \n    \u001b]8;id=2230;https://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/datasets/items_based_features\u001b\\\u001b[4;38;2;161;161;169mhttps://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/datasets/items_\u001b[0m\u001b]8;;\u001b\\ \n    \u001b]8;id=2230;https://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/datasets/items_based_features\u001b\\\u001b[4;38;2;161;161;169mbased_features\u001b[0m\u001b]8;;\u001b\\                                                                           \n✅  reviews_raw_table    \u001b[38;2;52;211;153m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[38;2;52;211;153m        done         \u001b[0m \u001b[39m[ \u001b[0m\u001b[33m0:00:26\u001b[0m\u001b[39m ]\u001b[0m            \n    \u001b]8;id=288721;https://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/datasets/reviews_raw_table\u001b\\\u001b[4;38;2;161;161;169mhttps://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/datasets/review\u001b[0m\u001b]8;;\u001b\\ \n    \u001b]8;id=288721;https://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/datasets/reviews_raw_table\u001b\\\u001b[4;38;2;161;161;169ms_raw_table\u001b[0m\u001b]8;;\u001b\\                                                                              \n✅  reviews_clean_table  \u001b[38;2;52;211;153m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[38;2;52;211;153m        done         \u001b[0m \u001b[39m[ \u001b[0m\u001b[33m0:00:50\u001b[0m\u001b[39m ]\u001b[0m            \n    \u001b]8;id=924036;https://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/datasets/reviews_clean_table\u001b\\\u001b[4;38;2;161;161;169mhttps://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/datasets/review\u001b[0m\u001b]8;;\u001b\\ \n    \u001b]8;id=924036;https://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/datasets/reviews_clean_table\u001b\\\u001b[4;38;2;161;161;169ms_clean_table\u001b[0m\u001b]8;;\u001b\\                                                                            \n✅  training_data        \u001b[38;2;52;211;153m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[38;2;52;211;153m        done         \u001b[0m \u001b[39m[ \u001b[0m\u001b[33m0:00:18\u001b[0m\u001b[39m ]\u001b[0m            \n    \u001b]8;id=452707;https://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/datasets/training_data\u001b\\\u001b[4;38;2;161;161;169mhttps://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/datasets/traini\u001b[0m\u001b]8;;\u001b\\ \n    \u001b]8;id=452707;https://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/datasets/training_data\u001b\\\u001b[4;38;2;161;161;169mng_data\u001b[0m\u001b]8;;\u001b\\                                                                                  \n✅  review_score_predic… \u001b[38;2;52;211;153m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[38;2;52;211;153m        done         \u001b[0m \u001b[39m[ \u001b[0m\u001b[33m0:01:24\u001b[0m\u001b[39m ]\u001b[0m            \n    \u001b]8;id=273153;https://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/models/review_score_predictor_model\u001b\\\u001b[4;38;2;161;161;169mhttps://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/models/review_s\u001b[0m\u001b]8;;\u001b\\ \n    \u001b]8;id=273153;https://app.layer.ai/layer/ecommerce_olist_order_review_score_prediction/models/review_score_predictor_model\u001b\\\u001b[4;38;2;161;161;169mcore_predictor_model\u001b[0m\u001b]8;;\u001b\\                                                                     \n"},"metadata":{},"output_type":"display_data"}]}}}}},"nbformat":4,"nbformat_minor":0}
